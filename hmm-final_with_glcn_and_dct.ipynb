{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from hmmlearn import hmm\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "import joblib\n",
    "import re\n",
    "from scipy.fftpack import dct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting GLCM features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute GLCM features for six properties across four directions\n",
    "def compute_glcm_features_4_directions(window, distances=[1], levels=256):\n",
    "    # Convert to grayscale if the window is not already\n",
    "    if len(window.shape) == 3:\n",
    "        window = cv2.cvtColor(window, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Ensure the window pixel intensity is in the range [0, levels-1]\n",
    "    window = np.clip(window, 0, levels - 1).astype(np.uint8)\n",
    "    \n",
    "    # Define angles for the four directions: 0°, 45°, 90°, 135°\n",
    "    angles = [0, np.pi/2]\n",
    "    \n",
    "    # Compute GLCM\n",
    "    glcm = graycomatrix(window, distances=distances, angles=angles, levels=levels, symmetric=True, normed=True)\n",
    "    \n",
    "    # Extract GLCM properties for six features\n",
    "    features = {}\n",
    "    features['contrast'] = np.mean(graycoprops(glcm, 'contrast'))\n",
    "    features['dissimilarity'] = np.mean(graycoprops(glcm, 'dissimilarity'))\n",
    "    features['homogeneity'] = np.mean(graycoprops(glcm, 'homogeneity'))\n",
    "    features['ASM'] = np.mean(graycoprops(glcm, 'ASM'))  # Angular Second Moment (Energy)\n",
    "    features['energy'] = np.mean(np.sqrt(graycoprops(glcm, 'ASM')))  # Energy is sqrt(ASM)\n",
    "    features['correlation'] = np.mean(graycoprops(glcm, 'correlation'))\n",
    "    \n",
    "    return [features['contrast'], features['dissimilarity'], features['homogeneity'], \n",
    "            features['ASM'], features['energy'], features['correlation']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting DCT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dct_features(window):\n",
    "    # Convert to grayscale if the window is not already\n",
    "    if len(window.shape) == 3:\n",
    "        window = cv2.cvtColor(window, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Flatten the window to 1D array for DCT computation\n",
    "    window_flat = window.flatten()\n",
    "    \n",
    "    # Compute DCT and take the first N coefficients (e.g., 198)\n",
    "    dct_features = dct(window_flat, norm='ortho')[:50]\n",
    "    \n",
    "    return dct_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combned both GLCM and DCT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_features(window, dct_features=50):\n",
    "    # Compute DCT features\n",
    "    dct_feats = compute_dct_features(window)\n",
    "    # Compute GLCM features\n",
    "    glcm_feature = compute_glcm_features_4_directions(window)\n",
    "    # Combine DCT and GLCM features\n",
    "    combined_features = np.hstack([dct_feats, glcm_feature])\n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_excel(r'//home//jaykishor_c//ml//gt_WIndow .xlsx')  \n",
    "\n",
    "image_folder = r'//home//jaykishor_c//ml//color_window_double1//color_window_double1'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(combined_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined features (GLCM and DCT) sequences for each character across all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_glcm_and_dct = {}\n",
    "\n",
    "window_width = 30   # Width of each sliding window in pixels\n",
    "step_size = 10     # Step size of the sliding window in pixels\n",
    "\n",
    "# Process each image (word) in the dataset\n",
    "for index, row in labels_df.iterrows():\n",
    "    image_name = row['image name']          # image name of respective gt text\n",
    "    character_sequence = row['gt']          # gt text\n",
    "    \n",
    "    # Load the corresponding image\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Image {image_name} could not be loaded.\")\n",
    "        continue\n",
    "\n",
    "    image_width = image.shape[1]  # Get image width\n",
    "    \n",
    "    # Calculate the width of each character region based on the sequence length\n",
    "    num_characters = len(character_sequence)\n",
    "    character_width = image_width // num_characters\n",
    "    \n",
    "    # Loop through each character in the sequence and collect its GLCM features\n",
    "    for i, char in enumerate(character_sequence):\n",
    "        # Define the region corresponding to the current character\n",
    "        region_start = i * character_width\n",
    "        region_end = region_start + character_width\n",
    "        character_region = image[:, region_start:region_end]  # Assume height is all rows\n",
    "        \n",
    "        # Split the character region into windows to capture GLCM features\n",
    "        num_windows = (character_width - window_width) // step_size + 1\n",
    "        char_combined_sequence = []\n",
    "        \n",
    "        for j in range(num_windows):\n",
    "            # Calculate the start and end of the window within the character region\n",
    "            window_start = region_start + j * step_size\n",
    "            window_end = window_start + window_width\n",
    "            \n",
    "            # Extract the window\n",
    "            window = image[:, window_start:window_end]\n",
    "            \n",
    "            # Compute GLCM features for this window across four directions\n",
    "            # glcm_features = compute_glcm_features_4_directions(window)\n",
    "            # dct_features = compute_dct_features(window)\n",
    "            # combined_features = np.hstack([glcm_features, dct_features])\n",
    "            combined_features = compute_combined_features(window)\n",
    "            # combine_features = combine_glcm_dct_features(dct_features, glcm_features)\n",
    "            char_combined_sequence.append(combined_features)\n",
    "\n",
    "        \n",
    "        # Append this character's GLCM features to the global dictionary\n",
    "        if char not in combined_features_glcm_and_dct:\n",
    "            combined_features_glcm_and_dct[char] = []\n",
    "        combined_features_glcm_and_dct[char].append(char_combined_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_combined_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Printing GLCM and DCT features sequences for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character 'െ'  has 618    sequences of GLCM features.\n",
      "Character 'ത'  has 535    sequences of GLCM features.\n",
      "Character 'അ'  has 103    sequences of GLCM features.\n",
      "Character '്'  has 1202    sequences of GLCM features.\n",
      "Character 'ാ'  has 993    sequences of GLCM features.\n",
      "Character 'ി'  has 729    sequences of GLCM features.\n",
      "Character 'പ'  has 339    sequences of GLCM features.\n",
      "Character 'റ'  has 432    sequences of GLCM features.\n",
      "Character 'ര'  has 681    sequences of GLCM features.\n",
      "Character 'ു'  has 455    sequences of GLCM features.\n",
      "Character 'ള'  has 78    sequences of GLCM features.\n",
      "Character 'ക'  has 473    sequences of GLCM features.\n",
      "Character 'ഷ'  has 105    sequences of GLCM features.\n",
      "Character 'മ'  has 361    sequences of GLCM features.\n",
      "Character 'ആ'  has 28    sequences of GLCM features.\n",
      "Character 'ഠ'  has 61    sequences of GLCM features.\n",
      "Character 'ൽ'  has 40    sequences of GLCM features.\n",
      "Character 'ർ'  has 62    sequences of GLCM features.\n",
      "Character 'ഇ'  has 30    sequences of GLCM features.\n",
      "Character 'ങ'  has 37    sequences of GLCM features.\n",
      "Character 'ന'  has 674    sequences of GLCM features.\n",
      "Character 'ജ'  has 115    sequences of GLCM features.\n",
      "Character 'ട'  has 281    sequences of GLCM features.\n",
      "Character 'വ'  has 312    sequences of GLCM features.\n",
      "Character 'ഹ'  has 76    sequences of GLCM features.\n",
      "Character 'ം'  has 196    sequences of GLCM features.\n",
      "Character 'യ'  has 337    sequences of GLCM features.\n",
      "Character '\"'  has 518    sequences of GLCM features.\n",
      "Character 'ധ'  has 70    sequences of GLCM features.\n",
      "Character 'ച'  has 210    sequences of GLCM features.\n",
      "Character 'ഫ'  has 13    sequences of GLCM features.\n",
      "Character 'എ'  has 41    sequences of GLCM features.\n",
      "Character 'ല'  has 273    sequences of GLCM features.\n",
      "Character 'ഴ'  has 55    sequences of GLCM features.\n",
      "Character 'ഒ'  has 14    sequences of GLCM features.\n",
      "Character 'ദ'  has 194    sequences of GLCM features.\n",
      "Character 'ഗ'  has 131    sequences of GLCM features.\n",
      "Character 'ഉ'  has 25    sequences of GLCM features.\n",
      "Character 'ണ'  has 155    sequences of GLCM features.\n",
      "Character 'ൂ'  has 71    sequences of GLCM features.\n",
      "Character 'ൻ'  has 56    sequences of GLCM features.\n",
      "Character 'സ'  has 200    sequences of GLCM features.\n",
      "Character 'ീ'  has 132    sequences of GLCM features.\n",
      "Character 'ഋ'  has 1    sequences of GLCM features.\n",
      "Character 'ഭ'  has 86    sequences of GLCM features.\n",
      "Character 'ഖ'  has 21    sequences of GLCM features.\n",
      "Character 'ശ'  has 119    sequences of GLCM features.\n",
      "Character 'ൈ'  has 45    sequences of GLCM features.\n",
      "Character 'ഥ'  has 23    sequences of GLCM features.\n",
      "Character 'ൾ'  has 26    sequences of GLCM features.\n",
      "Character 'ഘ'  has 16    sequences of GLCM features.\n",
      "Character 'ൃ'  has 63    sequences of GLCM features.\n",
      "Character 'ഡ'  has 8    sequences of GLCM features.\n",
      "Character 'ഛ'  has 14    sequences of GLCM features.\n",
      "Character '‌'  has 3    sequences of GLCM features.\n",
      "Character 'ൊ'  has 54    sequences of GLCM features.\n",
      "Character 'േ'  has 5    sequences of GLCM features.\n",
      "Character 'ഞ'  has 22    sequences of GLCM features.\n",
      "Character '2'  has 1    sequences of GLCM features.\n",
      "Character 'ബ'  has 26    sequences of GLCM features.\n",
      "Character ':'  has 6    sequences of GLCM features.\n",
      "Character 'ഃ'  has 28    sequences of GLCM features.\n",
      "Character 'ൗ'  has 12    sequences of GLCM features.\n",
      "Character 'ൌ'  has 3    sequences of GLCM features.\n",
      "Character '‍'  has 18    sequences of GLCM features.\n",
      "Character 'ോ'  has 1    sequences of GLCM features.\n",
      "Character 'ഝ'  has 2    sequences of GLCM features.\n",
      "Character 'ഢ'  has 3    sequences of GLCM features.\n",
      "Character '?'  has 2    sequences of GLCM features.\n",
      "Character 'ഐ'  has 1    sequences of GLCM features.\n",
      "Character 'ൺ'  has 4    sequences of GLCM features.\n"
     ]
    }
   ],
   "source": [
    "# Print the number of GLCM feature sequences for each character\n",
    "for char, sequences in combined_features_glcm_and_dct.items():\n",
    "    print(f\"Character '{char}'  has {len(sequences)}    sequences of GLCM features.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the GLCM features to a file for analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLCM features saved to //home//jaykishor_c//ml//Output2//character_glcm_and_dct_features_final.xlsx\n"
     ]
    }
   ],
   "source": [
    "output_path =r'//home//jaykishor_c//ml//Output2//character_glcm_and_dct_features_final.xlsx'\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    'Character': [char for char, sequences in combined_features_glcm_and_dct.items() for _ in sequences],\n",
    "    'GLCM Features': [seq for sequences in combined_features_glcm_and_dct.values() for seq in sequences]\n",
    "})\n",
    "\n",
    "features_df.to_excel(output_path, index=False)\n",
    "print(f\"GLCM features saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_combined_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Character HMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "618\n",
      "[30, 14, 30, 30, 30, 14, 14, 14, 14, 14, 30, 14, 14, 30, 14, 30, 14, 30, 14, 14, 14, 14, 14, 30, 14, 14, 14, 30, 14, 14, 30, 30, 30, 14, 6, 8, 8, 14, 14, 14, 30, 6, 14, 30, 14, 30, 14, 14, 30, 14, 14, 30, 30, 14, 14, 6, 14, 14, 30, 14, 14, 14, 14, 14, 14, 14, 30, 14, 8, 8, 8, 8, 3, 4, 8, 8, 8, 8, 6, 14, 4, 8, 8, 8, 8, 8, 8, 8, 14, 6, 14, 6, 8, 8, 4, 2, 4, 4, 3, 6, 14, 14, 4, 4, 14, 14, 6, 14, 14, 14, 2, 2, 8, 8, 14, 14, 8, 8, 8, 6, 6, 4, 4, 8, 8, 14, 14, 8, 8, 14, 8, 6, 8, 14, 4, 14, 8, 8, 14, 8, 8, 14, 30, 8, 4, 8, 8, 14, 14, 4, 4, 14, 6, 14, 14, 8, 8, 14, 14, 8, 14, 14, 8, 8, 14, 14, 8, 14, 4, 8, 8, 6, 6, 14, 14, 8, 8, 14, 4, 4, 2, 2, 3, 2, 2, 2, 4, 2, 3, 4, 4, 6, 4, 3, 1, 2, 2, 4, 2, 4, 4, 2, 1, 3, 3, 4, 3, 1, 2, 1, 4, 3, 4, 2, 4, 4, 4, 3, 1, 2, 2, 2, 2, 2, 2, 3, 3, 2, 30, 1, 2, 2, 1, 2, 2, 4, 2, 2, 3, 3, 3, 4, 3, 2, 2, 2, 3, 3, 3, 2, 3, 1, 2, 4, 2, 3, 2, 4, 4, 4, 4, 3, 1, 6, 4, 4, 3, 2, 14, 30, 14, 8, 14, 14, 30, 14, 30, 14, 14, 30, 14, 14, 14, 14, 30, 14, 14, 30, 14, 14, 14, 6, 14, 14, 14, 14, 14, 14, 14, 14, 14, 6, 8, 30, 14, 14, 14, 14, 14, 30, 14, 14, 30, 14, 14, 14, 14, 14, 14, 14, 14, 14, 8, 30, 14, 30, 14, 6, 30, 14, 8, 30, 30, 14, 14, 8, 30, 14, 14, 30, 14, 14, 14, 14, 8, 30, 30, 14, 30, 6, 14, 14, 8, 14, 6, 30, 30, 14, 14, 14, 6, 8, 30, 30, 14, 14, 30, 14, 30, 14, 6, 30, 14, 14, 30, 14, 6, 30, 14, 8, 8, 14, 14, 14, 14, 14, 14, 6, 14, 6, 8, 8, 8, 14, 14, 8, 4, 6, 8, 8, 14, 8, 8, 6, 14, 14, 14, 8, 8, 6, 14, 6, 8, 14, 14, 8, 14, 14, 14, 8, 8, 8, 4, 14, 8, 14, 30, 8, 8, 8, 14, 6, 8, 14, 8, 14, 14, 14, 3, 14, 6, 8, 14, 14, 14, 14, 4, 8, 6, 14, 14, 4, 8, 4, 6, 6, 14, 4, 14, 8, 8, 14, 8, 8, 8, 14, 6, 4, 8, 14, 14, 14, 8, 8, 4, 8, 8, 8, 8, 6, 30, 14, 8, 6, 8, 8, 6, 14, 8, 8, 8, 30, 30, 30, 6, 6, 14, 14, 14, 8, 8, 14, 8, 14, 8, 14, 8, 8, 14, 14, 8, 8, 8, 8, 8, 6, 6, 14, 8, 6, 8, 6, 14, 8, 14, 8, 14, 14, 6, 14, 14, 8, 8, 14, 4, 4, 14, 8, 14, 8, 8, 6, 4, 8, 8, 14, 4, 4, 6, 6, 14, 14, 8, 8, 14, 8, 14, 8, 4, 14, 6, 8, 8, 8, 14, 8, 8, 6, 6, 4, 6, 14, 8, 8, 8, 6, 14, 14, 8, 14, 30, 14, 3, 14, 4, 4, 4, 8, 14, 6, 14, 6, 6, 6, 4, 6, 14, 8, 6, 4, 4, 14, 8, 8, 8, 8, 4, 14, 14, 8, 8, 8, 14, 8, 8, 8, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -2100229.60589664             +nan\n",
      "         2 -2043946.39462183  +56283.21127481\n",
      "         3 -2016519.93395459  +27426.46066724\n",
      "         4 -2001806.81812657  +14713.11582802\n",
      "         5 -1997701.78805688   +4105.03006969\n",
      "         6 -1996877.49976359    +824.28829329\n",
      "         7 -1996613.63322689    +263.86653670\n",
      "         8 -1996427.28541274    +186.34781415\n",
      "         9 -1996273.49120909    +153.79420365\n",
      "        10 -1996177.40840467     +96.08280442\n",
      "        11 -1996111.79635517     +65.61204951\n",
      "        12 -1996065.26750924     +46.52884593\n",
      "        13 -1996039.13190789     +26.13560135\n",
      "        14 -1996024.44838520     +14.68352268\n",
      "        15 -1996015.88040158      +8.56798362\n",
      "        16 -1996010.53025340      +5.35014819\n",
      "        17 -1996006.96652900      +3.56372440\n",
      "        18 -1996004.68133297      +2.28519603\n",
      "        19 -1996003.31098858      +1.37034439\n",
      "        20 -1996002.51125299      +0.79973559\n",
      "        21 -1996002.04804394      +0.46320905\n",
      "        22 -1996001.77967488      +0.26836906\n",
      "        23 -1996001.62355953      +0.15611535\n",
      "        24 -1996001.53236426      +0.09119527\n",
      "        25 -1996001.47897983      +0.05338443\n",
      "        26 -1996001.44775932      +0.03122051\n",
      "        27 -1996001.42958417      +0.01817515\n",
      "        28 -1996001.41909664      +0.01048754\n",
      "        29 -1996001.41313104      +0.00596559\n",
      "         1 -1028884.57582289             +nan\n",
      "         2 -1011724.13683086  +17160.43899203\n",
      "         3 -998953.46829967  +12770.66853119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: െ\n",
      "525\n",
      "[14, 8, 8, 14, 6, 6, 6, 6, 8, 14, 30, 14, 30, 8, 14, 30, 30, 14, 8, 8, 14, 6, 8, 14, 8, 8, 14, 14, 30, 8, 8, 8, 8, 14, 8, 14, 8, 8, 8, 6, 4, 6, 6, 14, 8, 8, 6, 8, 4, 4, 3, 3, 6, 8, 8, 8, 8, 14, 14, 6, 8, 8, 14, 14, 14, 4, 8, 6, 6, 8, 6, 14, 8, 4, 4, 8, 8, 8, 6, 4, 4, 4, 6, 6, 6, 6, 8, 8, 8, 14, 6, 8, 14, 14, 4, 6, 14, 14, 6, 8, 14, 6, 6, 8, 6, 8, 2, 4, 14, 30, 14, 8, 6, 3, 3, 4, 8, 6, 6, 4, 14, 14, 8, 6, 6, 8, 14, 8, 14, 6, 2, 4, 6, 6, 8, 14, 14, 6, 8, 6, 8, 4, 4, 4, 2, 2, 1, 1, 2, 3, 2, 1, 3, 3, 2, 4, 2, 3, 1, 1, 3, 2, 2, 3, 2, 2, 4, 3, 2, 2, 2, 4, 1, 2, 2, 1, 3, 2, 4, 3, 3, 2, 2, 4, 3, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 3, 3, 14, 1, 2, 2, 2, 4, 2, 2, 2, 4, 4, 4, 1, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 2, 2, 2, 1, 1, 2, 2, 3, 2, 2, 3, 2, 3, 2, 3, 2, 6, 3, 3, 2, 2, 2, 4, 8, 4, 3, 2, 3, 3, 3, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 3, 2, 1, 2, 1, 1, 6, 4, 3, 4, 2, 2, 3, 6, 6, 14, 8, 14, 8, 6, 6, 6, 14, 14, 14, 6, 6, 8, 8, 30, 30, 14, 14, 6, 6, 4, 8, 8, 14, 8, 30, 14, 6, 6, 6, 6, 4, 4, 6, 14, 6, 14, 6, 6, 6, 6, 6, 6, 30, 4, 4, 6, 8, 4, 6, 6, 14, 14, 8, 6, 4, 4, 4, 4, 4, 4, 8, 14, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 14, 14, 14, 14, 14, 8, 6, 8, 4, 4, 4, 14, 4, 6, 6, 8, 8, 8, 4, 2, 2, 4, 4, 4, 4, 6, 3, 3, 6, 6, 6, 6, 6, 6, 8, 4, 4, 4, 4, 6, 6, 14, 8, 14, 6, 6, 6, 6, 4, 4, 4, 4, 3, 8, 4, 8, 6, 4, 4, 6, 6, 14, 6, 4, 14, 6, 6, 8, 8, 6, 6, 6, 6, 4, 4, 2, 2, 4, 8, 6, 4, 8, 6, 6, 6, 6, 6, 14, 8, 6, 6, 4, 8, 4, 6, 3, 6, 6, 6, 6, 14, 14, 8, 8, 3, 6, 6, 6, 6, 4, 4, 4, 8, 6, 8, 3, 4, 4, 6, 6, 14, 14, 4, 4, 4, 4, 14, 3, 4, 14, 4, 4, 6, 6, 6, 6, 6, 14, 6, 6, 4, 4, 4, 6, 6, 6, 6, 6, 8, 6, 4, 14, 14, 4, 3, 6, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         4 -993030.33061590   +5923.13768377\n",
      "         5 -991925.72427532   +1104.60634057\n",
      "         6 -991402.86846542    +522.85580991\n",
      "         7 -990283.87634806   +1118.99211735\n",
      "         8 -988057.06926462   +2226.80708344\n",
      "         9 -985903.53132100   +2153.53794362\n",
      "        10 -984872.01077573   +1031.52054528\n",
      "        11 -984226.39356856    +645.61720717\n",
      "        12 -983876.52133404    +349.87223451\n",
      "        13 -983700.89415766    +175.62717638\n",
      "        14 -983601.26252816     +99.63162951\n",
      "        15 -983539.55188359     +61.71064456\n",
      "        16 -983514.41516596     +25.13671763\n",
      "        17 -983501.55042672     +12.86473924\n",
      "        18 -983493.07884405      +8.47158267\n",
      "        19 -983485.95303341      +7.12581064\n",
      "        20 -983479.00152627      +6.95150714\n",
      "        21 -983471.33020857      +7.67131770\n",
      "        22 -983466.76658486      +4.56362371\n",
      "        23 -983464.14450196      +2.62208290\n",
      "        24 -983462.64879371      +1.49570825\n",
      "        25 -983461.82377352      +0.82502019\n",
      "        26 -983461.36986744      +0.45390608\n",
      "        27 -983461.11188080      +0.25798664\n",
      "        28 -983460.96115203      +0.15072877\n",
      "        29 -983460.87415826      +0.08699377\n",
      "        30 -983460.82697777      +0.04718049\n",
      "        31 -983460.80396229      +0.02301548\n",
      "        32 -983460.79401401      +0.00994828\n",
      "         1 -435430.59031378             +nan\n",
      "         2 -420802.27637074  +14628.31394303\n",
      "         3 -417771.57473713   +3030.70163362\n",
      "         4 -415502.69863641   +2268.87610072\n",
      "         5 -414533.58758120    +969.11105521\n",
      "         6 -414260.58542588    +273.00215532\n",
      "         7 -414186.39576152     +74.18966436\n",
      "         8 -414135.60751842     +50.78824310\n",
      "         9 -414129.51022993      +6.09728849\n",
      "        10 -414129.66883349      -0.15860356\n",
      "Model is not converging.  Current: -414129.6688334937 is not greater than -414129.5102299305. Delta is -0.15860356320627034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ത\n",
      "102\n",
      "[30, 30, 30, 4, 30, 30, 14, 8, 30, 30, 14, 14, 14, 4, 4, 3, 2, 30, 14, 14, 30, 14, 14, 30, 14, 14, 30, 14, 14, 4, 14, 14, 14, 14, 14, 14, 6, 14, 8, 4, 30, 14, 14, 30, 14, 8, 14, 14, 8, 14, 14, 8, 30, 30, 8, 14, 6, 14, 4, 14, 6, 14, 8, 14, 14, 14, 14, 14, 14, 14, 14, 4, 6, 14, 14, 4, 4, 14, 30, 14, 14, 6, 14, 6, 14, 14, 14, 8, 8, 8, 14, 8, 8, 14, 8, 8, 30, 6, 4, 6, 6, 14]\n",
      "Model trained for character: അ\n",
      "1151\n",
      "[8, 6, 6, 8, 8, 8, 6, 6, 4, 6, 4, 8, 4, 6, 8, 8, 6, 6, 3, 4, 8, 8, 8, 6, 4, 6, 6, 8, 6, 6, 8, 6, 8, 6, 6, 6, 6, 8, 8, 3, 3, 8, 3, 3, 6, 4, 4, 8, 6, 8, 8, 8, 8, 8, 8, 3, 3, 2, 2, 3, 3, 2, 2, 2, 3, 3, 4, 4, 2, 2, 6, 4, 6, 3, 4, 4, 4, 6, 3, 2, 2, 2, 6, 3, 3, 4, 4, 6, 4, 6, 6, 3, 3, 3, 3, 6, 6, 4, 4, 4, 4, 4, 6, 3, 3, 3, 2, 2, 3, 3, 4, 6, 4, 4, 6, 6, 4, 4, 4, 2, 2, 6, 6, 3, 6, 6, 8, 4, 3, 3, 6, 6, 3, 3, 3, 2, 2, 6, 6, 6, 8, 8, 6, 4, 4, 4, 4, 3, 6, 8, 4, 2, 2, 2, 2, 6, 4, 4, 6, 4, 6, 4, 4, 3, 3, 4, 6, 4, 6, 2, 2, 2, 2, 4, 4, 3, 3, 6, 4, 4, 4, 6, 4, 4, 4, 2, 4, 4, 4, 6, 6, 3, 4, 6, 2, 2, 2, 2, 6, 4, 4, 4, 6, 3, 3, 3, 6, 4, 3, 3, 4, 3, 6, 4, 4, 4, 6, 6, 4, 2, 4, 4, 6, 6, 6, 6, 3, 3, 2, 2, 4, 4, 6, 4, 2, 2, 4, 6, 6, 6, 6, 6, 4, 4, 4, 6, 4, 6, 6, 4, 6, 4, 6, 8, 3, 3, 3, 4, 4, 4, 8, 3, 3, 6, 2, 2, 6, 4, 4, 4, 6, 6, 4, 4, 4, 6, 6, 4, 4, 6, 4, 4, 4, 3, 8, 8, 6, 4, 3, 3, 3, 3, 6, 6, 6, 6, 2, 2, 4, 4, 6, 6, 4, 6, 4, 6, 4, 6, 6, 2, 2, 4, 6, 4, 6, 6, 6, 6, 3, 3, 3, 3, 2, 2, 1, 1, 1, 1, 1, 1, 2, 3, 2, 2, 3, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 3, 2, 2, 3, 3, 3, 1, 2, 2, 2, 2, 3, 3, 2, 1, 2, 2, 3, 3, 1, 1, 2, 1, 1, 1, 3, 1, 1, 2, 2, 3, 2, 2, 1, 1, 2, 2, 2, 3, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 1, 3, 6, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 6, 4, 2, 2, 3, 3, 2, 2, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 3, 4, 6, 1, 1, 2, 1, 1, 2, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 6, 2, 2, 2, 3, 2, 2, 3, 3, 2, 1, 1, 2, 2, 6, 2, 1, 1, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 3, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2, 1, 3, 2, 2, 3, 2, 2, 1, 1, 2, 2, 2, 2, 2, 3, 3, 1, 1, 1, 1, 2, 2, 3, 2, 6, 6, 6, 6, 8, 6, 6, 6, 8, 6, 8, 6, 8, 6, 4, 6, 6, 6, 8, 6, 8, 6, 8, 6, 8, 6, 6, 6, 8, 6, 8, 6, 6, 6, 6, 6, 8, 6, 8, 6, 6, 8, 6, 6, 8, 4, 8, 6, 8, 6, 8, 6, 8, 8, 8, 6, 6, 8, 8, 6, 6, 4, 6, 6, 6, 6, 8, 6, 6, 8, 6, 4, 6, 6, 6, 8, 6, 8, 6, 8, 8, 8, 6, 8, 6, 4, 6, 4, 4, 6, 4, 6, 4, 6, 4, 4, 2, 2, 3, 3, 4, 4, 6, 6, 6, 6, 6, 6, 4, 6, 6, 3, 3, 6, 4, 4, 6, 6, 6, 6, 6, 6, 8, 6, 4, 4, 4, 3, 4, 3, 4, 4, 6, 4, 6, 6, 6, 6, 6, 6, 4, 6, 4, 4, 4, 4, 6, 4, 6, 8, 6, 6, 6, 6, 6, 4, 6, 2, 2, 4, 6, 6, 6, 6, 6, 6, 4, 4, 6, 4, 4, 3, 4, 3, 3, 3, 6, 6, 6, 4, 4, 4, 4, 6, 6, 4, 4, 6, 8, 4, 8, 6, 4, 6, 6, 4, 4, 3, 6, 6, 6, 6, 3, 3, 3, 3, 4, 4, 4, 6, 4, 6, 6, 6, 6, 4, 4, 4, 4, 6, 6, 3, 4, 6, 4, 4, 4, 4, 6, 8, 4, 3, 4, 2, 4, 4, 4, 6, 6, 6, 4, 2, 2, 3, 3, 6, 6, 4, 6, 6, 4, 3, 4, 6, 4, 4, 4, 4, 4, 6, 6, 4, 4, 6, 3, 3, 6, 4, 8, 6, 6, 6, 6, 6, 6, 4, 3, 4, 6, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 6, 6, 6, 6, 4, 6, 6, 6, 4, 4, 4, 4, 4, 3, 6, 6, 2, 2, 6, 6, 6, 4, 3, 3, 4, 6, 6, 6, 4, 6, 6, 4, 4, 6, 4, 6, 6, 4, 3, 6, 6, 4, 4, 3, 4, 4, 4, 8, 6, 4, 6, 6, 4, 2, 2, 3, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 3, 4, 4, 4, 6, 6, 3, 3, 6, 6, 6, 4, 4, 4, 4, 4, 4, 6, 6, 4, 4, 6, 6, 6, 4, 4, 3, 2, 2, 3, 6, 6, 6, 6, 3, 3, 6, 4, 6, 6, 6, 4, 4, 6, 6, 4, 3, 8, 4, 4, 6, 2, 2, 3, 6, 8, 6, 6, 4, 6, 4, 8, 3, 4, 6, 6, 6, 6, 4, 4, 4, 3, 6, 6, 4, 6, 4, 6, 4, 4, 4, 6, 6, 4, 4, 6, 6, 6, 6, 6, 8, 6, 6, 4, 4, 6, 3, 4, 6, 8, 6, 3, 4, 4, 6, 6, 6, 6, 6, 4, 4, 3, 4, 4, 4, 3, 3, 2, 2, 2, 2, 4, 6, 3, 3, 3, 4, 4, 4, 4, 4, 6, 4, 4, 6, 4, 2, 2, 6, 6, 8, 3, 6, 6, 3, 3, 6, 6, 6, 4, 4, 6, 6, 6, 4, 4, 4, 2, 2, 4, 6, 6, 6, 4, 4, 6, 6, 6, 4, 6, 4, 3, 6, 4, 2, 2, 6, 2, 3, 4, 3, 3, 6, 2, 2, 4, 4, 4, 4, 6, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -1496643.44803974             +nan\n",
      "         2 -1452492.41723017  +44151.03080956\n",
      "         3 -1439579.44256539  +12912.97466478\n",
      "         4 -1436578.18551846   +3001.25704693\n",
      "         5 -1434681.99369870   +1896.19181976\n",
      "         6 -1433874.34306166    +807.65063704\n",
      "         7 -1433535.27969112    +339.06337054\n",
      "         8 -1433264.94788472    +270.33180640\n",
      "         9 -1432905.15438098    +359.79350374\n",
      "        10 -1432489.60158813    +415.55279285\n",
      "        11 -1431892.38937693    +597.21221120\n",
      "        12 -1431328.68192407    +563.70745286\n",
      "        13 -1431027.52666180    +301.15526227\n",
      "        14 -1430878.57009568    +148.95656611\n",
      "        15 -1430832.45926128     +46.11083440\n",
      "        16 -1430806.26437891     +26.19488237\n",
      "        17 -1430786.65023231     +19.61414659\n",
      "        18 -1430772.02441264     +14.62581968\n",
      "        19 -1430760.38610590     +11.63830674\n",
      "        20 -1430754.61712677      +5.76897912\n",
      "        21 -1430751.49020163      +3.12692514\n",
      "        22 -1430749.38690297      +2.10329866\n",
      "        23 -1430747.76443353      +1.62246944\n",
      "        24 -1430746.43521407      +1.32921946\n",
      "        25 -1430745.32723932      +1.10797476\n",
      "        26 -1430744.43959782      +0.88764150\n",
      "        27 -1430743.81820107      +0.62139675\n",
      "        28 -1430743.49305382      +0.32514724\n",
      "        29 -1430743.27360155      +0.21945227\n",
      "        30 -1430742.54482321      +0.72877834\n",
      "        31 -1430741.41208219      +1.13274102\n",
      "        32 -1430740.28265867      +1.12942352\n",
      "        33 -1430739.23482294      +1.04783573\n",
      "        34 -1430738.25630420      +0.97851875\n",
      "        35 -1430737.32433519      +0.93196901\n",
      "        36 -1430736.41765362      +0.90668156\n",
      "        37 -1430735.51975663      +0.89789700\n",
      "        38 -1430734.61890526      +0.90085136\n",
      "        39 -1430733.70440490      +0.91450037\n",
      "        40 -1430732.76072879      +0.94367610\n",
      "        41 -1430731.76272004      +0.99800876\n",
      "        42 -1430730.67661131      +1.08610873\n",
      "        43 -1430729.47558805      +1.20102326\n",
      "        44 -1430728.16089138      +1.31469667\n",
      "        45 -1430726.74386017      +1.41703120\n",
      "        46 -1430725.21649966      +1.52736051\n",
      "        47 -1430723.57367672      +1.64282295\n",
      "        48 -1430721.83766442      +1.73601229\n",
      "        49 -1430720.03102554      +1.80663888\n",
      "        50 -1430718.15295665      +1.87806889\n",
      "        51 -1430716.16340691      +1.98954974\n",
      "        52 -1430713.90955745      +2.25384946\n",
      "        53 -1430711.47698103      +2.43257642\n",
      "        54 -1430709.38863097      +2.08835006\n",
      "        55 -1430707.47123314      +1.91739783\n",
      "        56 -1430705.53901988      +1.93221326\n",
      "        57 -1430703.51772883      +2.02129105\n",
      "        58 -1430700.68031299      +2.83741584\n",
      "        59 -1430697.40191602      +3.27839697\n",
      "        60 -1430695.82561936      +1.57629666\n",
      "        61 -1430694.70532183      +1.12029753\n",
      "        62 -1430693.80932516      +0.89599667\n",
      "        63 -1430693.10737399      +0.70195117\n",
      "        64 -1430692.56374457      +0.54362941\n",
      "        65 -1430692.14490633      +0.41883824\n",
      "        66 -1430691.82287840      +0.32202793\n",
      "        67 -1430691.57535772      +0.24752068\n",
      "        68 -1430691.38495541      +0.19040231\n",
      "        69 -1430691.23827690      +0.14667851\n",
      "        70 -1430691.12507263      +0.11320427\n",
      "        71 -1430691.03752476      +0.08754787\n",
      "        72 -1430690.96967594      +0.06784881\n",
      "        73 -1430690.91698426      +0.05269169\n",
      "        74 -1430690.87598175      +0.04100251\n",
      "        75 -1430690.84401504      +0.03196671\n",
      "        76 -1430690.81904913      +0.02496591\n",
      "        77 -1430690.79951932      +0.01952981\n",
      "        78 -1430690.78421941      +0.01529991\n",
      "        79 -1430690.77221720      +0.01200221\n",
      "        80 -1430690.76279055      +0.00942665\n",
      "         1 -2178308.52977576             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ്\n",
      "987\n",
      "[14, 8, 14, 14, 14, 14, 30, 14, 30, 14, 30, 30, 14, 6, 14, 14, 30, 6, 30, 14, 6, 14, 14, 30, 14, 30, 14, 30, 14, 14, 14, 14, 30, 30, 30, 30, 14, 2, 8, 14, 8, 8, 4, 2, 6, 4, 8, 8, 6, 6, 8, 6, 8, 8, 6, 3, 8, 8, 6, 4, 8, 14, 6, 8, 6, 4, 6, 6, 6, 6, 6, 8, 4, 8, 6, 8, 8, 8, 8, 8, 8, 8, 6, 8, 4, 8, 8, 8, 3, 6, 3, 8, 8, 8, 8, 30, 14, 8, 14, 6, 8, 6, 8, 8, 8, 30, 14, 8, 8, 6, 8, 8, 4, 8, 8, 8, 2, 2, 8, 8, 6, 8, 8, 14, 30, 3, 6, 4, 8, 8, 4, 6, 2, 4, 4, 6, 8, 8, 8, 8, 6, 4, 8, 6, 6, 2, 2, 4, 6, 8, 3, 8, 8, 8, 8, 2, 8, 6, 8, 6, 6, 8, 8, 8, 6, 8, 8, 8, 14, 14, 14, 8, 6, 4, 6, 14, 6, 6, 6, 8, 4, 4, 4, 8, 6, 8, 2, 6, 8, 14, 8, 14, 4, 8, 14, 6, 6, 2, 4, 8, 6, 6, 6, 6, 14, 8, 8, 8, 8, 8, 8, 14, 8, 8, 4, 8, 14, 4, 8, 6, 8, 8, 8, 8, 8, 14, 6, 6, 8, 8, 8, 8, 4, 8, 8, 8, 8, 6, 3, 14, 3, 8, 6, 8, 6, 14, 4, 4, 8, 8, 30, 6, 8, 8, 14, 4, 14, 4, 3, 8, 8, 14, 8, 8, 8, 8, 8, 6, 8, 8, 30, 6, 6, 2, 4, 14, 8, 8, 8, 8, 14, 6, 14, 4, 14, 14, 8, 8, 14, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 14, 14, 14, 8, 8, 14, 6, 8, 8, 14, 6, 3, 4, 4, 3, 3, 3, 2, 3, 3, 3, 4, 1, 2, 4, 4, 4, 3, 3, 2, 2, 1, 2, 4, 4, 4, 4, 4, 4, 3, 4, 3, 2, 2, 1, 2, 2, 2, 3, 2, 2, 1, 1, 3, 3, 2, 2, 2, 3, 3, 2, 3, 3, 4, 6, 3, 3, 2, 2, 2, 1, 3, 2, 3, 3, 4, 3, 2, 2, 4, 3, 3, 3, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 3, 2, 2, 2, 2, 2, 4, 3, 2, 2, 1, 2, 2, 2, 2, 2, 3, 3, 4, 4, 4, 3, 6, 3, 2, 1, 1, 2, 2, 3, 3, 4, 4, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 3, 4, 3, 2, 2, 4, 3, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 6, 6, 1, 2, 2, 2, 1, 2, 2, 4, 4, 6, 6, 6, 8, 2, 3, 3, 3, 2, 2, 3, 4, 4, 4, 3, 1, 2, 2, 2, 2, 2, 2, 1, 3, 1, 2, 2, 6, 2, 6, 4, 2, 2, 6, 2, 2, 2, 3, 6, 14, 3, 3, 2, 3, 1, 1, 1, 2, 2, 4, 4, 6, 2, 6, 8, 4, 2, 4, 6, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 2, 3, 1, 1, 3, 3, 4, 4, 4, 4, 4, 4, 2, 3, 1, 1, 2, 2, 3, 3, 2, 2, 4, 4, 4, 4, 4, 2, 2, 2, 2, 2, 3, 2, 2, 3, 1, 2, 2, 2, 2, 3, 3, 4, 3, 3, 3, 2, 3, 3, 2, 4, 4, 4, 3, 3, 4, 2, 2, 6, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 2, 2, 2, 3, 2, 14, 30, 8, 14, 14, 14, 14, 14, 14, 8, 8, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 8, 14, 6, 6, 6, 14, 14, 14, 6, 14, 8, 14, 14, 14, 4, 14, 4, 4, 4, 6, 8, 8, 8, 6, 6, 6, 8, 6, 14, 6, 6, 8, 14, 8, 8, 8, 14, 8, 8, 14, 14, 8, 4, 8, 8, 8, 8, 8, 14, 8, 14, 8, 3, 8, 6, 6, 4, 6, 8, 14, 8, 6, 4, 6, 8, 4, 14, 8, 14, 8, 8, 14, 14, 14, 14, 14, 14, 30, 14, 8, 8, 14, 8, 6, 8, 6, 6, 8, 14, 30, 6, 14, 8, 8, 8, 8, 8, 4, 4, 6, 30, 14, 14, 14, 8, 8, 8, 8, 8, 8, 6, 4, 4, 4, 8, 14, 6, 6, 8, 8, 8, 8, 14, 6, 8, 6, 6, 8, 14, 3, 14, 14, 14, 14, 6, 8, 8, 4, 14, 8, 8, 8, 4, 8, 8, 6, 8, 14, 8, 8, 8, 6, 14, 8, 8, 4, 14, 8, 2, 8, 8, 8, 8, 8, 4, 4, 3, 4, 8, 8, 8, 8, 4, 8, 8, 4, 8, 8, 8, 8, 8, 14, 8, 8, 8, 8, 6, 6, 14, 14, 8, 8, 8, 8, 6, 6, 8, 4, 6, 8, 8, 4, 4, 4, 8, 8, 8, 14, 8, 6, 8, 8, 8, 6, 14, 14, 8, 4, 4, 4, 8, 6, 2, 8, 8, 8, 14, 8, 14, 8, 8, 8, 14, 30, 6, 8, 6, 8, 6, 6, 14, 6, 8, 14, 4, 14, 8, 8, 6, 4, 8, 4, 6, 14, 14, 14, 8, 14, 8, 8, 8, 14, 8, 8, 14, 4, 14, 14, 4, 4, 14, 8, 8, 6, 6, 14, 8, 6, 4, 6, 8, 8, 8, 6, 6, 8, 8, 8, 8, 6, 2, 30, 6, 14, 8, 8, 4, 8, 8, 6, 6, 4, 8, 6, 6, 6, 8, 6, 8, 6, 8, 8, 8, 14, 30, 8, 8, 8, 14, 8, 30, 8, 4, 2, 3, 3, 8, 8, 6, 8, 6, 8, 8, 14, 8, 8, 8, 14, 6, 2, 6, 2, 4, 8, 14, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2 -2109637.67868782  +68670.85108794\n",
      "         3 -2089117.93586617  +20519.74282165\n",
      "         4 -2087756.99498196   +1360.94088421\n",
      "         5 -2086603.75057407   +1153.24440788\n",
      "         6 -2085410.49004080   +1193.26053328\n",
      "         7 -2084475.90039877    +934.58964203\n",
      "         8 -2083864.79207618    +611.10832259\n",
      "         9 -2083606.69308281    +258.09899337\n",
      "        10 -2083511.73119194     +94.96189087\n",
      "        11 -2083442.45855072     +69.27264122\n",
      "        12 -2083376.29926252     +66.15928820\n",
      "        13 -2083302.44271089     +73.85655164\n",
      "        14 -2083222.36182794     +80.08088295\n",
      "        15 -2083132.62700209     +89.73482585\n",
      "        16 -2082995.75148067    +136.87552142\n",
      "        17 -2082799.25939659    +196.49208408\n",
      "        18 -2082611.31439125    +187.94500533\n",
      "        19 -2082368.23711865    +243.07727260\n",
      "        20 -2081707.58130322    +660.65581543\n",
      "        21 -2080507.61238196   +1199.96892126\n",
      "        22 -2079231.23519804   +1276.37718392\n",
      "        23 -2078618.99891430    +612.23628374\n",
      "        24 -2078030.28362830    +588.71528600\n",
      "        25 -2077432.29244179    +597.99118650\n",
      "        26 -2077296.54248922    +135.74995258\n",
      "        27 -2077199.95678169     +96.58570753\n",
      "        28 -2077091.80970396    +108.14707773\n",
      "        29 -2077048.02414390     +43.78556006\n",
      "        30 -2077004.94269589     +43.08144801\n",
      "        31 -2076960.65576383     +44.28693206\n",
      "        32 -2076933.44661539     +27.20914844\n",
      "        33 -2076916.98295861     +16.46365679\n",
      "        34 -2076910.36307969      +6.61987891\n",
      "        35 -2076907.24632723      +3.11675246\n",
      "        36 -2076904.49739577      +2.74893146\n",
      "        37 -2076901.80326682      +2.69412896\n",
      "        38 -2076899.62254927      +2.18071755\n",
      "        39 -2076897.99019875      +1.63235052\n",
      "        40 -2076891.36757494      +6.62262381\n",
      "        41 -2076874.23093037     +17.13664457\n",
      "        42 -2076849.86094267     +24.36998770\n",
      "        43 -2076794.25874894     +55.60219373\n",
      "        44 -2076738.79756283     +55.46118612\n",
      "        45 -2076718.80558506     +19.99197777\n",
      "        46 -2076710.23683778      +8.56874728\n",
      "        47 -2076705.61130894      +4.62552884\n",
      "        48 -2076703.30862902      +2.30267993\n",
      "        49 -2076702.24377410      +1.06485492\n",
      "        50 -2076701.73491982      +0.50885428\n",
      "        51 -2076701.48060598      +0.25431385\n",
      "        52 -2076701.34884645      +0.13175952\n",
      "        53 -2076701.27867623      +0.07017022\n",
      "        54 -2076701.24052237      +0.03815386\n",
      "        55 -2076701.21945194      +0.02107042\n",
      "        56 -2076701.20768003      +0.01177191\n",
      "        57 -2076701.20104596      +0.00663407\n",
      "         1 -1348758.68159888             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ാ\n",
      "713\n",
      "[30, 30, 6, 6, 6, 4, 8, 8, 14, 14, 4, 6, 14, 6, 6, 3, 14, 8, 14, 8, 4, 2, 8, 8, 2, 8, 8, 8, 8, 6, 8, 8, 6, 6, 6, 6, 8, 6, 6, 3, 3, 2, 14, 8, 4, 4, 8, 8, 4, 14, 14, 3, 2, 6, 8, 6, 6, 8, 6, 8, 4, 4, 4, 8, 6, 14, 6, 6, 4, 8, 8, 8, 8, 6, 14, 2, 4, 6, 8, 8, 8, 6, 4, 4, 8, 6, 8, 8, 8, 6, 6, 8, 8, 6, 8, 8, 4, 3, 6, 8, 2, 8, 6, 2, 6, 8, 4, 8, 8, 6, 6, 8, 8, 8, 8, 3, 4, 6, 6, 6, 8, 14, 8, 8, 14, 2, 6, 4, 6, 6, 6, 6, 6, 4, 4, 4, 6, 8, 8, 4, 4, 8, 8, 14, 6, 8, 14, 4, 2, 4, 6, 14, 6, 4, 14, 3, 3, 6, 6, 8, 4, 4, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 3, 4, 1, 1, 2, 3, 3, 2, 2, 4, 4, 2, 2, 3, 3, 6, 4, 4, 2, 1, 1, 2, 2, 2, 3, 1, 2, 3, 1, 3, 3, 2, 3, 2, 2, 3, 2, 1, 2, 1, 1, 1, 3, 3, 2, 2, 3, 4, 3, 2, 2, 2, 4, 3, 3, 4, 3, 1, 1, 1, 2, 1, 1, 4, 2, 2, 2, 2, 2, 4, 2, 2, 3, 6, 3, 2, 2, 3, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 1, 3, 14, 2, 2, 2, 4, 3, 2, 2, 2, 1, 1, 2, 2, 4, 2, 2, 2, 2, 1, 2, 3, 2, 2, 2, 3, 2, 3, 6, 2, 2, 2, 1, 1, 1, 1, 2, 2, 4, 3, 2, 3, 2, 2, 2, 1, 1, 2, 2, 3, 3, 1, 1, 1, 2, 3, 4, 1, 2, 2, 3, 2, 3, 2, 3, 1, 1, 3, 2, 2, 2, 2, 3, 3, 3, 3, 2, 3, 4, 6, 1, 2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 6, 8, 14, 30, 8, 8, 14, 6, 30, 30, 14, 6, 14, 14, 30, 6, 14, 6, 30, 14, 14, 14, 14, 6, 6, 6, 6, 14, 14, 14, 8, 14, 14, 8, 14, 30, 14, 30, 6, 8, 30, 14, 14, 30, 8, 14, 14, 8, 14, 8, 30, 14, 14, 8, 14, 14, 30, 8, 14, 4, 14, 14, 8, 14, 8, 14, 14, 6, 8, 6, 14, 6, 14, 14, 14, 8, 8, 14, 6, 6, 4, 8, 8, 8, 14, 14, 6, 6, 8, 14, 14, 8, 14, 14, 14, 8, 8, 14, 4, 6, 14, 14, 6, 8, 14, 14, 14, 14, 8, 14, 8, 8, 8, 8, 4, 6, 4, 8, 6, 4, 4, 4, 2, 6, 8, 8, 8, 4, 4, 6, 8, 8, 4, 3, 3, 4, 8, 6, 8, 6, 6, 6, 8, 8, 8, 8, 4, 6, 2, 6, 8, 8, 6, 6, 6, 6, 6, 14, 8, 6, 6, 8, 3, 3, 3, 8, 4, 4, 6, 6, 8, 8, 6, 4, 14, 4, 4, 3, 4, 4, 8, 4, 8, 8, 8, 8, 8, 8, 6, 8, 8, 14, 3, 6, 8, 8, 14, 14, 8, 4, 2, 14, 8, 8, 6, 4, 4, 3, 4, 4, 6, 4, 4, 8, 4, 4, 3, 3, 3, 4, 6, 14, 4, 4, 8, 4, 3, 6, 8, 6, 4, 4, 6, 6, 8, 3, 8, 8, 4, 4, 8, 4, 4, 2, 3, 6, 4, 4, 8, 4, 3, 8, 4, 4, 8, 6, 6, 3, 3, 3, 3, 6, 4, 8, 4, 8, 8, 4, 8, 4, 4, 8, 8, 4, 3, 6, 6, 8, 8, 6, 6, 6, 4, 4, 3, 6, 6, 6, 6, 2, 2, 6, 4, 8, 4, 3, 6, 6, 6, 6, 6, 4, 6, 8, 4, 6, 6, 6, 6, 6, 8, 3, 4, 4, 8, 8, 3, 4, 4, 8, 2, 2, 8, 6, 6, 8, 8, 6, 3, 3, 6, 4, 6, 4, 6, 4, 6, 2, 4, 4, 8, 8, 8, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2 -1319442.61436444  +29316.06723444\n",
      "         3 -1307016.20526576  +12426.40909868\n",
      "         4 -1298503.29611626   +8512.90914950\n",
      "         5 -1295913.52580123   +2589.77031503\n",
      "         6 -1295248.69601783    +664.82978339\n",
      "         7 -1295057.59921502    +191.09680281\n",
      "         8 -1294966.83661467     +90.76260036\n",
      "         9 -1294938.26301681     +28.57359785\n",
      "        10 -1294922.59472470     +15.66829211\n",
      "        11 -1294909.90800662     +12.68671808\n",
      "        12 -1294891.26636419     +18.64164243\n",
      "        13 -1294883.46738492      +7.79897926\n",
      "        14 -1294880.21439711      +3.25298782\n",
      "        15 -1294877.68178192      +2.53261519\n",
      "        16 -1294876.18805216      +1.49372976\n",
      "        17 -1294875.54527998      +0.64277218\n",
      "        18 -1294875.28352467      +0.26175531\n",
      "        19 -1294875.17847952      +0.10504515\n",
      "        20 -1294875.13754470      +0.04093482\n",
      "        21 -1294875.12268934      +0.01485536\n",
      "        22 -1294875.11822040      +0.00446894\n",
      "         1 -719732.08655227             +nan\n",
      "         2 -706970.86049856  +12761.22605371\n",
      "         3 -692904.30759681  +14066.55290175\n",
      "         4 -688234.36971279   +4669.93788402\n",
      "         5 -687136.58488861   +1097.78482418\n",
      "         6 -686727.48287607    +409.10201254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ി\n",
      "334\n",
      "[30, 14, 30, 30, 4, 4, 6, 6, 8, 8, 14, 30, 8, 2, 8, 8, 3, 4, 2, 4, 8, 3, 4, 3, 4, 3, 30, 14, 8, 14, 14, 14, 14, 6, 4, 14, 14, 14, 3, 3, 6, 8, 4, 4, 4, 8, 4, 4, 8, 6, 6, 6, 4, 4, 4, 6, 14, 6, 2, 4, 14, 14, 14, 6, 6, 6, 14, 14, 3, 8, 14, 8, 4, 6, 8, 14, 8, 14, 30, 4, 4, 1, 1, 3, 4, 2, 1, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 1, 2, 4, 3, 3, 3, 2, 1, 2, 2, 1, 2, 2, 2, 3, 3, 14, 2, 2, 2, 2, 4, 4, 2, 1, 2, 2, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 4, 4, 6, 2, 2, 3, 1, 2, 2, 2, 2, 6, 4, 2, 3, 1, 1, 1, 2, 3, 2, 1, 2, 1, 3, 1, 6, 4, 2, 4, 4, 2, 4, 3, 4, 4, 4, 6, 2, 2, 2, 3, 1, 1, 8, 14, 6, 8, 6, 30, 8, 8, 14, 30, 14, 14, 8, 14, 14, 14, 14, 30, 14, 14, 14, 14, 8, 8, 8, 8, 4, 4, 6, 6, 4, 4, 2, 4, 8, 14, 6, 8, 4, 6, 6, 8, 8, 8, 8, 14, 8, 14, 8, 14, 14, 8, 14, 4, 6, 2, 30, 14, 8, 8, 8, 14, 6, 6, 8, 4, 14, 6, 14, 14, 8, 6, 6, 8, 14, 8, 8, 14, 8, 6, 4, 3, 3, 4, 8, 4, 4, 6, 6, 3, 3, 4, 8, 14, 14, 8, 4, 4, 8, 4, 8, 14, 2, 8, 14, 8, 4, 14, 6, 3, 14, 8, 14, 14, 8, 14, 30, 8, 8, 14, 4, 3, 4, 4, 6, 14, 8, 4, 4, 3, 3, 2, 2, 2, 2, 2, 6, 4, 4, 8, 8, 8, 6, 6, 6, 6, 4, 4, 6, 8, 6, 3, 2, 14, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         7 -686510.80151833    +216.68135774\n",
      "         8 -686387.03331175    +123.76820658\n",
      "         9 -686327.68256012     +59.35075163\n",
      "        10 -686286.27862476     +41.40393536\n",
      "        11 -686253.55884829     +32.71977646\n",
      "        12 -686216.80774484     +36.75110345\n",
      "        13 -686155.46915953     +61.33858532\n",
      "        14 -686109.77148535     +45.69767418\n",
      "        15 -686085.74330634     +24.02817901\n",
      "        16 -686075.64152954     +10.10177680\n",
      "        17 -686069.41318003      +6.22834951\n",
      "        18 -686057.90944184     +11.50373820\n",
      "        19 -686036.35437333     +21.55506850\n",
      "        20 -686013.01635534     +23.33801800\n",
      "        21 -686004.04380623      +8.97254910\n",
      "        22 -686002.04877303      +1.99503320\n",
      "        23 -686001.40545342      +0.64331961\n",
      "        24 -686001.21095197      +0.19450145\n",
      "        25 -686001.14979659      +0.06115538\n",
      "        26 -686001.00264093      +0.14715566\n",
      "        27 -686000.53109266      +0.47154827\n",
      "        28 -686000.13443545      +0.39665720\n",
      "        29 -686000.45740061      -0.32296516\n",
      "Model is not converging.  Current: -686000.4574006114 is not greater than -686000.1344354536. Delta is -0.32296515780035406\n",
      "         1 -943253.33805781             +nan\n",
      "         2 -914652.43291049  +28600.90514732\n",
      "         3 -906567.37835468   +8085.05455581\n",
      "         4 -903031.97855658   +3535.39979811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: പ\n",
      "428\n",
      "[14, 14, 14, 14, 14, 3, 4, 14, 14, 14, 14, 2, 4, 6, 4, 4, 4, 6, 8, 6, 2, 3, 6, 8, 3, 3, 3, 4, 14, 4, 4, 4, 4, 2, 2, 6, 8, 8, 8, 3, 3, 3, 8, 8, 6, 6, 4, 4, 4, 4, 6, 4, 6, 6, 8, 8, 8, 14, 6, 4, 4, 3, 3, 3, 3, 14, 6, 4, 8, 8, 8, 6, 4, 4, 6, 4, 4, 2, 2, 6, 8, 6, 4, 4, 4, 4, 6, 6, 3, 4, 8, 4, 4, 6, 6, 4, 2, 2, 8, 6, 6, 6, 6, 4, 4, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 6, 6, 30, 8, 14, 14, 14, 30, 3, 3, 3, 3, 3, 6, 6, 2, 2, 6, 8, 30, 30, 4, 8, 8, 6, 8, 8, 8, 8, 6, 6, 8, 4, 2, 2, 2, 2, 4, 4, 4, 4, 8, 14, 8, 8, 8, 6, 8, 8, 14, 8, 14, 6, 8, 8, 6, 6, 8, 8, 6, 6, 3, 3, 3, 4, 2, 1, 2, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 3, 6, 3, 2, 2, 2, 3, 4, 2, 2, 8, 2, 2, 2, 2, 2, 1, 2, 4, 6, 2, 2, 3, 1, 1, 1, 1, 2, 4, 1, 1, 1, 2, 3, 2, 2, 2, 1, 2, 14, 6, 14, 6, 14, 8, 30, 14, 14, 14, 14, 6, 4, 4, 4, 14, 6, 30, 14, 14, 14, 6, 14, 14, 14, 6, 14, 14, 14, 8, 8, 14, 14, 14, 14, 14, 14, 14, 6, 14, 30, 14, 6, 14, 14, 14, 14, 14, 14, 8, 8, 8, 8, 6, 6, 8, 8, 14, 6, 14, 14, 14, 14, 8, 6, 6, 4, 4, 8, 8, 8, 14, 8, 8, 4, 8, 8, 6, 8, 8, 8, 6, 8, 4, 4, 14, 14, 8, 8, 8, 4, 8, 8, 8, 14, 4, 14, 6, 8, 14, 8, 8, 6, 14, 8, 4, 4, 8, 8, 8, 6, 6, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 14, 8, 8, 8, 8, 8, 8, 8, 8, 3, 8, 8, 8, 8, 8, 4, 8, 14, 3, 6, 6, 6, 8, 8, 8, 14, 14, 8, 6, 8, 8, 14, 14, 8, 8, 8, 14, 14, 6, 6, 14, 8, 4, 4, 6, 6, 14, 14, 4, 8, 8, 14, 6, 4, 6, 6, 6, 8, 8, 3, 4, 6, 8, 3, 3, 8, 8, 14, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         5 -901275.69866698   +1756.27988959\n",
      "         6 -900314.30476274    +961.39390424\n",
      "         7 -900187.98947074    +126.31529200\n",
      "         8 -900132.84323091     +55.14623983\n",
      "         9 -900097.14541793     +35.69781298\n",
      "        10 -900075.78189165     +21.36352628\n",
      "        11 -900063.39394053     +12.38795112\n",
      "        12 -900057.39058359      +6.00335695\n",
      "        13 -900058.56194221      -1.17135862\n",
      "Model is not converging.  Current: -900058.5619422086 is not greater than -900057.3905835856. Delta is -1.171358622959815\n",
      "         1 -1373514.80696489             +nan\n",
      "         2 -1345436.03560222  +28078.77136267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: റ\n",
      "658\n",
      "[14, 14, 8, 6, 6, 4, 8, 14, 14, 6, 8, 8, 14, 8, 4, 8, 6, 8, 14, 14, 3, 2, 3, 2, 2, 3, 4, 4, 2, 6, 4, 8, 3, 2, 2, 3, 3, 3, 4, 8, 8, 6, 8, 8, 3, 8, 14, 4, 4, 4, 6, 8, 3, 3, 2, 3, 4, 6, 4, 4, 6, 3, 6, 6, 6, 14, 3, 3, 2, 4, 4, 4, 2, 2, 6, 8, 6, 4, 4, 14, 6, 4, 6, 14, 6, 8, 2, 2, 4, 4, 4, 4, 2, 8, 14, 8, 6, 4, 3, 3, 6, 6, 8, 8, 8, 4, 4, 4, 6, 6, 4, 4, 4, 4, 4, 6, 6, 3, 3, 2, 2, 4, 8, 14, 6, 4, 2, 14, 8, 14, 14, 14, 6, 6, 6, 8, 6, 8, 4, 6, 8, 14, 6, 6, 4, 8, 8, 14, 4, 4, 6, 6, 14, 6, 14, 14, 3, 3, 3, 3, 6, 6, 8, 8, 6, 6, 14, 8, 8, 8, 4, 6, 8, 6, 6, 2, 8, 8, 6, 8, 14, 8, 14, 3, 3, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 3, 3, 4, 1, 2, 2, 2, 1, 1, 1, 1, 1, 4, 3, 2, 2, 4, 3, 2, 2, 2, 2, 4, 4, 3, 2, 2, 2, 1, 2, 2, 4, 2, 1, 1, 4, 2, 2, 2, 2, 1, 2, 2, 2, 2, 3, 3, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 6, 2, 2, 6, 4, 2, 4, 4, 3, 4, 2, 2, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 6, 2, 2, 3, 3, 3, 6, 3, 4, 4, 6, 14, 1, 1, 1, 2, 2, 4, 2, 3, 3, 2, 2, 2, 1, 2, 6, 3, 3, 2, 2, 3, 1, 3, 1, 3, 2, 3, 2, 2, 1, 2, 3, 2, 4, 2, 2, 2, 2, 3, 1, 1, 2, 2, 3, 6, 14, 14, 6, 14, 6, 6, 30, 14, 30, 14, 14, 30, 14, 14, 14, 8, 8, 30, 14, 8, 30, 14, 8, 30, 14, 14, 14, 6, 14, 14, 14, 8, 14, 14, 6, 14, 14, 14, 14, 14, 14, 4, 8, 14, 8, 14, 14, 14, 14, 3, 4, 4, 14, 14, 8, 6, 6, 8, 8, 8, 8, 6, 4, 6, 8, 8, 8, 8, 8, 8, 14, 14, 8, 14, 8, 8, 8, 6, 4, 8, 14, 14, 8, 8, 14, 8, 14, 8, 4, 6, 8, 14, 14, 8, 14, 8, 6, 14, 14, 14, 14, 8, 8, 6, 6, 8, 4, 30, 14, 8, 6, 6, 8, 8, 8, 14, 6, 8, 3, 8, 6, 6, 14, 8, 4, 4, 6, 6, 3, 6, 6, 14, 14, 14, 8, 8, 14, 14, 4, 14, 4, 6, 6, 14, 14, 8, 4, 6, 6, 6, 14, 8, 14, 8, 4, 6, 8, 6, 6, 6, 4, 3, 14, 8, 8, 8, 6, 4, 8, 6, 4, 8, 6, 14, 8, 8, 14, 30, 8, 6, 6, 8, 8, 14, 30, 6, 4, 4, 4, 4, 8, 3, 6, 6, 2, 30, 14, 8, 14, 8, 8, 8, 6, 14, 4, 3, 3, 30, 6, 4, 4, 4, 14, 8, 8, 4, 3, 6, 8, 14, 6, 8, 6, 4, 8, 8, 8, 8, 8, 8, 8, 14, 3, 6, 14, 14, 14, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 8, 8, 4, 6, 6, 3, 6, 4, 4, 8, 8, 4, 6, 6, 4, 8, 8, 8, 14, 8, 2, 6, 8, 6, 4, 3, 3, 6, 6, 4, 6, 4, 4, 6, 6, 6, 8, 8, 14, 6, 6, 6, 6, 8, 8, 14, 6, 8, 8, 8, 14, 14, 3, 4, 6, 4, 2, 8, 6, 8, 6, 14, 8, 6, 4, 4, 6, 14, 14, 14, 3, 6, 2, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         3 -1334848.24600653  +10587.78959569\n",
      "         4 -1330924.38080819   +3923.86519834\n",
      "         5 -1326916.33415680   +4008.04665138\n",
      "         6 -1323939.06618255   +2977.26797425\n",
      "         7 -1322946.37137742    +992.69480513\n",
      "         8 -1322658.85667348    +287.51470395\n",
      "         9 -1322539.75082144    +119.10585204\n",
      "        10 -1322475.07380990     +64.67701153\n",
      "        11 -1322426.54136088     +48.53244902\n",
      "        12 -1322402.27448070     +24.26688019\n",
      "        13 -1322392.15130848     +10.12317222\n",
      "        14 -1322384.96122373      +7.19008474\n",
      "        15 -1322378.18568961      +6.77553413\n",
      "        16 -1322354.29254366     +23.89314594\n",
      "        17 -1322211.83722034    +142.45532332\n",
      "        18 -1322103.54787816    +108.28934218\n",
      "        19 -1322063.81038448     +39.73749368\n",
      "        20 -1322027.82724829     +35.98313618\n",
      "        21 -1321976.42448412     +51.40276417\n",
      "        22 -1321936.44877744     +39.97570668\n",
      "        23 -1321914.63120621     +21.81757123\n",
      "        24 -1321898.26327029     +16.36793592\n",
      "        25 -1321883.47269192     +14.79057837\n",
      "        26 -1321867.33280161     +16.13989031\n",
      "        27 -1321848.07902414     +19.25377748\n",
      "        28 -1321825.66229214     +22.41673199\n",
      "        29 -1321800.10049256     +25.56179958\n",
      "        30 -1321777.66480502     +22.43568754\n",
      "        31 -1321757.35389401     +20.31091102\n",
      "        32 -1321736.64161734     +20.71227666\n",
      "        33 -1321717.78117595     +18.86044140\n",
      "        34 -1321702.73810984     +15.04306611\n",
      "        35 -1321693.25401078      +9.48409905\n",
      "        36 -1321687.91553913      +5.33847165\n",
      "        37 -1321684.47663204      +3.43890709\n",
      "        38 -1321682.12369695      +2.35293509\n",
      "        39 -1321680.53957507      +1.58412188\n",
      "        40 -1321679.48523411      +1.05434096\n",
      "        41 -1321678.78952362      +0.69571049\n",
      "        42 -1321678.33417527      +0.45534835\n",
      "        43 -1321678.03588286      +0.29829241\n",
      "        44 -1321677.83841588      +0.19746698\n",
      "        45 -1321677.70562368      +0.13279220\n",
      "        46 -1321677.61482517      +0.09079851\n",
      "        47 -1321677.55180237      +0.06302280\n",
      "        48 -1321677.50751516      +0.04428721\n",
      "        49 -1321677.47609261      +0.03142255\n",
      "        50 -1321677.45363515      +0.02245746\n",
      "        51 -1321677.43749854      +0.01613661\n",
      "        52 -1321677.42585828      +0.01164026\n",
      "        53 -1321677.41743777      +0.00842051\n",
      "         1 -768050.65598957             +nan\n",
      "         2 -750584.10288050  +17466.55310907\n",
      "         3 -744699.36050522   +5884.74237528\n",
      "         4 -740379.99903718   +4319.36146804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ര\n",
      "449\n",
      "[14, 6, 4, 14, 3, 4, 6, 4, 6, 6, 14, 8, 8, 14, 6, 8, 8, 6, 4, 8, 6, 8, 6, 4, 4, 4, 6, 3, 2, 6, 6, 6, 6, 4, 6, 2, 6, 6, 3, 6, 6, 6, 6, 6, 6, 8, 4, 6, 8, 6, 8, 8, 6, 8, 3, 6, 6, 8, 6, 8, 6, 3, 3, 6, 6, 4, 4, 4, 6, 6, 6, 6, 3, 3, 4, 6, 8, 8, 6, 8, 6, 6, 6, 8, 6, 6, 6, 3, 3, 6, 6, 4, 4, 6, 8, 4, 8, 6, 8, 3, 3, 6, 6, 4, 2, 2, 1, 2, 2, 2, 3, 2, 1, 1, 1, 2, 3, 1, 2, 2, 1, 1, 2, 2, 3, 2, 1, 3, 2, 2, 2, 3, 3, 2, 2, 4, 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 4, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 1, 2, 8, 4, 3, 2, 2, 2, 1, 3, 2, 1, 1, 3, 2, 2, 2, 2, 2, 2, 2, 3, 1, 3, 2, 2, 2, 2, 2, 3, 2, 2, 4, 4, 6, 6, 8, 8, 14, 6, 14, 8, 8, 8, 14, 8, 14, 8, 6, 8, 8, 8, 14, 8, 14, 8, 14, 8, 14, 8, 6, 8, 14, 6, 6, 6, 8, 6, 8, 14, 14, 8, 8, 8, 6, 8, 14, 14, 8, 8, 8, 14, 6, 8, 8, 6, 6, 8, 8, 8, 8, 8, 6, 3, 4, 14, 8, 4, 8, 6, 14, 8, 8, 8, 14, 8, 8, 8, 8, 2, 4, 8, 8, 6, 8, 6, 8, 4, 14, 8, 8, 8, 8, 8, 8, 4, 4, 3, 3, 14, 8, 4, 4, 8, 8, 6, 4, 8, 8, 8, 6, 4, 4, 4, 6, 3, 4, 8, 4, 8, 3, 4, 6, 6, 6, 6, 8, 2, 2, 4, 4, 4, 8, 4, 6, 3, 8, 6, 6, 8, 4, 4, 14, 8, 8, 4, 4, 8, 6, 6, 4, 4, 6, 4, 4, 6, 4, 4, 8, 8, 8, 14, 8, 8, 14, 8, 6, 6, 8, 3, 4, 8, 8, 4, 8, 2, 3, 6, 8, 8, 8, 4, 8, 8, 8, 8, 8, 3, 2, 2, 3, 3, 8, 6, 8, 4, 4, 3, 8, 8, 4, 4, 2, 2, 3, 3, 3, 4, 6, 6, 8, 3, 3, 4, 8, 6, 3, 4, 6, 4, 3, 4, 2, 4, 3, 3, 4, 8, 4, 4, 6, 6, 8, 6, 6, 3, 8, 6, 8, 8, 8, 8, 4, 2, 2, 4, 4, 4, 4, 3, 4, 2, 2, 6, 2, 3, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         5 -738968.95753348   +1411.04150369\n",
      "         6 -738149.71330724    +819.24422624\n",
      "         7 -737389.66476508    +760.04854216\n",
      "         8 -736878.63772932    +511.02703575\n",
      "         9 -736552.21144560    +326.42628372\n",
      "        10 -736049.24065276    +502.97079284\n",
      "        11 -735129.98323028    +919.25742248\n",
      "        12 -734524.08787281    +605.89535747\n",
      "        13 -734250.59598079    +273.49189202\n",
      "        14 -734087.99967285    +162.59630794\n",
      "        15 -734003.02717260     +84.97250025\n",
      "        16 -733958.81652892     +44.21064368\n",
      "        17 -733934.76212769     +24.05440122\n",
      "        18 -733897.10572022     +37.65640748\n",
      "        19 -733874.44278820     +22.66293202\n",
      "        20 -733848.27170815     +26.17108005\n",
      "        21 -733843.25536749      +5.01634066\n",
      "        22 -733840.34274496      +2.91262253\n",
      "        23 -733837.73361283      +2.60913213\n",
      "        24 -733833.96773444      +3.76587839\n",
      "        25 -733828.83296043      +5.13477401\n",
      "        26 -733825.03379667      +3.79916376\n",
      "        27 -733821.77879242      +3.25500425\n",
      "        28 -733820.72071867      +1.05807375\n",
      "        29 -733821.07062248      -0.34990381\n",
      "Model is not converging.  Current: -733821.0706224819 is not greater than -733820.72071867. Delta is -0.34990381181705743\n",
      "         1 -207968.63454834             +nan\n",
      "         2 -202838.12217192   +5130.51237642\n",
      "         3 -201307.65120558   +1530.47096634\n",
      "         4 -200886.07259124    +421.57861434\n",
      "         5 -200678.95250715    +207.12008409\n",
      "         6 -200524.79110246    +154.16140469\n",
      "         7 -200423.12254797    +101.66855449\n",
      "         8 -200335.48107408     +87.64147389\n",
      "         9 -200284.91739394     +50.56368014\n",
      "        10 -200274.86426215     +10.05313180\n",
      "        11 -200269.53150448      +5.33275767\n",
      "        12 -200264.97992049      +4.55158398\n",
      "        13 -200260.27872199      +4.70119850\n",
      "        14 -200249.92758424     +10.35113775\n",
      "        15 -200239.29190071     +10.63568353\n",
      "        16 -200235.84299414      +3.44890657\n",
      "        17 -200234.98338245      +0.85961168\n",
      "        18 -200234.72741434      +0.25596811\n",
      "        19 -200234.64911154      +0.07830280\n",
      "        20 -200234.63678557      +0.01232597\n",
      "        21 -200234.64195797      -0.00517240\n",
      "Model is not converging.  Current: -200234.64195797383 is not greater than -200234.6367855734. Delta is -0.005172400415176526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ു\n",
      "78\n",
      "[14, 8, 14, 30, 6, 3, 3, 8, 14, 14, 8, 8, 14, 8, 6, 8, 2, 14, 14, 8, 8, 14, 8, 8, 8, 14, 14, 6, 8, 6, 8, 8, 14, 8, 6, 6, 4, 4, 8, 14, 8, 8, 4, 4, 8, 8, 14, 6, 6, 8, 14, 8, 8, 8, 14, 8, 4, 4, 6, 6, 8, 6, 14, 6, 8, 4, 6, 3, 8, 6, 6, 8, 6, 8, 8, 8, 8, 8]\n",
      "Model trained for character: ള\n",
      "469\n",
      "[8, 30, 30, 14, 8, 8, 14, 6, 30, 14, 30, 14, 8, 30, 14, 30, 14, 14, 6, 14, 4, 8, 6, 3, 6, 6, 14, 4, 4, 8, 6, 8, 8, 8, 6, 6, 8, 4, 8, 6, 6, 3, 6, 8, 14, 6, 4, 4, 6, 4, 2, 2, 14, 14, 14, 2, 8, 8, 14, 14, 4, 6, 6, 14, 6, 6, 4, 3, 6, 8, 3, 3, 3, 8, 8, 3, 3, 3, 2, 3, 3, 1, 2, 2, 4, 6, 3, 2, 2, 2, 4, 4, 4, 4, 3, 2, 2, 4, 4, 3, 2, 2, 3, 4, 3, 2, 3, 2, 2, 1, 3, 14, 6, 4, 2, 3, 2, 3, 2, 2, 1, 3, 4, 30, 6, 2, 6, 2, 3, 2, 2, 3, 2, 2, 4, 2, 2, 2, 3, 2, 3, 2, 3, 2, 2, 2, 4, 4, 4, 6, 30, 14, 8, 8, 6, 6, 14, 14, 14, 14, 14, 8, 14, 14, 14, 14, 14, 14, 14, 6, 30, 14, 8, 14, 8, 14, 14, 8, 14, 30, 14, 6, 14, 6, 8, 8, 14, 8, 8, 6, 14, 14, 8, 8, 6, 8, 14, 8, 14, 14, 4, 6, 4, 6, 8, 4, 6, 6, 6, 3, 3, 6, 6, 6, 6, 6, 6, 6, 8, 8, 4, 4, 4, 6, 6, 8, 8, 8, 4, 4, 8, 6, 8, 8, 8, 30, 30, 4, 4, 4, 3, 3, 14, 8, 4, 4, 4, 4, 4, 4, 6, 6, 8, 3, 3, 14, 14, 14, 4, 4, 4, 4, 6, 6, 4, 4, 6, 8, 14, 8, 14, 6, 4, 8, 14, 8, 8, 14, 8, 4, 4, 4, 4, 4, 4, 6, 14, 14, 6, 14, 8, 6, 4, 6, 8, 8, 8, 4, 8, 8, 14, 30, 4, 4, 4, 4, 8, 4, 4, 4, 4, 4, 8, 4, 6, 14, 4, 6, 3, 6, 4, 3, 8, 4, 4, 6, 6, 8, 14, 3, 3, 3, 3, 8, 6, 6, 4, 4, 14, 14, 4, 4, 4, 4, 4, 4, 14, 14, 4, 8, 8, 8, 6, 6, 6, 6, 4, 4, 3, 3, 2, 2, 4, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 4, 4, 8, 8, 8, 8, 3, 30, 6, 4, 6, 4, 4, 6, 6, 4, 4, 4, 4, 4, 6, 6, 8, 3, 8, 8, 8, 3, 3, 4, 4, 6, 6, 6, 6, 8, 3, 3, 4, 4, 30, 14, 3, 3, 3, 3, 3, 4, 4, 8, 4, 2, 2, 6, 6, 6, 4, 8, 8, 4, 4, 6, 6, 4, 4, 2, 2, 4, 4, 6, 6, 8, 4, 4, 3, 3, 6, 6, 14, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4, 8, 4, 4, 4, 8, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -1017417.13902431             +nan\n",
      "         2 -985294.35170258  +32122.78732173\n",
      "         3 -973890.74151604  +11403.61018654\n",
      "         4 -971483.90825331   +2406.83326273\n",
      "         5 -969756.67457952   +1727.23367379\n",
      "         6 -968727.42860941   +1029.24597011\n",
      "         7 -968137.66044406    +589.76816536\n",
      "         8 -967629.47911607    +508.18132798\n",
      "         9 -967223.15677016    +406.32234592\n",
      "        10 -967003.58759919    +219.56917096\n",
      "        11 -966833.18075052    +170.40684867\n",
      "        12 -966721.29738022    +111.88337030\n",
      "        13 -966621.67566239     +99.62171783\n",
      "        14 -966572.26804872     +49.40761367\n",
      "        15 -966528.45213059     +43.81591813\n",
      "        16 -966490.33831046     +38.11382013\n",
      "        17 -966465.09408555     +25.24422491\n",
      "        18 -966441.36969258     +23.72439296\n",
      "        19 -966421.38625945     +19.98343313\n",
      "        20 -966407.39844114     +13.98781831\n",
      "        21 -966397.51271419      +9.88572696\n",
      "        22 -966385.85753702     +11.65517716\n",
      "        23 -966380.06820347      +5.78933355\n",
      "        24 -966375.62612558      +4.44207789\n",
      "        25 -966374.16289308      +1.46323250\n",
      "        26 -966373.79808627      +0.36480682\n",
      "        27 -966373.77813991      +0.01994635\n",
      "        28 -966373.90209944      -0.12395952\n",
      "Model is not converging.  Current: -966373.9020994357 is not greater than -966373.7781399136. Delta is -0.12395952211227268\n",
      "         1 -175769.50733676             +nan\n",
      "         2 -170856.12545732   +4913.38187944\n",
      "         3 -169162.85727819   +1693.26817913\n",
      "         4 -168901.16854873    +261.68872946\n",
      "         5 -168750.12901207    +151.03953666\n",
      "         6 -168587.20367570    +162.92533637\n",
      "         7 -168547.22341453     +39.98026117\n",
      "         8 -168514.82783525     +32.39557928\n",
      "         9 -168508.83946256      +5.98837269\n",
      "        10 -168507.60217021      +1.23729234\n",
      "        11 -168507.71573099      -0.11356077\n",
      "Model is not converging.  Current: -168507.71573098822 is not greater than -168507.60217021356. Delta is -0.11356077465461567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ക\n",
      "104\n",
      "[30, 4, 4, 4, 4, 6, 6, 6, 8, 6, 6, 8, 8, 8, 4, 4, 6, 8, 8, 8, 14, 4, 3, 4, 4, 4, 14, 3, 3, 6, 1, 4, 1, 2, 3, 1, 2, 2, 3, 4, 4, 2, 4, 2, 3, 3, 1, 2, 2, 4, 2, 2, 3, 6, 2, 2, 2, 2, 2, 3, 2, 2, 2, 6, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 3, 4, 4, 14, 4, 6, 14, 8, 8, 14, 14, 4, 6, 14, 14, 14, 8, 14, 8, 8, 4, 14, 14, 8, 14, 4, 4]\n",
      "Model trained for character: ഷ\n",
      "357\n",
      "[14, 14, 8, 30, 6, 30, 14, 14, 30, 14, 8, 2, 8, 3, 4, 4, 2, 2, 6, 6, 6, 8, 8, 8, 4, 4, 3, 4, 8, 8, 8, 8, 8, 6, 8, 8, 8, 8, 6, 3, 6, 6, 6, 3, 4, 6, 8, 4, 3, 8, 8, 8, 8, 6, 6, 3, 4, 8, 8, 8, 8, 6, 6, 6, 4, 2, 6, 14, 8, 6, 4, 4, 4, 4, 4, 8, 3, 3, 6, 6, 4, 6, 8, 8, 8, 8, 8, 8, 14, 4, 8, 8, 8, 8, 14, 4, 4, 4, 3, 2, 2, 1, 2, 2, 2, 3, 3, 4, 3, 3, 3, 2, 2, 1, 3, 3, 4, 4, 2, 2, 2, 4, 1, 1, 3, 2, 2, 4, 3, 1, 1, 3, 4, 4, 2, 4, 1, 1, 2, 2, 4, 3, 1, 2, 2, 2, 2, 4, 3, 2, 4, 3, 2, 2, 2, 1, 4, 2, 2, 2, 4, 2, 2, 2, 3, 2, 4, 4, 3, 6, 3, 2, 2, 4, 3, 2, 2, 6, 2, 4, 3, 1, 1, 6, 4, 3, 3, 4, 14, 14, 6, 14, 14, 6, 14, 14, 14, 8, 6, 14, 14, 14, 6, 6, 14, 30, 6, 30, 14, 8, 14, 30, 30, 8, 14, 8, 14, 14, 8, 14, 14, 30, 8, 14, 8, 8, 6, 6, 14, 14, 14, 14, 8, 8, 6, 6, 14, 6, 4, 6, 6, 14, 8, 6, 8, 14, 8, 14, 8, 6, 6, 6, 8, 8, 8, 8, 14, 14, 8, 14, 14, 8, 8, 8, 6, 6, 6, 6, 6, 8, 14, 8, 6, 6, 8, 8, 6, 4, 8, 4, 6, 6, 8, 8, 14, 8, 14, 8, 8, 8, 8, 6, 4, 8, 4, 4, 14, 8, 8, 6, 6, 14, 4, 3, 4, 6, 6, 8, 4, 6, 4, 30, 14, 4, 8, 4, 2, 6, 14, 8, 8, 8, 14, 6, 6, 8, 14, 6, 3, 6, 14, 8, 8, 8, 14, 3, 4, 8, 8, 6, 6, 6, 6, 6, 8, 4, 8, 8, 4, 4, 8, 6, 6, 3, 8, 14, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -777572.22136057             +nan\n",
      "         2 -758276.31374793  +19295.90761263\n",
      "         3 -749449.34120224   +8826.97254569\n",
      "         4 -745848.96845818   +3600.37274406\n",
      "         5 -745040.48194115    +808.48651703\n",
      "         6 -744671.98536938    +368.49657177\n",
      "         7 -744422.96319834    +249.02217104\n",
      "         8 -744204.97576953    +217.98742882\n",
      "         9 -744001.36475626    +203.61101327\n",
      "        10 -743885.64447331    +115.72028294\n",
      "        11 -743829.06713999     +56.57733332\n",
      "        12 -743790.36907425     +38.69806574\n",
      "        13 -743742.09799946     +48.27107479\n",
      "        14 -743720.37270148     +21.72529798\n",
      "        15 -743696.09227116     +24.28043032\n",
      "        16 -743692.05926542      +4.03300575\n",
      "        17 -743690.85486842      +1.20439700\n",
      "        18 -743689.89544573      +0.95942269\n",
      "        19 -743688.64212380      +1.25332193\n",
      "        20 -743688.19736761      +0.44475619\n",
      "        21 -743687.74976727      +0.44760034\n",
      "        22 -743687.31442952      +0.43533774\n",
      "        23 -743687.10488774      +0.20954178\n",
      "        24 -743687.01949382      +0.08539392\n",
      "        25 -743686.97638450      +0.04310932\n",
      "        26 -743686.95053746      +0.02584704\n",
      "        27 -743686.93366235      +0.01687511\n",
      "        28 -743686.92228111      +0.01138125\n",
      "        29 -743686.91454811      +0.00773300\n",
      "         1 -149148.89161140             +nan\n",
      "         2 -146539.74070633   +2609.15090507\n",
      "         3 -145379.63058489   +1160.11012144\n",
      "         4 -144969.54763341    +410.08295148\n",
      "         5 -144717.48963223    +252.05800118\n",
      "         6 -144510.25455216    +207.23508007\n",
      "         7 -144504.07637313      +6.17817903\n",
      "         8 -144503.30331808      +0.77305505\n",
      "         9 -144502.67787531      +0.62544277\n",
      "        10 -144501.99952667      +0.67834864\n",
      "        11 -144501.01291822      +0.98660845\n",
      "        12 -144500.26654241      +0.74637581\n",
      "        13 -144500.06352607      +0.20301635\n",
      "        14 -144500.00828111      +0.05524496\n",
      "        15 -144499.99409688      +0.01418422\n",
      "        16 -144499.99053492      +0.00356197\n",
      "         1 -191581.47206477             +nan\n",
      "         2 -187746.91518953   +3834.55687524\n",
      "         3 -185208.37398020   +2538.54120933\n",
      "         4 -183860.67571542   +1347.69826479\n",
      "         5 -183381.79893773    +478.87677769\n",
      "         6 -183363.87364182     +17.92529591\n",
      "         7 -183362.07113631      +1.80250551\n",
      "         8 -183362.27389214      -0.20275583\n",
      "Model is not converging.  Current: -183362.2738921445 is not greater than -183362.07113631256. Delta is -0.2027558319387026\n",
      "         1 -132258.30761089             +nan\n",
      "         2 -129372.39518182   +2885.91242907\n",
      "         3 -128788.10450473    +584.29067709\n",
      "         4 -128576.02128201    +212.08322272\n",
      "         5 -128452.11669227    +123.90458973\n",
      "         6 -128375.06970719     +77.04698508\n",
      "         7 -128305.60271387     +69.46699332\n",
      "         8 -128179.61915769    +125.98355619\n",
      "         9 -127699.14002653    +480.47913116\n",
      "        10 -127326.54147256    +372.59855397\n",
      "        11 -127237.59606382     +88.94540874\n",
      "        12 -127220.67112877     +16.92493505\n",
      "        13 -127213.17211962      +7.49900914\n",
      "        14 -127208.29296669      +4.87915293\n",
      "        15 -127207.42167964      +0.87128705\n",
      "        16 -127207.47961188      -0.05793224\n",
      "Model is not converging.  Current: -127207.47961188051 is not greater than -127207.4216796433. Delta is -0.05793223720684182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: മ\n",
      "28\n",
      "[30, 30, 30, 14, 14, 14, 6, 30, 30, 30, 14, 30, 30, 14, 8, 30, 8, 6, 30, 30, 8, 14, 8, 6, 4, 8, 6, 8]\n",
      "Model trained for character: ആ\n",
      "60\n",
      "[14, 4, 14, 14, 14, 14, 30, 14, 14, 30, 30, 4, 8, 4, 1, 8, 14, 8, 14, 14, 8, 14, 14, 6, 8, 6, 8, 30, 6, 4, 6, 6, 8, 8, 3, 4, 6, 14, 8, 30, 8, 6, 6, 8, 14, 8, 4, 14, 14, 14, 3, 14, 6, 8, 8, 6, 6, 8, 8, 8]\n",
      "Model trained for character: ഠ\n",
      "40\n",
      "[14, 30, 14, 14, 8, 4, 14, 6, 14, 14, 14, 14, 8, 8, 8, 8, 4, 4, 14, 14, 14, 8, 8, 14, 14, 14, 8, 14, 3, 6, 14, 4, 3, 6, 30, 8, 14, 14, 4, 8]\n",
      "Model trained for character: ൽ\n",
      "62\n",
      "[14, 8, 8, 6, 3, 4, 8, 8, 8, 3, 8, 4, 3, 8, 14, 3, 4, 1, 4, 2, 2, 3, 3, 3, 2, 2, 6, 14, 14, 14, 8, 14, 14, 14, 14, 8, 6, 4, 8, 4, 8, 4, 8, 6, 8, 6, 8, 8, 8, 14, 14, 8, 6, 8, 6, 6, 6, 4, 14, 8, 2, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -134402.11169532             +nan\n",
      "         2 -132387.44281807   +2014.66887725\n",
      "         3 -131910.51006229    +476.93275578\n",
      "         4 -131155.53151039    +754.97855191\n",
      "         5 -130759.70070530    +395.83080508\n",
      "         6 -130593.30433488    +166.39637042\n",
      "         7 -130454.78733022    +138.51700467\n",
      "         8 -130387.89368319     +66.89364703\n",
      "         9 -130353.76997573     +34.12370746\n",
      "        10 -130339.20869863     +14.56127710\n",
      "        11 -130335.07110929      +4.13758934\n",
      "        12 -130334.59823504      +0.47287426\n",
      "        13 -130334.16971773      +0.42851731\n",
      "        14 -130333.96901606      +0.20070167\n",
      "        15 -130333.80387667      +0.16513939\n",
      "        16 -130333.48359075      +0.32028591\n",
      "        17 -130332.56254475      +0.92104600\n",
      "        18 -130330.79925962      +1.76328513\n",
      "        19 -130328.55352455      +2.24573507\n",
      "        20 -130318.13347591     +10.42004864\n",
      "        21 -130316.76862351      +1.36485241\n",
      "        22 -130316.74737519      +0.02124831\n",
      "        23 -130316.74486581      +0.00250938\n",
      "         1 -116120.72358263             +nan\n",
      "         2 -112454.86065083   +3665.86293180\n",
      "         3 -111345.80202425   +1109.05862658\n",
      "         4 -111135.82857476    +209.97344949\n",
      "         5 -111110.93845256     +24.89012220\n",
      "         6 -111073.88368491     +37.05476765\n",
      "         7 -111067.21719987      +6.66648504\n",
      "         8 -111063.26445157      +3.95274831\n",
      "         9 -111061.95185283      +1.31259874\n",
      "        10 -111061.42321056      +0.52864227\n",
      "        11 -111061.09154015      +0.33167041\n",
      "        12 -111060.34907614      +0.74246401\n",
      "        13 -111059.13925987      +1.20981627\n",
      "        14 -111058.66917320      +0.47008667\n",
      "        15 -111058.59867795      +0.07049525\n",
      "        16 -111058.58373558      +0.01494238\n",
      "        17 -111058.57949494      +0.00424064\n",
      "         1  -71749.25534999             +nan\n",
      "         2  -69534.43007280   +2214.82527719\n",
      "         3  -69337.71907921    +196.71099359\n",
      "         4  -69270.20420284     +67.51487637\n",
      "         5  -69230.34364360     +39.86055924\n",
      "         6  -69218.12069751     +12.22294609\n",
      "         7  -69194.92642184     +23.19427567\n",
      "         8  -69108.44824934     +86.47817250\n",
      "         9  -68902.10592069    +206.34232865\n",
      "        10  -68848.65857945     +53.44734123\n",
      "        11  -68829.20876560     +19.44981386\n",
      "        12  -68816.93088998     +12.27787562\n",
      "        13  -68803.21858347     +13.71230651\n",
      "        14  -68790.18114413     +13.03743934\n",
      "        15  -68783.75663464      +6.42450948\n",
      "        16  -68776.87145791      +6.88517674\n",
      "        17  -68770.38278432      +6.48867359\n",
      "        18  -68768.32697247      +2.05581184\n",
      "        19  -68768.29710299      +0.02986948\n",
      "        20  -68768.28836471      +0.00873828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ർ\n",
      "30\n",
      "[14, 30, 14, 14, 14, 14, 4, 8, 8, 8, 14, 6, 30, 8, 14, 14, 6, 30, 14, 14, 8, 6, 8, 4, 8, 14, 8, 6, 14, 14]\n",
      "Model trained for character: ഇ\n",
      "37\n",
      "[8, 8, 6, 8, 8, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 8, 8, 6, 6, 8, 8, 6, 6, 14, 8, 8, 6, 6, 8, 6, 6, 4, 4, 6, 6, 6, 6]\n",
      "Model trained for character: ങ\n",
      "661\n",
      "[14, 30, 14, 8, 8, 14, 8, 6, 6, 6, 6, 14, 6, 6, 6, 6, 14, 30, 14, 14, 8, 8, 6, 6, 4, 8, 8, 14, 3, 2, 3, 2, 2, 14, 8, 14, 4, 6, 8, 8, 2, 2, 2, 6, 6, 8, 4, 6, 4, 4, 8, 8, 8, 8, 8, 2, 2, 3, 3, 4, 8, 8, 8, 4, 14, 14, 6, 8, 8, 8, 8, 8, 8, 3, 2, 8, 8, 8, 6, 8, 6, 6, 6, 6, 14, 2, 2, 14, 6, 4, 4, 6, 6, 30, 6, 8, 8, 14, 8, 8, 8, 3, 3, 4, 4, 8, 8, 8, 8, 8, 14, 4, 4, 4, 8, 8, 3, 3, 4, 4, 6, 14, 14, 8, 8, 4, 8, 8, 6, 6, 14, 8, 8, 8, 14, 14, 2, 2, 8, 8, 8, 8, 8, 6, 6, 14, 6, 4, 4, 4, 3, 2, 2, 3, 4, 4, 3, 2, 1, 1, 1, 2, 2, 2, 1, 1, 3, 3, 3, 4, 2, 4, 4, 4, 3, 2, 4, 4, 1, 3, 1, 2, 2, 2, 4, 2, 2, 2, 3, 3, 2, 4, 2, 4, 3, 1, 1, 1, 1, 3, 3, 3, 4, 2, 2, 3, 4, 2, 1, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 4, 3, 2, 1, 2, 2, 3, 4, 4, 4, 1, 2, 2, 3, 2, 3, 3, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 4, 4, 1, 3, 1, 6, 6, 3, 3, 2, 2, 2, 2, 4, 2, 2, 2, 3, 14, 2, 2, 4, 2, 2, 2, 2, 3, 6, 2, 3, 4, 2, 1, 2, 4, 4, 4, 6, 2, 3, 3, 3, 2, 1, 1, 2, 2, 6, 3, 2, 1, 2, 2, 2, 2, 1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 6, 4, 1, 1, 2, 2, 4, 2, 3, 2, 2, 1, 3, 2, 3, 3, 3, 3, 4, 3, 3, 2, 3, 4, 3, 2, 2, 4, 4, 4, 4, 4, 4, 4, 2, 2, 6, 6, 6, 8, 6, 6, 6, 6, 8, 8, 6, 14, 30, 30, 14, 6, 6, 14, 30, 14, 14, 30, 14, 14, 6, 6, 14, 14, 14, 14, 8, 14, 14, 14, 14, 30, 14, 8, 30, 14, 14, 30, 14, 14, 14, 14, 8, 8, 14, 6, 8, 14, 6, 6, 4, 6, 6, 6, 6, 8, 8, 14, 14, 8, 14, 30, 14, 14, 8, 8, 6, 6, 8, 8, 8, 14, 4, 14, 6, 6, 4, 4, 6, 6, 14, 6, 6, 6, 6, 8, 8, 4, 4, 6, 6, 6, 6, 14, 4, 4, 4, 8, 14, 6, 6, 6, 6, 8, 8, 8, 14, 8, 8, 14, 4, 3, 3, 14, 8, 6, 6, 4, 4, 6, 6, 8, 8, 4, 4, 8, 8, 4, 8, 6, 6, 8, 8, 6, 6, 6, 14, 8, 4, 6, 6, 6, 8, 4, 4, 6, 6, 14, 30, 14, 6, 6, 6, 6, 6, 4, 6, 8, 4, 4, 4, 4, 4, 4, 4, 8, 6, 6, 4, 4, 8, 4, 4, 4, 4, 8, 6, 14, 6, 8, 14, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 8, 4, 4, 4, 4, 4, 6, 8, 14, 14, 14, 4, 6, 6, 6, 6, 6, 6, 4, 14, 14, 14, 14, 14, 14, 2, 2, 3, 3, 3, 8, 8, 3, 3, 8, 8, 6, 4, 3, 3, 4, 4, 6, 6, 6, 6, 14, 6, 4, 4, 4, 4, 4, 4, 8, 8, 3, 3, 4, 4, 8, 8, 6, 6, 14, 3, 8, 8, 4, 4, 4, 4, 4, 8, 4, 4, 4, 4, 6, 6, 6, 4, 4, 4, 6, 3, 3, 6, 6, 14, 6, 6, 6, 6, 14, 2, 2, 4, 4, 8, 4, 4, 6, 6, 2, 2, 6, 6, 8, 8, 8, 8, 6, 6, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -1272155.73661642             +nan\n",
      "         2 -1241595.98782220  +30559.74879422\n",
      "         3 -1228065.93926223  +13530.04855997\n",
      "         4 -1214769.66953947  +13296.26972276\n",
      "         5 -1211357.79449280   +3411.87504667\n",
      "         6 -1210883.33080100    +474.46369181\n",
      "         7 -1210742.66755333    +140.66324767\n",
      "         8 -1210662.01826681     +80.64928652\n",
      "         9 -1210576.68218126     +85.33608555\n",
      "        10 -1210506.08052412     +70.60165714\n",
      "        11 -1210429.50946400     +76.57106012\n",
      "        12 -1210371.96113943     +57.54832457\n",
      "        13 -1210318.43994282     +53.52119660\n",
      "        14 -1210283.24078433     +35.19915849\n",
      "        15 -1210251.52210176     +31.71868257\n",
      "        16 -1210224.31177011     +27.21033165\n",
      "        17 -1210214.86865403      +9.44311608\n",
      "        18 -1210214.15478406      +0.71386997\n",
      "        19 -1210213.50111191      +0.65367216\n",
      "        20 -1210213.70239958      -0.20128767\n",
      "Model is not converging.  Current: -1210213.7023995758 is not greater than -1210213.5011119063. Delta is -0.20128766959533095\n",
      "         1 -346051.85247250             +nan\n",
      "         2 -337148.71383513   +8903.13863737\n",
      "         3 -333681.79513212   +3466.91870301\n",
      "         4 -331110.11669866   +2571.67843346\n",
      "         5 -330123.22282378    +986.89387488\n",
      "         6 -329753.55890909    +369.66391468\n",
      "         7 -329452.85796606    +300.70094304\n",
      "         8 -329314.65118197    +138.20678409\n",
      "         9 -329275.39419019     +39.25699177\n",
      "        10 -329237.76561903     +37.62857117\n",
      "        11 -329151.71738017     +86.04823886\n",
      "        12 -329053.96481490     +97.75256527\n",
      "        13 -328981.47220406     +72.49261084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ന\n",
      "115\n",
      "[14, 14, 30, 14, 30, 30, 14, 3, 8, 6, 6, 6, 14, 14, 6, 3, 2, 6, 14, 6, 6, 4, 4, 6, 6, 6, 6, 6, 8, 14, 8, 8, 14, 8, 8, 14, 14, 8, 3, 2, 2, 2, 2, 4, 3, 4, 2, 2, 1, 2, 2, 2, 6, 2, 3, 14, 8, 8, 6, 6, 6, 6, 8, 8, 6, 6, 14, 30, 14, 30, 14, 8, 8, 6, 6, 14, 14, 14, 14, 14, 8, 8, 8, 8, 6, 6, 8, 14, 6, 6, 14, 14, 30, 14, 14, 14, 8, 14, 8, 30, 30, 14, 3, 3, 3, 3, 4, 14, 8, 8, 8, 8, 8, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        14 -328917.06970732     +64.40249674\n",
      "        15 -328897.85556005     +19.21414727\n",
      "        16 -328894.89321268      +2.96234736\n",
      "        17 -328894.06682689      +0.82638579\n",
      "        18 -328893.79686462      +0.26996227\n",
      "        19 -328893.68703108      +0.10983354\n",
      "        20 -328893.63851317      +0.04851791\n",
      "        21 -328893.61565746      +0.02285570\n",
      "        22 -328893.60443899      +0.01121847\n",
      "        23 -328893.59882102      +0.00561797\n",
      "         1 -626626.42057846             +nan\n",
      "         2 -608077.70510430  +18548.71547416\n",
      "         3 -601499.04397501   +6578.66112929\n",
      "         4 -599564.56691129   +1934.47706372\n",
      "         5 -597885.72885837   +1678.83805292\n",
      "         6 -597208.78375420    +676.94510418\n",
      "         7 -596849.83813602    +358.94561817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ജ\n",
      "281\n",
      "[6, 6, 4, 4, 6, 6, 4, 4, 3, 3, 4, 4, 14, 30, 30, 8, 14, 6, 14, 14, 14, 6, 6, 4, 4, 14, 14, 30, 14, 6, 8, 4, 4, 4, 4, 4, 4, 14, 6, 8, 2, 2, 4, 4, 6, 4, 8, 6, 4, 14, 8, 6, 4, 4, 2, 2, 1, 1, 3, 2, 4, 4, 3, 8, 8, 6, 6, 14, 30, 14, 8, 6, 14, 30, 30, 6, 8, 6, 6, 6, 6, 30, 14, 8, 8, 8, 30, 14, 14, 30, 14, 8, 30, 30, 8, 6, 8, 8, 14, 8, 30, 14, 6, 6, 8, 8, 6, 6, 4, 8, 8, 4, 4, 3, 6, 6, 6, 4, 4, 14, 14, 4, 6, 4, 6, 6, 8, 4, 4, 4, 4, 6, 6, 4, 4, 14, 4, 3, 3, 3, 3, 3, 3, 6, 6, 8, 4, 6, 6, 8, 14, 14, 4, 4, 4, 4, 4, 8, 8, 4, 4, 8, 2, 6, 4, 8, 4, 8, 4, 8, 4, 4, 8, 4, 4, 6, 6, 4, 3, 3, 14, 4, 6, 4, 4, 4, 3, 6, 4, 4, 4, 4, 6, 6, 4, 4, 4, 4, 3, 6, 6, 14, 8, 6, 4, 4, 4, 4, 4, 4, 8, 8, 6, 6, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 3, 4, 4, 6, 6, 8, 8, 6, 2, 8, 4, 6, 6, 4, 4, 4, 4, 4, 3, 6, 6, 6, 6, 4, 6, 4, 6, 4, 4, 6, 6, 6, 6, 14, 3, 3, 4, 6, 3, 6, 4, 6, 4, 6, 4, 8, 8, 8, 8, 8, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         8 -596669.45043311    +180.38770291\n",
      "         9 -596588.60615352     +80.84427958\n",
      "        10 -596525.14800924     +63.45814428\n",
      "        11 -596457.75018097     +67.39782827\n",
      "        12 -596383.74827849     +74.00190248\n",
      "        13 -596298.51125536     +85.23702313\n",
      "        14 -596237.88870588     +60.62254949\n",
      "        15 -596212.15007548     +25.73863040\n",
      "        16 -596187.10889036     +25.04118513\n",
      "        17 -596134.51744462     +52.59144574\n",
      "        18 -596081.26252324     +53.25492138\n",
      "        19 -596026.88478384     +54.37773940\n",
      "        20 -595974.24172838     +52.64305546\n",
      "        21 -595914.55695961     +59.68476877\n",
      "        22 -595800.48618487    +114.07077473\n",
      "        23 -595572.82345744    +227.66272744\n",
      "        24 -595268.69890878    +304.12454865\n",
      "        25 -594971.84140005    +296.85750873\n",
      "        26 -594657.25416762    +314.58723243\n",
      "        27 -594391.92823131    +265.32593631\n",
      "        28 -594180.65089907    +211.27733224\n",
      "        29 -594073.68028875    +106.97061032\n",
      "        30 -594014.03772394     +59.64256481\n",
      "        31 -593959.61038624     +54.42733770\n",
      "        32 -593909.90786772     +49.70251852\n",
      "        33 -593894.21270706     +15.69516066\n",
      "        34 -593881.72819652     +12.48451054\n",
      "        35 -593869.85936730     +11.86882922\n",
      "        36 -593858.19702167     +11.66234562\n",
      "        37 -593850.17961711      +8.01740457\n",
      "        38 -593846.16920646      +4.01041064\n",
      "        39 -593844.99215143      +1.17705503\n",
      "        40 -593844.53643753      +0.45571390\n",
      "        41 -593844.31566219      +0.22077534\n",
      "        42 -593844.19486728      +0.12079490\n",
      "        43 -593844.12337636      +0.07149092\n",
      "        44 -593844.07924961      +0.04412676\n",
      "        45 -593844.05153616      +0.02771344\n",
      "        46 -593844.03405021      +0.01748595\n",
      "        47 -593844.02302697      +0.01102324\n",
      "        48 -593844.01609742      +0.00692955\n",
      "         1 -670088.68692828             +nan\n",
      "         2 -653097.31927783  +16991.36765045\n",
      "         3 -649371.71504001   +3725.60423782\n",
      "         4 -647930.53172821   +1441.18331180\n",
      "         5 -647632.97847535    +297.55325286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ട\n",
      "302\n",
      "[14, 8, 3, 2, 8, 8, 14, 6, 6, 6, 3, 4, 8, 8, 6, 6, 6, 6, 6, 6, 6, 6, 3, 8, 6, 3, 3, 6, 14, 4, 8, 8, 8, 6, 3, 30, 8, 4, 6, 6, 6, 4, 6, 8, 4, 8, 8, 4, 8, 8, 8, 6, 3, 14, 14, 8, 8, 8, 4, 6, 6, 14, 3, 6, 6, 6, 6, 14, 14, 14, 14, 8, 8, 8, 6, 8, 30, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 4, 4, 14, 14, 14, 3, 6, 30, 14, 6, 8, 6, 8, 14, 14, 14, 14, 4, 3, 2, 2, 2, 1, 3, 2, 3, 4, 1, 2, 3, 2, 4, 4, 3, 3, 6, 4, 4, 4, 4, 4, 4, 3, 3, 1, 4, 3, 2, 2, 2, 2, 1, 1, 3, 2, 2, 1, 6, 3, 3, 3, 3, 2, 2, 4, 4, 4, 3, 2, 2, 1, 1, 1, 6, 2, 1, 1, 2, 3, 2, 2, 2, 2, 1, 2, 3, 4, 4, 6, 4, 3, 2, 3, 3, 2, 2, 2, 1, 3, 4, 4, 4, 14, 8, 14, 14, 4, 14, 14, 6, 4, 14, 14, 14, 14, 6, 14, 6, 8, 8, 6, 14, 8, 6, 30, 14, 14, 14, 14, 14, 14, 14, 6, 4, 4, 6, 14, 8, 14, 30, 6, 8, 8, 8, 8, 8, 14, 14, 6, 8, 8, 8, 14, 6, 8, 4, 14, 6, 14, 30, 14, 8, 14, 4, 6, 8, 14, 4, 2, 3, 14, 8, 8, 14, 8, 8, 8, 4, 8, 8, 4, 6, 3, 14, 14, 6, 6, 14, 4, 4, 14, 8, 14, 14, 4, 8, 8, 6, 6, 14, 8, 6, 14, 8, 8, 8, 14, 6, 8, 6, 3, 8, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         6 -647513.61026219    +119.36821316\n",
      "         7 -647439.59673474     +74.01352744\n",
      "         8 -647390.43678967     +49.15994507\n",
      "         9 -647352.04505667     +38.39173301\n",
      "        10 -647309.25353843     +42.79151823\n",
      "        11 -647233.05925062     +76.19428781\n",
      "        12 -647103.31345487    +129.74579576\n",
      "        13 -647007.38487062     +95.92858425\n",
      "        14 -646941.81318480     +65.57168582\n",
      "        15 -646892.08800727     +49.72517753\n",
      "        16 -646833.90295244     +58.18505483\n",
      "        17 -646777.39203407     +56.51091837\n",
      "        18 -646734.07039335     +43.32164072\n",
      "        19 -646693.03186393     +41.03852942\n",
      "        20 -646666.78561319     +26.24625074\n",
      "        21 -646652.78791039     +13.99770280\n",
      "        22 -646643.14248901      +9.64542139\n",
      "        23 -646633.58620905      +9.55627996\n",
      "        24 -646628.24898679      +5.33722225\n",
      "        25 -646625.68093541      +2.56805138\n",
      "        26 -646623.71352964      +1.96740577\n",
      "        27 -646621.57470880      +2.13882084\n",
      "        28 -646616.52454949      +5.05015931\n",
      "        29 -646607.82412404      +8.70042545\n",
      "        30 -646602.55283363      +5.27129041\n",
      "        31 -646598.74245176      +3.81038187\n",
      "        32 -646595.52466666      +3.21778510\n",
      "        33 -646590.28868088      +5.23598578\n",
      "        34 -646581.89298922      +8.39569166\n",
      "        35 -646575.31636702      +6.57662220\n",
      "        36 -646566.43349614      +8.88287088\n",
      "        37 -646557.72041950      +8.71307663\n",
      "        38 -646553.40598140      +4.31443810\n",
      "        39 -646550.01969434      +3.38628706\n",
      "        40 -646547.02417150      +2.99552283\n",
      "        41 -646544.09848875      +2.92568275\n",
      "        42 -646541.90002884      +2.19845991\n",
      "        43 -646540.25510522      +1.64492362\n",
      "        44 -646539.03010537      +1.22499985\n",
      "        45 -646538.27324274      +0.75686263\n",
      "        46 -646537.75226810      +0.52097463\n",
      "        47 -646537.36598603      +0.38628207\n",
      "        48 -646537.16083444      +0.20515159\n",
      "        49 -646537.13081077      +0.03002368\n",
      "        50 -646537.17346038      -0.04264962\n",
      "Model is not converging.  Current: -646537.1734603806 is not greater than -646537.1308107652. Delta is -0.04264961543958634\n",
      "         1 -163477.52212059             +nan\n",
      "         2 -158991.79171717   +4485.73040343\n",
      "         3 -156736.83200377   +2254.95971340\n",
      "         4 -155834.74451878    +902.08748499\n",
      "         5 -155695.34807507    +139.39644371\n",
      "         6 -155642.11449776     +53.23357731\n",
      "         7 -155556.83601323     +85.27848453\n",
      "         8 -155216.86632592    +339.96968730\n",
      "         9 -155201.47896799     +15.38735794\n",
      "        10 -155188.73693888     +12.74202911\n",
      "        11 -155185.68608010      +3.05085878\n",
      "        12 -155185.33238765      +0.35369245\n",
      "        13 -155185.15923117      +0.17315648\n",
      "        14 -155185.01416776      +0.14506342\n",
      "        15 -155184.86294163      +0.15122613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: വ\n",
      "76\n",
      "[30, 14, 14, 14, 8, 8, 6, 6, 6, 6, 8, 4, 3, 3, 30, 14, 14, 6, 3, 1, 1, 1, 1, 1, 3, 2, 2, 2, 2, 4, 2, 3, 3, 3, 1, 4, 2, 3, 3, 2, 1, 2, 2, 4, 3, 2, 2, 2, 6, 30, 14, 6, 6, 6, 6, 14, 14, 6, 6, 6, 6, 6, 6, 2, 6, 14, 14, 14, 6, 4, 14, 14, 6, 6, 14, 14]\n",
      "Model trained for character: ഹ\n",
      "195\n",
      "[14, 14, 14, 4, 8, 14, 14, 8, 4, 8, 8, 2, 4, 4, 8, 4, 4, 6, 8, 8, 4, 4, 4, 6, 8, 2, 6, 6, 8, 14, 14, 14, 8, 8, 8, 8, 8, 8, 2, 2, 2, 1, 2, 1, 3, 4, 2, 4, 3, 3, 4, 2, 2, 3, 3, 4, 2, 6, 8, 3, 2, 4, 2, 2, 3, 2, 4, 3, 3, 4, 2, 3, 2, 6, 2, 3, 2, 3, 14, 14, 14, 14, 14, 8, 14, 14, 14, 8, 14, 6, 8, 8, 14, 8, 8, 4, 8, 8, 6, 8, 6, 6, 6, 8, 8, 4, 8, 14, 8, 6, 8, 8, 8, 14, 6, 8, 4, 6, 8, 14, 3, 8, 3, 14, 8, 6, 8, 6, 8, 8, 4, 4, 3, 4, 6, 8, 4, 6, 8, 6, 14, 4, 8, 8, 6, 6, 8, 14, 14, 8, 8, 8, 6, 3, 8, 4, 14, 14, 8, 8, 8, 8, 14, 3, 6, 14, 8, 14, 4, 6, 6, 8, 8, 4, 6, 8, 3, 8, 8, 3, 4, 14, 6, 3, 3, 6, 8, 8, 6, 6, 6, 6, 14, 6, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        16 -155184.68968843      +0.17325320\n",
      "        17 -155184.49486304      +0.19482539\n",
      "        18 -155184.30604887      +0.18881418\n",
      "        19 -155184.16310983      +0.14293903\n",
      "        20 -155184.07789764      +0.08521219\n",
      "        21 -155184.03376986      +0.04412778\n",
      "        22 -155184.01188499      +0.02188487\n",
      "        23 -155184.00087346      +0.01101153\n",
      "        24 -155183.99509415      +0.00577930\n",
      "         1 -406822.65914691             +nan\n",
      "         2 -395803.70513420  +11018.95401270\n",
      "         3 -391557.06777854   +4246.63735567\n",
      "         4 -389753.30368656   +1803.76409198\n",
      "         5 -389383.03377226    +370.26991430\n",
      "         6 -389295.63905019     +87.39472207\n",
      "         7 -389234.17795571     +61.46109448\n",
      "         8 -389190.69273991     +43.48521580\n",
      "         9 -389174.18183251     +16.51090740\n",
      "        10 -389153.67035414     +20.51147836\n",
      "        11 -389137.82814929     +15.84220485\n",
      "        12 -389122.50480734     +15.32334195\n",
      "        13 -389102.99862797     +19.50617937\n",
      "        14 -389089.26059049     +13.73803748\n",
      "        15 -389081.07536500      +8.18522549\n",
      "        16 -389071.83293656      +9.24242844\n",
      "        17 -389060.01452483     +11.81841173\n",
      "        18 -389055.08680947      +4.92771536\n",
      "        19 -389055.32326283      -0.23645336\n",
      "Model is not converging.  Current: -389055.3232628278 is not greater than -389055.0868094664. Delta is -0.23645336140180007\n",
      "         1 -759619.93930827             +nan\n",
      "         2 -728415.38622972  +31204.55307855\n",
      "         3 -722719.81884894   +5695.56738077\n",
      "         4 -720426.42168426   +2293.39716468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ം\n",
      "332\n",
      "[30, 30, 14, 30, 30, 8, 30, 14, 6, 14, 30, 14, 6, 8, 6, 6, 6, 8, 8, 8, 4, 8, 8, 3, 2, 6, 14, 14, 14, 8, 4, 6, 6, 8, 8, 6, 6, 14, 6, 4, 4, 14, 2, 2, 8, 8, 8, 6, 6, 8, 4, 2, 2, 4, 4, 4, 6, 6, 8, 14, 8, 6, 6, 4, 3, 4, 4, 4, 6, 6, 4, 4, 6, 14, 8, 8, 6, 6, 8, 14, 8, 4, 4, 4, 1, 1, 1, 2, 3, 2, 1, 3, 2, 3, 2, 3, 1, 1, 2, 2, 2, 4, 3, 2, 2, 3, 4, 6, 2, 2, 2, 2, 4, 2, 2, 2, 2, 1, 6, 4, 4, 3, 3, 3, 2, 2, 2, 2, 4, 3, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 6, 2, 3, 1, 1, 1, 1, 6, 2, 3, 1, 2, 2, 3, 1, 4, 1, 2, 4, 3, 2, 2, 2, 1, 2, 4, 4, 2, 6, 6, 1, 2, 2, 2, 3, 3, 3, 1, 1, 4, 2, 2, 6, 30, 14, 30, 14, 14, 30, 14, 14, 14, 14, 30, 30, 8, 8, 6, 14, 14, 14, 8, 14, 30, 8, 14, 30, 14, 14, 30, 14, 14, 30, 14, 8, 8, 8, 6, 6, 8, 8, 6, 8, 8, 4, 8, 8, 6, 6, 14, 8, 6, 8, 8, 8, 6, 14, 30, 14, 14, 8, 14, 30, 14, 14, 8, 6, 6, 8, 8, 3, 3, 8, 8, 8, 8, 8, 6, 6, 8, 4, 6, 4, 6, 8, 14, 14, 14, 8, 6, 8, 4, 6, 6, 8, 8, 4, 6, 3, 6, 6, 8, 6, 4, 14, 14, 14, 14, 4, 8, 4, 8, 8, 6, 8, 6, 6, 6, 4, 3, 6, 6, 6, 6, 4, 6, 4, 8, 8, 4, 6, 6, 14, 14, 30, 8, 6, 6, 4, 8, 8, 14, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         5 -720183.82564290    +242.59604136\n",
      "         6 -720137.05206247     +46.77358043\n",
      "         7 -720124.98380442     +12.06825805\n",
      "         8 -720120.04666862      +4.93713580\n",
      "         9 -720114.00088983      +6.04577878\n",
      "        10 -720112.99712321      +1.00376663\n",
      "        11 -720113.59585779      -0.59873459\n",
      "Model is not converging.  Current: -720113.5958577921 is not greater than -720112.9971232064. Delta is -0.5987345856847242\n",
      "         1 -2182744.06060679             +nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: യ\n",
      "518\n",
      "[14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         2 -2050763.70741947 +131980.35318732\n",
      "         3 -2006227.42122476  +44536.28619471\n",
      "         4 -2000035.18699412   +6192.23423063\n",
      "         5 -1991156.97572567   +8878.21126845\n",
      "         6 -1965798.16452991  +25358.81119576\n",
      "         7 -1926402.08307896  +39396.08145096\n",
      "         8 -1878216.78978582  +48185.29329313\n",
      "         9 -1840074.61703354  +38142.17275228\n",
      "        10 -1806235.67155801  +33838.94547553\n",
      "        11 -1764468.51772984  +41767.15382817\n",
      "        12 -1758878.65215430   +5589.86557554\n",
      "        13 -1758878.44518010      +0.20697420\n",
      "        14 -1758878.32577055      +0.11940955\n",
      "        15 -1758878.26110292      +0.06466763\n",
      "        16 -1758878.22709757      +0.03400535\n",
      "        17 -1758878.20942859      +0.01766898\n",
      "        18 -1758878.20029778      +0.00913081\n",
      "         1 -193053.88247428             +nan\n",
      "         2 -187311.12016764   +5742.76230664\n",
      "         3 -186482.07640601    +829.04376163\n",
      "         4 -186166.71237150    +315.36403451\n",
      "         5 -185985.17435192    +181.53801958\n",
      "         6 -185948.04841723     +37.12593469\n",
      "         7 -185941.24227742      +6.80613981\n",
      "         8 -185940.24717732      +0.99510011\n",
      "         9 -185940.19995914      +0.04721817\n",
      "        10 -185940.41019173      -0.21023259\n",
      "Model is not converging.  Current: -185940.41019173388 is not greater than -185940.19995914146. Delta is -0.2102325924206525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: \"\n",
      "69\n",
      "[4, 4, 6, 6, 8, 6, 4, 4, 6, 2, 2, 8, 4, 4, 14, 8, 6, 6, 8, 8, 8, 6, 4, 6, 8, 3, 6, 4, 8, 8, 8, 1, 1, 6, 4, 2, 3, 2, 2, 3, 2, 1, 1, 30, 14, 8, 30, 14, 30, 8, 14, 30, 14, 14, 30, 14, 30, 14, 14, 30, 14, 8, 8, 8, 8, 8, 8, 6, 14]\n",
      "Model trained for character: ധ\n",
      "203\n",
      "[4, 4, 6, 6, 8, 8, 30, 8, 8, 6, 6, 8, 30, 14, 14, 30, 6, 6, 3, 3, 14, 8, 30, 6, 6, 3, 3, 6, 4, 4, 4, 4, 6, 4, 4, 3, 6, 6, 4, 6, 2, 2, 1, 3, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 4, 4, 14, 30, 14, 6, 6, 6, 6, 14, 30, 14, 30, 4, 4, 8, 8, 6, 6, 30, 30, 14, 4, 4, 6, 6, 6, 6, 4, 4, 6, 6, 4, 4, 2, 2, 3, 3, 14, 6, 4, 4, 3, 3, 4, 4, 3, 3, 4, 4, 4, 4, 14, 14, 6, 14, 14, 2, 2, 4, 4, 14, 8, 14, 8, 3, 3, 4, 4, 3, 3, 4, 4, 14, 14, 14, 14, 8, 8, 6, 4, 4, 14, 8, 14, 14, 3, 3, 4, 4, 2, 2, 3, 3, 4, 4, 4, 4, 14, 14, 8, 8, 6, 6, 4, 4, 6, 6, 14, 8, 2, 2, 2, 2, 3, 3, 8, 8, 6, 6, 6, 6, 2, 2, 2, 2, 4, 4, 14, 6, 6, 8, 8, 6, 8, 14, 2, 2, 3, 3, 4, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -432650.46635325             +nan\n",
      "         2 -421474.17618790  +11176.29016535\n",
      "         3 -416832.84478509   +4641.33140282\n",
      "         4 -412696.90271084   +4135.94207424\n",
      "         5 -411239.82087312   +1457.08183772\n",
      "         6 -411009.97451698    +229.84635614\n",
      "         7 -410852.15673638    +157.81778059\n",
      "         8 -410750.33600935    +101.82072703\n",
      "         9 -410685.62731707     +64.70869229\n",
      "        10 -410640.63837729     +44.98893977\n",
      "        11 -410624.15959212     +16.47878517\n",
      "        12 -410614.05236461     +10.10722751\n",
      "        13 -410605.53410780      +8.51825681\n",
      "        14 -410600.82268543      +4.71142237\n",
      "        15 -410598.14926358      +2.67342185\n",
      "        16 -410596.27680970      +1.87245389\n",
      "        17 -410594.88816141      +1.38864829\n",
      "        18 -410593.79637299      +1.09178841\n",
      "        19 -410592.70913846      +1.08723453\n",
      "        20 -410591.81261246      +0.89652601\n",
      "        21 -410591.15619875      +0.65641370\n",
      "        22 -410590.68764016      +0.46855859\n",
      "        23 -410590.25708371      +0.43055645\n",
      "        24 -410589.65312133      +0.60396239\n",
      "        25 -410588.82848198      +0.82463934\n",
      "        26 -410588.29214249      +0.53633949\n",
      "        27 -410588.05196371      +0.24017878\n",
      "        28 -410587.91765492      +0.13430879\n",
      "        29 -410587.83312055      +0.08453437\n",
      "        30 -410587.77713982      +0.05598073\n",
      "        31 -410587.73896135      +0.03817847\n",
      "        32 -410587.71240986      +0.02655149\n",
      "        33 -410587.69368669      +0.01872317\n",
      "        34 -410587.68034978      +0.01333691\n",
      "        35 -410587.67077888      +0.00957091\n",
      "         1 -183099.35271390             +nan\n",
      "         2 -172993.28224414  +10106.07046976\n",
      "         3 -172049.39404775    +943.88819639\n",
      "         4 -171853.42619370    +195.96785406\n",
      "         5 -171832.44477699     +20.98141670\n",
      "         6 -171801.00610406     +31.43867293\n",
      "         7 -171754.00149883     +47.00460523\n",
      "         8 -171717.01409339     +36.98740545\n",
      "         9 -171700.74165672     +16.27243667\n",
      "        10 -171690.92863355      +9.81302316\n",
      "        11 -171677.86831348     +13.06032007\n",
      "        12 -171665.28953941     +12.57877408\n",
      "        13 -171657.56026353      +7.72927587\n",
      "        14 -171657.10895593      +0.45130760\n",
      "        15 -171658.16242162      -1.05346569\n",
      "Model is not converging.  Current: -171658.16242161609 is not greater than -171657.1089559297. Delta is -1.053465686389245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ച\n",
      "13\n",
      "41\n",
      "[30, 30, 30, 14, 30, 30, 30, 14, 14, 14, 30, 14, 14, 14, 14, 3, 4, 8, 4, 14, 30, 14, 8, 6, 8, 14, 14, 6, 6, 4, 6, 30, 14, 8, 14, 6, 14, 14, 14, 8, 6]\n",
      "Model trained for character: എ\n",
      "269\n",
      "[8, 8, 8, 8, 8, 8, 6, 6, 6, 6, 14, 3, 3, 8, 8, 30, 8, 8, 8, 8, 30, 30, 6, 6, 3, 3, 8, 6, 6, 8, 6, 8, 8, 8, 4, 14, 6, 4, 8, 8, 8, 4, 8, 14, 6, 6, 6, 6, 8, 4, 4, 14, 6, 6, 6, 8, 6, 14, 8, 8, 8, 8, 14, 8, 14, 14, 14, 4, 4, 3, 3, 6, 30, 6, 6, 6, 14, 2, 3, 2, 3, 6, 4, 4, 6, 2, 2, 2, 3, 4, 4, 4, 4, 2, 2, 2, 2, 6, 6, 2, 2, 2, 2, 1, 2, 3, 30, 6, 2, 2, 4, 6, 6, 4, 2, 4, 6, 6, 4, 3, 2, 2, 2, 3, 2, 4, 3, 1, 2, 3, 4, 8, 8, 6, 6, 14, 14, 14, 14, 14, 8, 14, 8, 8, 6, 6, 14, 14, 8, 6, 4, 14, 4, 4, 2, 8, 6, 8, 8, 8, 6, 4, 6, 2, 6, 8, 14, 6, 14, 14, 6, 8, 8, 8, 14, 8, 4, 6, 14, 8, 6, 8, 8, 8, 8, 3, 3, 4, 4, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 8, 14, 14, 8, 6, 6, 6, 6, 6, 6, 6, 8, 4, 4, 14, 8, 14, 14, 8, 4, 8, 8, 3, 8, 4, 8, 8, 14, 6, 6, 4, 4, 8, 8, 14, 14, 14, 14, 8, 14, 14, 14, 14, 14, 8, 8, 6, 14, 14, 8, 6, 6, 14, 30, 6, 6, 3, 3, 3, 3, 14, 8, 6, 6, 8, 8, 6, 4, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -630041.39763199             +nan\n",
      "         2 -614226.67512404  +15814.72250795\n",
      "         3 -601844.40505945  +12382.27006459\n",
      "         4 -600519.53465169   +1324.87040776\n",
      "         5 -600184.90103013    +334.63362156\n",
      "         6 -600032.21791018    +152.68311995\n",
      "         7 -599957.41450559     +74.80340459\n",
      "         8 -599939.31541060     +18.09909499\n",
      "         9 -599924.02180194     +15.29360866\n",
      "        10 -599904.74221371     +19.27958823\n",
      "        11 -599897.62065155      +7.12156216\n",
      "        12 -599893.64689922      +3.97375232\n",
      "        13 -599888.86699493      +4.77990429\n",
      "        14 -599885.31004899      +3.55694594\n",
      "        15 -599883.30488785      +2.00516115\n",
      "        16 -599881.00833991      +2.29654794\n",
      "        17 -599877.55480761      +3.45353230\n",
      "        18 -599875.02623582      +2.52857179\n",
      "        19 -599874.21613766      +0.81009816\n",
      "        20 -599873.82538866      +0.39074900\n",
      "        21 -599873.49926689      +0.32612177\n",
      "        22 -599873.23854595      +0.26072094\n",
      "        23 -599873.04831564      +0.19023032\n",
      "        24 -599872.90788865      +0.14042699\n",
      "        25 -599872.79862985      +0.10925880\n",
      "        26 -599872.71172337      +0.08690648\n",
      "        27 -599872.64300936      +0.06871402\n",
      "        28 -599872.58941593      +0.05359343\n",
      "        29 -599872.54809188      +0.04132405\n",
      "        30 -599872.51645075      +0.03164113\n",
      "        31 -599872.49229614      +0.02415460\n",
      "        32 -599872.47385742      +0.01843872\n",
      "        33 -599872.45975502      +0.01410240\n",
      "        34 -599872.44893595      +0.01081908\n",
      "        35 -599872.44060533      +0.00833061\n",
      "         1 -153324.60362752             +nan\n",
      "         2 -147693.17424671   +5631.42938081\n",
      "         3 -146484.93120583   +1208.24304088\n",
      "         4 -146446.46212073     +38.46908511\n",
      "         5 -146442.23875283      +4.22336789\n",
      "         6 -146425.59023105     +16.64852178\n",
      "         7 -146405.33851876     +20.25171229\n",
      "         8 -146394.20186327     +11.13665549\n",
      "         9 -146393.53112633      +0.67073694\n",
      "        10 -146393.37053612      +0.16059021\n",
      "        11 -146393.16556390      +0.20497222\n",
      "        12 -146392.75440072      +0.41116318\n",
      "        13 -146391.82542978      +0.92897094\n",
      "        14 -146390.35226545      +1.47316434\n",
      "        15 -146389.24720384      +1.10506161\n",
      "        16 -146385.90841044      +3.33879340\n",
      "        17 -146384.97655189      +0.93185854\n",
      "        18 -146384.94450082      +0.03205107\n",
      "        19 -146384.92275615      +0.02174467\n",
      "        20 -146384.89876399      +0.02399216\n",
      "        21 -146384.86077518      +0.03798881\n",
      "        22 -146384.77051110      +0.09026408\n",
      "        23 -146384.42110295      +0.34940815\n",
      "        24 -146382.47893570      +1.94216725\n",
      "        25 -146376.03805846      +6.44087724\n",
      "        26 -146370.62031885      +5.41773962\n",
      "        27 -146370.34382004      +0.27649880\n",
      "        28 -146370.34445427      -0.00063423\n",
      "Model is not converging.  Current: -146370.34445426677 is not greater than -146370.34382004058. Delta is -0.0006342261913232505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ല\n",
      "55\n",
      "[14, 30, 14, 6, 8, 8, 2, 6, 14, 14, 8, 14, 14, 8, 6, 6, 8, 8, 4, 3, 8, 3, 4, 8, 6, 8, 8, 8, 30, 14, 30, 8, 6, 6, 8, 14, 3, 8, 14, 8, 14, 8, 8, 6, 8, 6, 6, 4, 14, 8, 8, 4, 3, 6, 2]\n",
      "Model trained for character: ഴ\n",
      "14\n",
      "185\n",
      "[14, 3, 2, 3, 2, 2, 3, 3, 6, 6, 4, 6, 6, 6, 4, 3, 2, 6, 30, 6, 4, 14, 14, 4, 8, 14, 6, 8, 3, 3, 6, 14, 8, 8, 2, 2, 30, 14, 8, 6, 3, 3, 6, 6, 6, 6, 6, 4, 4, 6, 2, 2, 4, 4, 3, 6, 8, 14, 6, 8, 8, 6, 4, 4, 8, 8, 8, 6, 8, 8, 30, 8, 3, 6, 8, 8, 8, 6, 8, 8, 6, 4, 1, 2, 2, 3, 3, 1, 3, 2, 2, 4, 2, 2, 2, 3, 2, 1, 3, 3, 3, 2, 2, 2, 2, 4, 6, 2, 3, 2, 2, 3, 3, 2, 1, 1, 4, 6, 2, 1, 1, 2, 1, 2, 4, 3, 3, 6, 2, 4, 4, 4, 4, 4, 14, 14, 30, 8, 6, 8, 14, 4, 14, 14, 14, 14, 14, 8, 6, 8, 8, 6, 8, 4, 6, 8, 14, 14, 3, 8, 6, 4, 6, 4, 14, 8, 14, 4, 8, 8, 6, 6, 8, 3, 6, 4, 4, 2, 6, 8, 4, 6, 4, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -355485.74782004             +nan\n",
      "         2 -348992.82911906   +6492.91870098\n",
      "         3 -347023.89363262   +1968.93548643\n",
      "         4 -345435.00228869   +1588.89134394\n",
      "         5 -344540.26881036    +894.73347833\n",
      "         6 -344225.23686625    +315.03194412\n",
      "         7 -344004.51772354    +220.71914270\n",
      "         8 -343833.59446571    +170.92325784\n",
      "         9 -343291.23600828    +542.35845742\n",
      "        10 -342420.24518252    +870.99082577\n",
      "        11 -342181.91906873    +238.32611378\n",
      "        12 -342117.15191428     +64.76715445\n",
      "        13 -342071.93646034     +45.21545394\n",
      "        14 -342017.84404148     +54.09241886\n",
      "        15 -341955.93683469     +61.90720679\n",
      "        16 -341893.33822167     +62.59861302\n",
      "        17 -341814.69387913     +78.64434254\n",
      "        18 -341748.49004058     +66.20383854\n",
      "        19 -341696.39956438     +52.09047620\n",
      "        20 -341638.00806612     +58.39149826\n",
      "        21 -341577.88164356     +60.12642257\n",
      "        22 -341511.46934184     +66.41230172\n",
      "        23 -341459.94859265     +51.52074919\n",
      "        24 -341441.05325194     +18.89534071\n",
      "        25 -341425.84939255     +15.20385939\n",
      "        26 -341415.58184735     +10.26754519\n",
      "        27 -341396.03465592     +19.54719143\n",
      "        28 -341383.85122593     +12.18342999\n",
      "        29 -341378.76465798      +5.08656795\n",
      "        30 -341376.26892966      +2.49572832\n",
      "        31 -341367.79082679      +8.47810286\n",
      "        32 -341358.75542733      +9.03539946\n",
      "        33 -341356.77077362      +1.98465371\n",
      "        34 -341346.29485615     +10.47591746\n",
      "        35 -341314.92720701     +31.36764915\n",
      "        36 -341314.19866309      +0.72854392\n",
      "        37 -341314.04581704      +0.15284604\n",
      "        38 -341313.99024473      +0.05557231\n",
      "        39 -341313.97041031      +0.01983442\n",
      "        40 -341313.96486509      +0.00554522\n",
      "         1 -186898.88898094             +nan\n",
      "         2 -180177.39838252   +6721.49059842\n",
      "         3 -178059.60804158   +2117.79034094\n",
      "         4 -177838.29915708    +221.30888450\n",
      "         5 -177830.18536838      +8.11378870\n",
      "         6 -177829.37276980      +0.81259858\n",
      "         7 -177829.55421561      -0.18144581\n",
      "Model is not converging.  Current: -177829.55421561023 is not greater than -177829.3727697955. Delta is -0.1814458147273399\n",
      "         1  -85768.11775626             +nan\n",
      "         2  -82497.36407931   +3270.75367694\n",
      "         3  -81576.74559887    +920.61848044\n",
      "         4  -81245.37585194    +331.36974693\n",
      "         5  -81204.53220095     +40.84365099\n",
      "         6  -81130.81445873     +73.71774222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ദ\n",
      "122\n",
      "[30, 6, 8, 3, 6, 8, 6, 4, 4, 4, 6, 3, 6, 3, 2, 14, 6, 8, 6, 6, 8, 14, 6, 8, 8, 14, 4, 4, 4, 14, 8, 8, 8, 8, 14, 3, 4, 1, 1, 1, 1, 4, 4, 3, 1, 1, 2, 4, 2, 2, 1, 3, 2, 3, 2, 2, 2, 4, 4, 2, 3, 3, 3, 4, 1, 1, 1, 1, 3, 3, 4, 4, 3, 3, 2, 2, 4, 4, 6, 4, 6, 1, 2, 4, 3, 2, 2, 1, 1, 4, 4, 3, 6, 6, 8, 8, 6, 6, 14, 14, 4, 6, 6, 6, 6, 2, 2, 3, 3, 6, 6, 6, 8, 8, 8, 4, 4, 4, 6, 4, 8, 4]\n",
      "Model trained for character: ഗ\n",
      "24\n",
      "[14, 14, 4, 4, 30, 8, 3, 14, 4, 3, 2, 2, 30, 14, 14, 30, 14, 8, 14, 6, 14, 14, 8, 8]\n",
      "Model trained for character: ഉ\n",
      "153\n",
      "[30, 14, 8, 14, 14, 8, 4, 4, 6, 14, 8, 4, 14, 4, 4, 4, 4, 14, 6, 8, 8, 14, 14, 14, 4, 14, 14, 3, 4, 3, 2, 1, 1, 2, 3, 3, 2, 2, 1, 1, 2, 3, 2, 4, 3, 2, 2, 2, 4, 3, 1, 1, 2, 2, 1, 1, 2, 2, 2, 3, 1, 2, 3, 2, 3, 2, 8, 6, 30, 14, 6, 8, 6, 6, 8, 6, 14, 14, 6, 14, 4, 6, 3, 6, 8, 6, 6, 6, 6, 8, 8, 6, 6, 4, 4, 6, 8, 8, 4, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 30, 4, 4, 6, 6, 8, 14, 6, 6, 6, 6, 6, 6, 8, 8, 4, 4, 14, 8, 6, 4, 8, 14, 14, 8, 4, 4, 6, 14, 30, 6, 6, 6, 6, 4, 4, 6, 6, 6, 14, 8, 8, 8, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         7  -81064.76000739     +66.05445134\n",
      "         8  -81028.11436992     +36.64563747\n",
      "         9  -81004.09178768     +24.02258224\n",
      "        10  -80977.93229771     +26.15948997\n",
      "        11  -80974.85657714      +3.07572057\n",
      "        12  -80974.38696591      +0.46961123\n",
      "        13  -80973.85840887      +0.52855703\n",
      "        14  -80973.64023986      +0.21816902\n",
      "        15  -80973.51633513      +0.12390472\n",
      "        16  -80973.44594325      +0.07039189\n",
      "        17  -80973.41356418      +0.03237907\n",
      "        18  -80973.40021132      +0.01335286\n",
      "        19  -80973.39489921      +0.00531211\n",
      "         1 -311722.47617915             +nan\n",
      "         2 -302593.24050476   +9129.23567439\n",
      "         3 -300055.46044661   +2537.78005815\n",
      "         4 -299660.64810944    +394.81233718\n",
      "         5 -299499.24559907    +161.40251037\n",
      "         6 -299299.55382650    +199.69177257\n",
      "         7 -299224.86595942     +74.68786708\n",
      "         8 -299214.18160462     +10.68435481\n",
      "         9 -299212.59156402      +1.59004060\n",
      "        10 -299211.89159107      +0.69997295\n",
      "        11 -299211.46816935      +0.42342172\n",
      "        12 -299211.27491588      +0.19325347\n",
      "        13 -299211.19576255      +0.07915333\n",
      "        14 -299211.15457899      +0.04118356\n",
      "        15 -299211.13055209      +0.02402689\n",
      "        16 -299211.11594462      +0.01460747\n",
      "        17 -299211.10681599      +0.00912863\n",
      "         1 -156376.43545428             +nan\n",
      "         2 -152271.69121466   +4104.74423962\n",
      "         3 -151684.86267260    +586.82854206\n",
      "         4 -151455.25777319    +229.60489941\n",
      "         5 -151433.49151003     +21.76626316\n",
      "         6 -151425.64747784      +7.84403219\n",
      "         7 -151420.76971887      +4.87775896\n",
      "         8 -151418.26814673      +2.50157215\n",
      "         9 -151413.92982709      +4.33831963\n",
      "        10 -151405.12352655      +8.80630054\n",
      "        11 -151401.26405593      +3.85947062\n",
      "        12 -151399.45401620      +1.81003973\n",
      "        13 -151398.06194457      +1.39207163\n",
      "        14 -151396.58329962      +1.47864494\n",
      "        15 -151393.49087528      +3.09242434\n",
      "        16 -151384.83287065      +8.65800463\n",
      "        17 -151374.81142227     +10.02144838\n",
      "        18 -151369.06006211      +5.75136016\n",
      "        19 -151366.32860030      +2.73146181\n",
      "        20 -151364.92922470      +1.39937561\n",
      "        21 -151363.14920500      +1.78001970\n",
      "        22 -151358.67513931      +4.47406570\n",
      "        23 -151353.78312790      +4.89201140\n",
      "        24 -151351.07063726      +2.71249064\n",
      "        25 -151349.94176538      +1.12887188\n",
      "        26 -151349.47092702      +0.47083836\n",
      "        27 -151349.28844151      +0.18248551\n",
      "        28 -151349.23330790      +0.05513362\n",
      "        29 -151349.23347532      -0.00016743\n",
      "Model is not converging.  Current: -151349.2334753223 is not greater than -151349.2333078964. Delta is -0.000167425925610587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ണ\n",
      "71\n",
      "[14, 3, 3, 6, 6, 6, 8, 6, 4, 3, 6, 8, 4, 4, 8, 14, 30, 8, 8, 8, 8, 6, 6, 6, 2, 2, 2, 3, 6, 3, 4, 14, 8, 14, 8, 14, 14, 14, 4, 8, 6, 4, 3, 8, 6, 6, 8, 8, 8, 4, 6, 4, 3, 8, 8, 6, 8, 4, 6, 14, 8, 4, 8, 8, 6, 6, 14, 8, 6, 4, 8]\n",
      "Model trained for character: ൂ\n",
      "56\n",
      "[30, 8, 2, 30, 2, 3, 6, 14, 14, 8, 14, 14, 30, 30, 14, 14, 8, 14, 14, 14, 14, 8, 8, 14, 14, 14, 14, 4, 6, 8, 8, 8, 8, 8, 8, 8, 8, 14, 8, 8, 8, 8, 14, 14, 8, 8, 6, 14, 8, 6, 14, 8, 8, 4, 8, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -185012.85478524             +nan\n",
      "         2 -180474.82401036   +4538.03077488\n",
      "         3 -179527.92936247    +946.89464789\n",
      "         4 -178144.58226404   +1383.34709843\n",
      "         5 -177811.47450795    +333.10775608\n",
      "         6 -177374.44723631    +437.02727164\n",
      "         7 -177147.72607737    +226.72115894\n",
      "         8 -177043.94352830    +103.78254908\n",
      "         9 -177017.14790158     +26.79562671\n",
      "        10 -177011.20313303      +5.94476855\n",
      "        11 -176998.14549261     +13.05764042\n",
      "        12 -176980.16581096     +17.97968165\n",
      "        13 -176973.71444924      +6.45136172\n",
      "        14 -176969.84234304      +3.87210620\n",
      "        15 -176967.21178902      +2.63055402\n",
      "        16 -176966.41516580      +0.79662322\n",
      "        17 -176965.84085453      +0.57431127\n",
      "        18 -176965.59757783      +0.24327670\n",
      "        19 -176965.52066127      +0.07691655\n",
      "        20 -176965.49088269      +0.02977858\n",
      "        21 -176965.47780012      +0.01308258\n",
      "        22 -176965.47159424      +0.00620587\n",
      "         1 -272206.72306468             +nan\n",
      "         2 -264799.08608091   +7407.63698377\n",
      "         3 -263722.59882056   +1076.48726035\n",
      "         4 -263413.38806029    +309.21076026\n",
      "         5 -263300.15136026    +113.23670004\n",
      "         6 -263269.29424168     +30.85711858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ൻ\n",
      "193\n",
      "[4, 6, 3, 3, 6, 6, 6, 4, 4, 2, 6, 14, 14, 6, 6, 6, 8, 8, 4, 4, 8, 14, 14, 8, 8, 14, 6, 4, 4, 6, 8, 2, 2, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 4, 4, 3, 3, 8, 6, 8, 6, 6, 14, 14, 4, 8, 14, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 8, 8, 14, 8, 8, 2, 2, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 2, 2, 3, 2, 3, 2, 1, 2, 1, 2, 1, 3, 2, 2, 2, 3, 4, 3, 3, 6, 3, 2, 3, 4, 2, 3, 2, 4, 2, 4, 3, 2, 1, 1, 2, 2, 2, 1, 2, 4, 1, 1, 30, 6, 6, 3, 2, 4, 2, 2, 2, 2, 3, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 3, 1, 1, 2, 2, 2, 2, 2, 3, 1, 3, 2, 3, 2, 4, 6, 2, 2, 3, 4, 4, 14, 8, 8, 8, 4, 2, 3, 6, 14, 14, 14, 6, 6, 6, 6, 8, 6, 14, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         7 -263264.14643100      +5.14781068\n",
      "         8 -263263.34852379      +0.79790721\n",
      "         9 -263263.10372463      +0.24479917\n",
      "        10 -263262.97542349      +0.12830114\n",
      "        11 -263262.85307354      +0.12234996\n",
      "        12 -263262.69806543      +0.15500810\n",
      "        13 -263262.49707949      +0.20098594\n",
      "        14 -263262.28752884      +0.20955066\n",
      "        15 -263262.13683667      +0.15069217\n",
      "        16 -263262.02712641      +0.10971026\n",
      "        17 -263261.63889072      +0.38823570\n",
      "        18 -263258.83535043      +2.80354029\n",
      "        19 -263256.51182762      +2.32352282\n",
      "        20 -263256.04163666      +0.47019096\n",
      "        21 -263255.83622981      +0.20540685\n",
      "        22 -263255.74113920      +0.09509060\n",
      "        23 -263255.68700319      +0.05413601\n",
      "        24 -263255.65005924      +0.03694395\n",
      "        25 -263255.62132061      +0.02873863\n",
      "        26 -263255.59656552      +0.02475509\n",
      "        27 -263255.57346826      +0.02309726\n",
      "        28 -263255.55060629      +0.02286198\n",
      "        29 -263255.52709364      +0.02351265\n",
      "        30 -263255.50248318      +0.02461046\n",
      "        31 -263255.47678287      +0.02570030\n",
      "        32 -263255.45045690      +0.02632598\n",
      "        33 -263255.42429410      +0.02616280\n",
      "        34 -263255.39913272      +0.02516138\n",
      "        35 -263255.37559070      +0.02354202\n",
      "        36 -263255.35396749      +0.02162321\n",
      "        37 -263255.33431602      +0.01965147\n",
      "        38 -263255.31656142      +0.01775460\n",
      "        39 -263255.30058090      +0.01598052\n",
      "        40 -263255.28623890      +0.01434200\n",
      "        41 -263255.27339974      +0.01283916\n",
      "        42 -263255.26193259      +0.01146715\n",
      "        43 -263255.25171383      +0.01021876\n",
      "        44 -263255.24262808      +0.00908575\n",
      "         1 -187721.86871535             +nan\n",
      "         2 -182434.79680405   +5287.07191129\n",
      "         3 -181166.83407375   +1267.96273030\n",
      "         4 -180914.31603305    +252.51804070\n",
      "         5 -180875.16720813     +39.14882492\n",
      "         6 -180857.64664420     +17.52056393\n",
      "         7 -180828.04948276     +29.59716144\n",
      "         8 -180814.33561588     +13.71386689\n",
      "         9 -180800.29648061     +14.03913527\n",
      "        10 -180795.09039011      +5.20609050\n",
      "        11 -180789.29648389      +5.79390622\n",
      "        12 -180785.10512268      +4.19136121\n",
      "        13 -180784.17605857      +0.92906411\n",
      "        14 -180784.12989912      +0.04615946\n",
      "        15 -180784.15854623      -0.02864712\n",
      "Model is not converging.  Current: -180784.15854623474 is not greater than -180784.12989911903. Delta is -0.028647115716012195\n",
      "         1 -158682.01621955             +nan\n",
      "         2 -154839.39585700   +3842.62036255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: സ\n",
      "127\n",
      "[3, 6, 6, 14, 6, 4, 8, 6, 3, 8, 8, 8, 14, 6, 6, 6, 8, 8, 8, 3, 4, 6, 6, 6, 6, 4, 6, 8, 4, 4, 6, 6, 8, 8, 14, 4, 3, 6, 8, 8, 6, 8, 8, 8, 8, 6, 3, 1, 1, 1, 1, 1, 2, 2, 4, 2, 3, 2, 2, 1, 1, 2, 2, 2, 3, 6, 4, 2, 2, 4, 2, 3, 1, 4, 2, 2, 2, 2, 2, 2, 3, 14, 2, 2, 4, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 4, 2, 3, 3, 3, 2, 2, 3, 2, 4, 4, 14, 4, 4, 6, 4, 4, 6, 8, 8, 4, 6, 6, 8, 14, 8, 6, 8, 4, 6, 6, 6]\n",
      "Model trained for character: ീ\n",
      "1\n",
      "84\n",
      "[6, 3, 2, 2, 6, 6, 8, 4, 4, 6, 8, 8, 6, 3, 3, 2, 6, 6, 6, 6, 6, 6, 8, 4, 14, 8, 14, 4, 8, 14, 14, 14, 4, 6, 6, 14, 8, 8, 6, 8, 6, 6, 4, 4, 3, 2, 1, 1, 6, 3, 2, 3, 3, 1, 1, 3, 2, 2, 2, 2, 3, 2, 2, 2, 3, 3, 6, 2, 2, 1, 14, 14, 30, 8, 8, 8, 8, 8, 14, 8, 6, 6, 8, 8]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         3 -154040.45812820    +798.93772880\n",
      "         4 -153858.46399258    +181.99413563\n",
      "         5 -153819.70048006     +38.76351252\n",
      "         6 -153788.74025408     +30.96022597\n",
      "         7 -153782.43556150      +6.30469259\n",
      "         8 -153782.32875316      +0.10680833\n",
      "         9 -153782.32591863      +0.00283453\n",
      "         1  -36752.79685349             +nan\n",
      "         2  -34729.99268653   +2022.80416696\n",
      "         3  -34720.82229770      +9.17038883\n",
      "         4  -34720.02406307      +0.79823463\n",
      "         5  -34718.80221363      +1.22184945\n",
      "         6  -34716.53046238      +2.27175125\n",
      "         7  -34714.99486512      +1.53559726\n",
      "         8  -34714.95864267      +0.03622245\n",
      "         9  -34714.95858857      +0.00005410\n",
      "         1 -192825.85958453             +nan\n",
      "         2 -186992.88807166   +5832.97151287\n",
      "         3 -186538.74204628    +454.14602538\n",
      "         4 -186464.54533670     +74.19670959\n",
      "         5 -186446.31950070     +18.22583600\n",
      "         6 -186428.90899264     +17.41050805\n",
      "         7 -186407.33322878     +21.57576386\n",
      "         8 -186373.37785149     +33.95537729\n",
      "         9 -186366.97984040      +6.39801109\n",
      "        10 -186365.96217245      +1.01766795\n",
      "        11 -186364.22946577      +1.73270668\n",
      "        12 -186363.35013407      +0.87933170\n",
      "        13 -186363.50910716      -0.15897309\n",
      "Model is not converging.  Current: -186363.50910716428 is not greater than -186363.3501340699. Delta is -0.15897309439606033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ഭ\n",
      "21\n",
      "[8, 8, 6, 6, 8, 14, 8, 8, 14, 8, 1, 2, 2, 4, 4, 4, 2, 4, 3, 2, 3]\n",
      "Model trained for character: ഖ\n",
      "114\n",
      "[6, 3, 2, 3, 4, 6, 8, 8, 6, 4, 14, 14, 6, 8, 2, 2, 6, 6, 4, 3, 6, 6, 6, 14, 14, 14, 14, 3, 1, 1, 1, 2, 2, 1, 1, 3, 2, 4, 3, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 2, 2, 4, 4, 3, 2, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 1, 6, 2, 2, 3, 6, 2, 2, 3, 3, 2, 1, 2, 2, 2, 2, 1, 1, 30, 14, 14, 8, 14, 14, 14, 6, 14, 8, 14, 6, 14, 14, 14, 14, 6, 6, 6, 8, 8, 4, 30, 14, 6, 8, 8, 4, 4]\n",
      "Model trained for character: ശ\n",
      "44\n",
      "[14, 14, 30, 8, 14, 14, 14, 14, 6, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 3, 1, 2, 2, 4, 3, 4, 6, 30, 30, 30, 30, 14, 14, 14, 30, 14, 8, 14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         1 -187941.14532805             +nan\n",
      "         2 -183928.06097129   +4013.08435677\n",
      "         3 -182825.96827722   +1102.09269407\n",
      "         4 -182126.80382680    +699.16445042\n",
      "         5 -181984.46332105    +142.34050574\n",
      "         6 -181876.65536500    +107.80795605\n",
      "         7 -181793.94016475     +82.71520026\n",
      "         8 -181730.54737591     +63.39278884\n",
      "         9 -181712.11808976     +18.42928614\n",
      "        10 -181701.77730711     +10.34078265\n",
      "        11 -181690.20130363     +11.57600349\n",
      "        12 -181688.02320366      +2.17809996\n",
      "        13 -181682.12111234      +5.90209132\n",
      "        14 -181675.66050491      +6.46060743\n",
      "        15 -181671.76299103      +3.89751388\n",
      "        16 -181663.40789806      +8.35509296\n",
      "        17 -181649.08986454     +14.31803352\n",
      "        18 -181636.96911122     +12.12075332\n",
      "        19 -181628.67682494      +8.29228628\n",
      "        20 -181603.78214996     +24.89467498\n",
      "        21 -181596.30972189      +7.47242808\n",
      "        22 -181593.90012768      +2.40959421\n",
      "        23 -181592.86281583      +1.03731184\n",
      "        24 -181591.83454355      +1.02827228\n",
      "        25 -181588.58591836      +3.24862519\n",
      "        26 -181583.37797909      +5.20793927\n",
      "        27 -181571.29502803     +12.08295105\n",
      "        28 -181568.66781818      +2.62720985\n",
      "        29 -181559.14217923      +9.52563895\n",
      "        30 -181533.34769125     +25.79448798\n",
      "        31 -181503.90877992     +29.43891133\n",
      "        32 -181434.50646493     +69.40231499\n",
      "        33 -181377.91364544     +56.59281949\n",
      "        34 -181355.84474883     +22.06889661\n",
      "        35 -181336.99069227     +18.85405656\n",
      "        36 -181303.49106386     +33.49962842\n",
      "        37 -181283.88960863     +19.60145523\n",
      "        38 -181262.00239320     +21.88721543\n",
      "        39 -181256.72493070      +5.27746251\n",
      "        40 -181251.16827968      +5.55665101\n",
      "        41 -181248.98557690      +2.18270278\n",
      "        42 -181246.37086897      +2.61470794\n",
      "        43 -181243.92565057      +2.44521840\n",
      "        44 -181243.59879173      +0.32685884\n",
      "        45 -181243.41093908      +0.18785265\n",
      "        46 -181243.26909055      +0.14184853\n",
      "        47 -181243.13749066      +0.13159989\n",
      "        48 -181242.98788368      +0.14960698\n",
      "        49 -181242.77823207      +0.20965161\n",
      "        50 -181242.40105937      +0.37717270\n",
      "        51 -181241.41695428      +0.98410508\n",
      "        52 -181237.96394996      +3.45300433\n",
      "        53 -181230.32798550      +7.63596446\n",
      "        54 -181218.34016286     +11.98782264\n",
      "        55 -181211.43167528      +6.90848758\n",
      "        56 -181205.66868105      +5.76299423\n",
      "        57 -181198.72867808      +6.94000297\n",
      "        58 -181189.11512848      +9.61354960\n",
      "        59 -181140.14442130     +48.97070718\n",
      "        60 -181120.28642537     +19.85799594\n",
      "        61 -181099.68818136     +20.59824401\n",
      "        62 -181080.58189034     +19.10629102\n",
      "        63 -181054.20001879     +26.38187154\n",
      "        64 -181016.53715100     +37.66286779\n",
      "        65 -180969.21935389     +47.31779712\n",
      "        66 -180948.29058377     +20.92877011\n",
      "        67 -180947.54846430      +0.74211947\n",
      "        68 -180947.35837094      +0.19009337\n",
      "        69 -180947.22320884      +0.13516210\n",
      "        70 -180947.15151831      +0.07169054\n",
      "        71 -180947.12725355      +0.02426476\n",
      "        72 -180947.12048369      +0.00676986\n",
      "         1  -53110.06836301             +nan\n",
      "         2  -51682.70899476   +1427.35936824\n",
      "         3  -51665.11800533     +17.59098943\n",
      "         4  -51653.49607571     +11.62192962\n",
      "         5  -51644.96481209      +8.53126362\n",
      "         6  -51637.70894757      +7.25586452\n",
      "         7  -51552.00968996     +85.69925760\n",
      "         8  -51486.42220973     +65.58748023\n",
      "         9  -51317.99254117    +168.42966856\n",
      "        10  -51206.23052856    +111.76201260\n",
      "        11  -51206.23052856      +0.00000000\n",
      "         1  -73181.11775851             +nan\n",
      "         2  -70974.00412802   +2207.11363049\n",
      "         3  -70732.90815842    +241.09596960\n",
      "         4  -70425.14071297    +307.76744544\n",
      "         5  -70302.28486199    +122.85585098\n",
      "         6  -70264.22138791     +38.06347408\n",
      "         7  -70256.17018310      +8.05120480\n",
      "         8  -70256.07170657      +0.09847653\n",
      "         9  -70256.07017391      +0.00153265\n",
      "         1  -26888.01140851             +nan\n",
      "         2  -25528.45414120   +1359.55726731\n",
      "         3  -25163.04199035    +365.41215086\n",
      "         4  -25122.13601484     +40.90597551\n",
      "         5  -25117.62696141      +4.50905342\n",
      "         6  -25111.27997348      +6.34698793\n",
      "         7  -25111.24172945      +0.03824404\n",
      "         8  -25111.24172856      +0.00000089\n",
      "         1  -98288.49052133             +nan\n",
      "         2  -95338.43888933   +2950.05163200\n",
      "         3  -94734.35148947    +604.08739986\n",
      "         4  -94430.81775124    +303.53373823\n",
      "         5  -94403.73579350     +27.08195774\n",
      "         6  -94391.96939202     +11.76640148\n",
      "         7  -94379.99583754     +11.97355448\n",
      "         8  -94374.68878282      +5.30705473\n",
      "         9  -94371.92994142      +2.75884140\n",
      "        10  -94371.01541521      +0.91452620\n",
      "        11  -94370.05769878      +0.95771644\n",
      "        12  -94365.66373482      +4.39396396\n",
      "        13  -94355.02015486     +10.64357996\n",
      "        14  -94342.42719606     +12.59295881\n",
      "        15  -94337.63570199      +4.79149407\n",
      "        16  -94314.36608871     +23.26961328\n",
      "        17  -94312.52997353      +1.83611518\n",
      "        18  -94312.44127396      +0.08869957\n",
      "        19  -94312.39355296      +0.04772100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ൈ\n",
      "23\n",
      "[6, 8, 6, 14, 4, 4, 14, 30, 8, 4, 6, 8, 14, 14, 14, 4, 2, 3, 6, 2, 3, 2, 2]\n",
      "Model trained for character: ഥ\n",
      "26\n",
      "[4, 6, 14, 6, 30, 14, 14, 8, 6, 8, 6, 8, 14, 6, 6, 14, 3, 6, 6, 14, 6, 14, 4, 8, 8, 14]\n",
      "Model trained for character: ൾ\n",
      "16\n",
      "[8, 4, 6, 6, 3, 2, 3, 6, 30, 2, 3, 2, 6, 4, 4, 2]\n",
      "Model trained for character: ഘ\n",
      "62\n",
      "[3, 8, 3, 6, 3, 6, 3, 8, 6, 14, 8, 2, 8, 8, 8, 1, 2, 3, 1, 1, 1, 2, 3, 2, 2, 3, 3, 3, 3, 1, 3, 1, 2, 2, 14, 14, 14, 8, 4, 4, 4, 6, 6, 8, 4, 8, 4, 4, 3, 8, 4, 8, 8, 6, 8, 8, 6, 6, 4, 8, 4, 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        20  -94312.23931879      +0.15423417\n",
      "        21  -94311.31718638      +0.92213241\n",
      "        22  -94303.04618564      +8.27100074\n",
      "        23  -94294.39321038      +8.65297525\n",
      "        24  -94294.39146581      +0.00174458\n",
      "         1 -106316.47777319             +nan\n",
      "         2 -102994.90026130   +3321.57751189\n",
      "         3 -102636.86912307    +358.03113822\n",
      "         4 -102623.90092325     +12.96819982\n",
      "         5 -102623.12008831      +0.78083495\n",
      "         6 -102621.52594663      +1.59414168\n",
      "         7 -102621.52898655      -0.00303993\n",
      "Model is not converging.  Current: -102621.52898655119 is not greater than -102621.52594662542. Delta is -0.0030399257666431367\n",
      "         1  -35779.54320628             +nan\n",
      "         2  -34692.02719070   +1087.51601559\n",
      "         3  -34221.07755095    +470.94963975\n",
      "         4  -34185.73225070     +35.34530025\n",
      "         5  -34173.74117660     +11.99107409\n",
      "         6  -34151.43129742     +22.30987919\n",
      "         7  -34151.43129665      +0.00000077\n",
      "         1  -44999.04843215             +nan\n",
      "         2  -44034.58658467    +964.46184748\n",
      "         3  -43877.65997227    +156.92661240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained for character: ൃ\n",
      "8\n",
      "12\n",
      "3\n",
      "54\n",
      "[14, 14, 14, 14, 14, 14, 3, 3, 4, 6, 3, 2, 4, 3, 4, 6, 4, 4, 4, 6, 4, 4, 3, 2, 3, 4, 6, 3, 6, 2, 4, 3, 6, 3, 3, 2, 4, 6, 4, 6, 2, 6, 4, 6, 2, 6, 6, 14, 14, 14, 14, 14, 14, 14]\n",
      "Model trained for character: ൊ\n",
      "5\n",
      "22\n",
      "[6, 8, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2, 6, 6, 6, 6, 6, 8, 14, 14, 14]\n",
      "Model trained for character: ഞ\n",
      "1\n",
      "26\n",
      "[8, 14, 8, 4, 4, 3, 1, 3, 4, 6, 4, 6, 6, 6, 6, 8, 6, 6, 6, 6, 6, 8, 6, 6, 4, 6]\n",
      "Model trained for character: ബ\n",
      "4\n",
      "25\n",
      "[2, 2, 4, 2, 2, 4, 4, 4, 3, 3, 2, 3, 2, 3, 3, 1, 1, 1, 1, 1, 4, 4, 2, 2, 2]\n",
      "Model trained for character: ഃ\n",
      "11\n",
      "3\n",
      "11\n",
      "1\n",
      "2\n",
      "3\n",
      "2\n",
      "1\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "         4  -43847.95687326     +29.70309901\n",
      "         5  -43809.42389012     +38.53298314\n",
      "         6  -43794.03801501     +15.38587511\n",
      "         7  -43778.44004917     +15.59796585\n",
      "         8  -43778.41103903      +0.02901014\n",
      "         9  -43778.40498327      +0.00605576\n",
      "         1  -18024.21101202             +nan\n",
      "         2  -17200.48334301    +823.72766901\n",
      "         3  -17097.38123503    +103.10210798\n",
      "         4  -17093.95789462      +3.42334041\n",
      "         5  -17093.95789005      +0.00000456\n"
     ]
    }
   ],
   "source": [
    "character_hmms = {}\n",
    "num_states = 4\n",
    "\n",
    "# Example: 'character_glcm_sequences' contains the GLCM feature sequences for each character\n",
    "for char, sequences in combined_features_glcm_and_dct.items():\n",
    "    # Remove empty sequences\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "    print(len(sequences))\n",
    "    if len(sequences) == 0:\n",
    "        print(f\"Warning: No valid sequences for character {char}. Skipping this character.\")\n",
    "        continue  # Skip to the next character if no valid sequences\n",
    "    \n",
    "    if len(sequences) >= 15:\n",
    "        # Prepare training data for the HMM\n",
    "        X = np.vstack(sequences)  # Stack the sequences into a single array\n",
    "        lengths = [len(seq) for seq in sequences]  # Length of each sequence\n",
    "        print(lengths)\n",
    "        # Initialize HMM for this character\n",
    "        model = hmm.GaussianHMM(n_components=num_states, covariance_type=\"diag\", n_iter=1000, init_params='', verbose=True)\n",
    "\n",
    "\n",
    "        # Use the custom model\n",
    "        model.fit(X, lengths)\n",
    "\n",
    "        # Store the trained model\n",
    "        character_hmms[char] = model\n",
    "        print(f\"Model trained for character: {char}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View the transition matrix after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.77777778e-001 3.88732678e-034 2.22222222e-001 7.44031374e-315]\n",
      " [2.23813875e-030 1.00000000e+000 2.74791074e-044 0.00000000e+000]\n",
      " [1.63716042e-053 2.64584386e-056 1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 1.00000000e+000]]\n",
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(model.transmat_)  \n",
    "row_sums = model.transmat_.sum(axis=1)\n",
    "print(row_sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the trained HMM model to a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "െ െ\n",
      "ത ത\n",
      "അ അ\n",
      "് ്\n",
      "ാ ാ\n",
      "ി ി\n",
      "പ പ\n",
      "റ റ\n",
      "ര ര\n",
      "ു ു\n",
      "ള ള\n",
      "ക ക\n",
      "ഷ ഷ\n",
      "മ മ\n",
      "ആ ആ\n",
      "ഠ ഠ\n",
      "ൽ ൽ\n",
      "ർ ർ\n",
      "ഇ ഇ\n",
      "ങ ങ\n",
      "ന ന\n",
      "ജ ജ\n",
      "ട ട\n",
      "വ വ\n",
      "ഹ ഹ\n",
      "ം ം\n",
      "യ യ\n",
      "\" _\n",
      "ധ ധ\n",
      "ച ച\n",
      "എ എ\n",
      "ല ല\n",
      "ഴ ഴ\n",
      "ദ ദ\n",
      "ഗ ഗ\n",
      "ഉ ഉ\n",
      "ണ ണ\n",
      "ൂ ൂ\n",
      "ൻ ൻ\n",
      "സ സ\n",
      "ീ ീ\n",
      "ഭ ഭ\n",
      "ഖ ഖ\n",
      "ശ ശ\n",
      "ൈ ൈ\n",
      "ഥ ഥ\n",
      "ൾ ൾ\n",
      "ഘ ഘ\n",
      "ൃ ൃ\n",
      "ൊ ൊ\n",
      "ഞ ഞ\n",
      "ബ ബ\n",
      "ഃ ഃ\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Assuming your models are in a dictionary called `character_hmms`\n",
    "# e.g., `character_hmms = {'െ': trained_model_1, 'ത': trained_model_2, ... }\n",
    "\n",
    "def sanitize_filename(char):\n",
    "    # Replace invalid filename characters with an underscore or remove them\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '_', char)\n",
    "\n",
    "# Ensure the directory for the models exists\n",
    "model_directory = '//home//jaykishor_c//ml//Model_combined'\n",
    "os.makedirs(model_directory, exist_ok=True)\n",
    "\n",
    "for char, model in character_hmms.items():\n",
    "    # Sanitize character to create a valid filename\n",
    "    sanitized_char = sanitize_filename(char)\n",
    "    print(char, sanitized_char)\n",
    "    # Save the trained HMM model to a file with the sanitized name in the 'model' directory\n",
    "    model_path = os.path.join(model_directory, f\"{sanitized_char}_hmm.pkl\")\n",
    "    dump(model, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 56)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing shell 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual sequence: വവവവവവവവൃൃൃൃൃൃൃൃഥഥഥഥഥഥഥഥ\n",
      "Predicted sequence: ദസിവദദമദ്്ൂസസളളസൈൈഭഭർർർ്ർസസർമസ\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from hmmlearn import hmm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    " \n",
    "# Function to compute the actual sequence based on window mapping\n",
    "# Function to extract the actual sequence for a specific image from the DataFrame\n",
    "def get_actual_sequence_from_df(image_name, line_image, gt_df, window_width=30, step_size=10):\n",
    "    # Find the corresponding row in the DataFrame\n",
    "    row = gt_df[gt_df['image name'] == image_name]\n",
    "    if row.empty:\n",
    "        raise ValueError(f\"Image name '{image_name}' not found in the gts DataFrame.\")\n",
    "    # Extract the ground truth character sequence\n",
    "    character_sequence = row['gt'].values[0]  # Adjust column name if necessary\n",
    "    # Compute the actual sequence based on ground truth and image dimensions\n",
    "    actual_sequence = []\n",
    "    image_width = line_image.shape[1]\n",
    "    num_characters = len(character_sequence)\n",
    "    character_width = image_width // num_characters\n",
    " \n",
    "    for i, char in enumerate(character_sequence):\n",
    "        # Define the region corresponding to this character\n",
    "        region_start = i * character_width\n",
    "        region_end = region_start + character_width\n",
    "        character_region = line_image[:, region_start:region_end]\n",
    " \n",
    "        # Divide the character region into windows\n",
    "        num_windows = (character_width - window_width) // step_size + 1\n",
    "        for _ in range(num_windows):\n",
    "            actual_sequence.append(char)  # Map each window to the current character\n",
    "    return actual_sequence\n",
    "# Function to predict the sequence based on HMM models\n",
    "def predict_line_sequence(line_image, window_width=30, step_size=10):\n",
    "    predictions = []\n",
    "    image_width = line_image.shape[1]\n",
    "    num_windows = (image_width - window_width) // step_size + 1\n",
    " \n",
    "    for i in range(num_windows):\n",
    "        window_start = i * step_size\n",
    "        window_end = window_start + window_width\n",
    "        window = line_image[:, window_start:window_end]\n",
    "        test_features = compute_combined_features(window)\n",
    " \n",
    "        test_features = test_features.reshape(1, -1) \n",
    "\n",
    " \n",
    "        # Calculate likelihoods for each character model\n",
    "        best_char = None\n",
    "        best_score = float('-inf')\n",
    " \n",
    "        for char, model in character_hmms.items():\n",
    "            try:\n",
    "                score = model.score(test_features )\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_char = char\n",
    "            except:\n",
    "                pass  # Ignore errors for invalid model scoring\n",
    " \n",
    "        if best_char is not None:\n",
    "            predictions.append(best_char)\n",
    " \n",
    "    return ''.join(predictions)\n",
    " \n",
    "# Test image details\n",
    "# Load the gts DataFrame\n",
    "gt_file = r\"//home//jaykishor_c//ml//gt_WIndow .xlsx\"\n",
    "gt_df = pd.read_excel(gt_file)\n",
    "\n",
    "# Test image details\n",
    "test_image_path = r\"//home//jaykishor_c//ml//color_window_double1//color_window_double1//MaI14_007_3.jpg_window_2.jpg\"\n",
    "test_image_name = test_image_path.split(\"/\")[-1]  # Correctly extracts the image name by splitting on '/'\n",
    "\n",
    "# print(\"test image name : \", test_image_name)\n",
    "# print(\"Data frame image name : \", gt_df['image name'])\n",
    " \n",
    "# Load the test image\n",
    "test_image = cv2.imread(test_image_path, cv2.IMREAD_GRAYSCALE)\n",
    " \n",
    "# Extract the actual sequence from the DataFrame\n",
    "actual_sequence = get_actual_sequence_from_df(test_image_name, test_image, gt_df)\n",
    " \n",
    "# Predict the sequence using the HMM models\n",
    "predicted_sequence = predict_line_sequence(test_image)\n",
    " \n",
    "# Print the sequences for comparison\n",
    "print(f\"Actual sequence: {''.join(actual_sequence)}\")\n",
    "print(f\"Predicted sequence: {predicted_sequence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the character names from the character_hmms dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character names: ['െ', 'ത', 'അ', '്', 'ാ', 'ി', 'പ', 'റ', 'ര', 'ു', 'ള', 'ക', 'ഷ', 'മ', 'ആ', 'ഠ', 'ൽ', 'ർ', 'ഇ', 'ങ', 'ന', 'ജ', 'ട', 'വ', 'ഹ', 'ം', 'യ', '\"', 'ധ', 'ച', 'എ', 'ല', 'ഴ', 'ദ', 'ഗ', 'ഉ', 'ണ', 'ൂ', 'ൻ', 'സ', 'ീ', 'ഭ', 'ഖ', 'ശ', 'ൈ', 'ഥ', 'ൾ', 'ഘ', 'ൃ', 'ൊ', 'ഞ', 'ബ', 'ഃ']\n"
     ]
    }
   ],
   "source": [
    "char_names = list(character_hmms.keys())\n",
    "\n",
    "# Print the character names\n",
    "print(\"Character names:\", char_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(char_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth =char_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth list: ['െ', 'ത', 'അ', '്', 'ാ', 'ി', 'പ', 'റ', 'ര', 'ു', 'ള', 'ക', 'ഷ', 'മ', 'ആ', 'ഠ', 'ൽ', 'ർ', 'ഇ', 'ങ', 'ന', 'ജ', 'ട', 'വ', 'ഹ', 'ം', 'യ', '\"', 'ധ', 'ച', 'എ', 'ല', 'ഴ', 'ദ', 'ഗ', 'ഉ', 'ണ', 'ൂ', 'ൻ', 'സ', 'ീ', 'ഭ', 'ഖ', 'ശ', 'ൈ', 'ഥ', 'ൾ', 'ഘ', 'ൃ', 'ൊ', 'ഞ', 'ബ', 'ഃ']\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground truth list:\", ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting 'character to state' and 'state to character'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_chars = sorted(set(\"\".join(ground_truth)))\n",
    "char_to_state = {char: idx for idx, char in enumerate(unique_chars)}\n",
    "state_to_char = {idx: char for char, idx in char_to_state.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing shel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaI14_007_4.jpg_window_16.jpg,   |   64.29%\n",
      "MaI14_007_9.jpg_window_31.jpg,   |   0.00%\n",
      "MaI14_051_07.jpg_window_16.jpg,   |   0.00%\n",
      "MaI12_Page102_line_3.jpg_window_32.jpg,   |   8.33%\n",
      "MaI849_041_line_5.jpg_window_51.jpg,   |   5.00%\n",
      "MaI849_038_line_5.jpg_window_23.jpg,   |   4.17%\n",
      "MaI14_051_04.jpg_window_40.jpg,   |   92.86%\n",
      "MaI12_Page101_line_1.jpg_window_39.jpg,   |   6.67%\n",
      "MaI14_007_6.jpg_window_16.jpg,   |   82.14%\n",
      "MaI12_Page101_line_5.jpg_window_40.jpg,   |   10.71%\n",
      "MaI849_039_line_8.jpg_window_32.jpg,   |   12.50%\n",
      "MaI849_041_line_7.jpg_window_50.jpg,   |   0.00%\n",
      "MaI849_041_line_2.jpg_window_27.jpg,   |   10.71%\n",
      "MaI849_038_line_3.jpg_window_7.jpg,   |   32.14%\n",
      "MaI12_Page101_line_5.jpg_window_49.jpg,   |   60.00%\n",
      "MaI12_Page101_line_4.jpg_window_37.jpg,   |   0.00%\n",
      "maI16_01_4.jpg_window_39.jpg,   |   12.50%\n",
      "maI16_01_7.jpg_window_14.jpg,   |   28.57%\n",
      "maI16_01_5.jpg_window_25.jpg,   |   14.29%\n",
      "MaI14_051_03.jpg_window_48.jpg,   |   20.83%\n",
      "MaI12_Page102_line_5.jpg_window_22.jpg,   |   12.50%\n",
      "maI16_01_1.jpg_window_51.jpg,   |   25.00%\n",
      "MaI14_051_05.jpg_window_17.jpg,   |   53.57%\n",
      "MaI849_039_line_9.jpg_window_30.jpg,   |   14.29%\n",
      "maI16_01_7.jpg_window_20.jpg,   |   21.43%\n",
      "MaI14_007_9.jpg_window_45.jpg,   |   5.00%\n",
      "MaI12_Page102_line_1.jpg_window_38.jpg,   |   70.00%\n",
      "MaI849_038_line_4.jpg_window_40.jpg,   |   8.33%\n",
      "MaI849_038_line_9.jpg_window_21.jpg,   |   17.86%\n",
      "MaI849_038_line_8.jpg_window_40.jpg,   |   7.14%\n",
      "MaI849_041_line_9.jpg_window_42.jpg,   |   8.33%\n",
      "MaI14_007_1.jpg_window_40.jpg,   |   25.00%\n",
      "MaI12_Page102_line_1.jpg_window_37.jpg,   |   25.00%\n",
      "MaI12_Page102_line_1.jpg_window_20.jpg,   |   50.00%\n",
      "maI16_01_9.jpg_window_38.jpg,   |   12.50%\n",
      "maI16_01_1.jpg_window_33.jpg,   |   5.56%\n",
      "MaI14_007_9.jpg_window_15.jpg,   |   16.67%\n",
      "MaI14_007_3.jpg_window_32.jpg,   |   7.14%\n",
      "MaI849_041_line_1.jpg_window_43.jpg,   |   10.00%\n",
      "MaI849_039_line_9.jpg_window_35.jpg,   |   25.00%\n",
      "MaI12_Page102_line_3.jpg_window_7.jpg,   |   7.14%\n",
      "MaI14_051_06.jpg_window_12.jpg,   |   71.43%\n",
      "MaI849_039_line_2.jpg_window_2.jpg,   |   10.71%\n",
      "MaI14_007_2.jpg_window_7.jpg,   |   8.33%\n",
      "MaI849_041_line_9.jpg_window_50.jpg,   |   46.43%\n",
      "MaI12_Page101_line_5.jpg_window_28.jpg,   |   7.14%\n",
      "MaI12_Page100_line_1.jpg_window_35.jpg,   |   14.29%\n",
      "MaI14_051_08.jpg_window_28.jpg,   |   16.67%\n",
      "MaI849_041_line_4.jpg_window_16.jpg,   |   5.00%\n",
      "MaI849_039_line_7.jpg_window_15.jpg,   |   0.00%\n",
      "MaI14_007_1.jpg_window_43.jpg,   |   25.00%\n",
      "MaI12_Page101_line_5.jpg_window_13.jpg,   |   3.57%\n",
      "MaI14_051_07.jpg_window_13.jpg,   |   20.83%\n",
      "MaI14_007_5.jpg_window_20.jpg,   |   14.29%\n",
      "MaI12_Page101_line_5.jpg_window_29.jpg,   |   16.67%\n",
      "maI16_01_2.jpg_window_8.jpg,   |   0.00%\n",
      "maI16_01_8.jpg_window_47.jpg,   |   14.29%\n",
      "MaI14_051_05.jpg_window_27.jpg,   |   8.33%\n",
      "MaI849_039_line_6.jpg_window_6.jpg,   |   7.14%\n",
      "MaI849_041_line_4.jpg_window_0.jpg,   |   7.14%\n",
      "MaI12_Page102_line_1.jpg_window_15.jpg,   |   70.00%\n",
      "MaI12_Page101_line_5.jpg_window_26.jpg,   |   17.86%\n",
      "MaI849_039_line_1.jpg_window_15.jpg,   |   14.29%\n",
      "MaI14_007_3.jpg_window_1.jpg,   |   5.56%\n",
      "maI16_01_3.jpg_window_31.jpg,   |   0.00%\n",
      "maI16_01_2.jpg_window_9.jpg,   |   5.00%\n",
      "MaI849_039_line_6.jpg_window_4.jpg,   |   12.50%\n",
      "MaI12_Page101_line_5.jpg_window_11.jpg,   |   32.14%\n",
      "MaI14_051_04.jpg_window_39.jpg,   |   82.14%\n",
      "MaI12_Page102_line_3.jpg_window_50.jpg,   |   17.86%\n",
      "MaI12_Page101_line_3.jpg_window_6.jpg,   |   0.00%\n",
      "MaI849_038_line_7.jpg_window_42.jpg,   |   25.00%\n",
      "MaI12_Page100_line_4.jpg_window_48.jpg,   |   64.29%\n",
      "MaI849_039_line_6.jpg_window_36.jpg,   |   42.86%\n",
      "MaI849_039_line_4.jpg_window_36.jpg,   |   16.67%\n",
      "MaI12_Page101_line_3.jpg_window_46.jpg,   |   8.33%\n",
      "MaI849_038_line_1.jpg_window_5.jpg,   |   10.71%\n",
      "MaI14_007_6.jpg_window_34.jpg,   |   10.00%\n",
      "MaI849_038_line_7.jpg_window_38.jpg,   |   39.29%\n",
      "MaI14_051_04.jpg_window_48.jpg,   |   5.00%\n",
      "MaI12_Page100_line_5.jpg_window_7.jpg,   |   10.71%\n",
      "MaI849_039_line_9.jpg_window_47.jpg,   |   21.43%\n",
      "MaI849_039_line_3.jpg_window_2.jpg,   |   0.00%\n",
      "MaI14_007_7.jpg_window_7.jpg,   |   17.86%\n",
      "MaI12_Page102_line_1.jpg_window_44.jpg,   |   35.71%\n",
      "MaI12_Page101_line_4.jpg_window_50.jpg,   |   8.33%\n",
      "MaI849_041_line_8.jpg_window_33.jpg,   |   16.67%\n",
      "MaI14_051_03.jpg_window_45.jpg,   |   16.67%\n",
      "MaI14_051_02.jpg_window_26.jpg,   |   8.33%\n",
      "MaI14_007_3.jpg_window_38.jpg,   |   67.86%\n",
      "MaI12_Page100_line_3.jpg_window_47.jpg,   |   21.43%\n",
      "MaI849_041_line_8.jpg_window_27.jpg,   |   5.00%\n",
      "MaI12_Page100_line_5.jpg_window_1.jpg,   |   16.67%\n",
      "MaI12_Page101_line_1.jpg_window_23.jpg,   |   83.33%\n",
      "MaI849_038_line_2.jpg_window_30.jpg,   |   8.33%\n",
      "MaI12_Page102_line_3.jpg_window_6.jpg,   |   6.67%\n",
      "MaI849_041_line_6.jpg_window_36.jpg,   |   82.14%\n",
      "MaI12_Page101_line_2.jpg_window_25.jpg,   |   29.17%\n",
      "maI16_01_3.jpg_window_21.jpg,   |   5.00%\n",
      "MaI849_041_line_3.jpg_window_36.jpg,   |   0.00%\n",
      "MaI849_038_line_1.jpg_window_14.jpg,   |   0.00%\n",
      "MaI14_007_6.jpg_window_1.jpg,   |   10.71%\n",
      "MaI14_051_05.jpg_window_50.jpg,   |   11.11%\n",
      "MaI12_Page100_line_2.jpg_window_42.jpg,   |   12.50%\n",
      "MaI14_051_02.jpg_window_4.jpg,   |   8.33%\n",
      "MaI12_Page102_line_1.jpg_window_2.jpg,   |   35.71%\n",
      "MaI849_041_line_8.jpg_window_38.jpg,   |   8.33%\n",
      "MaI12_Page101_line_3.jpg_window_28.jpg,   |   20.83%\n",
      "MaI849_038_line_5.jpg_window_45.jpg,   |   12.50%\n",
      "MaI849_039_line_1.jpg_window_9.jpg,   |   17.86%\n",
      "MaI12_Page102_line_5.jpg_window_42.jpg,   |   16.67%\n",
      "MaI849_038_line_7.jpg_window_17.jpg,   |   0.00%\n",
      "MaI849_039_line_1.jpg_window_22.jpg,   |   0.00%\n",
      "MaI12_Page100_line_2.jpg_window_27.jpg,   |   14.29%\n",
      "MaI14_007_7.jpg_window_37.jpg,   |   46.43%\n",
      "MaI849_041_line_5.jpg_window_7.jpg,   |   14.29%\n",
      "MaI14_051_04.jpg_window_16.jpg,   |   85.71%\n",
      "MaI849_041_line_8.jpg_window_15.jpg,   |   17.86%\n",
      "MaI14_051_05.jpg_window_8.jpg,   |   32.14%\n",
      "maI16_01_6.jpg_window_7.jpg,   |   16.67%\n",
      "MaI849_041_line_6.jpg_window_38.jpg,   |   78.57%\n",
      "MaI849_039_line_5.jpg_window_13.jpg,   |   21.43%\n",
      "maI16_01_7.jpg_window_30.jpg,   |   20.83%\n",
      "MaI849_038_line_1.jpg_window_47.jpg,   |   16.67%\n",
      "MaI14_051_08.jpg_window_46.jpg,   |   7.14%\n",
      "MaI12_Page101_line_2.jpg_window_29.jpg,   |   30.00%\n",
      "MaI849_038_line_3.jpg_window_23.jpg,   |   32.14%\n",
      "MaI849_041_line_2.jpg_window_8.jpg,   |   12.50%\n",
      "maI16_01_6.jpg_window_18.jpg,   |   11.11%\n",
      "MaI14_007_9.jpg_window_24.jpg,   |   42.86%\n",
      "MaI14_051_08.jpg_window_2.jpg,   |   10.71%\n",
      "MaI849_041_line_6.jpg_window_21.jpg,   |   12.50%\n",
      "MaI12_Page100_line_4.jpg_window_38.jpg,   |   8.33%\n",
      "MaI849_039_line_8.jpg_window_34.jpg,   |   20.83%\n",
      "MaI14_051_04.jpg_window_15.jpg,   |   100.00%\n",
      "MaI14_051_06.jpg_window_29.jpg,   |   5.56%\n",
      "MaI849_041_line_8.jpg_window_39.jpg,   |   37.50%\n",
      "MaI849_039_line_6.jpg_window_0.jpg,   |   0.00%\n",
      "MaI14_051_04.jpg_window_47.jpg,   |   28.57%\n",
      "MaI14_051_04.jpg_window_3.jpg,   |   12.50%\n",
      "MaI849_041_line_3.jpg_window_7.jpg,   |   39.29%\n",
      "MaI14_051_04.jpg_window_11.jpg,   |   96.43%\n",
      "MaI849_041_line_8.jpg_window_32.jpg,   |   8.33%\n",
      "MaI14_007_6.jpg_window_2.jpg,   |   17.86%\n",
      "MaI12_Page101_line_2.jpg_window_15.jpg,   |   17.86%\n",
      "MaI14_051_05.jpg_window_24.jpg,   |   12.50%\n",
      "MaI849_039_line_8.jpg_window_19.jpg,   |   33.33%\n",
      "MaI849_041_line_9.jpg_window_8.jpg,   |   4.17%\n",
      "MaI849_041_line_1.jpg_window_21.jpg,   |   46.43%\n",
      "maI16_01_3.jpg_window_3.jpg,   |   10.00%\n",
      "MaI12_Page101_line_4.jpg_window_34.jpg,   |   20.00%\n",
      "MaI14_007_9.jpg_window_32.jpg,   |   0.00%\n",
      "MaI12_Page101_line_1.jpg_window_15.jpg,   |   30.00%\n",
      "MaI849_039_line_4.jpg_window_37.jpg,   |   75.00%\n",
      "MaI849_041_line_7.jpg_window_33.jpg,   |   28.57%\n",
      "MaI849_041_line_5.jpg_window_12.jpg,   |   67.86%\n",
      "MaI849_039_line_8.jpg_window_23.jpg,   |   12.50%\n",
      "MaI849_039_line_8.jpg_window_35.jpg,   |   17.86%\n",
      "MaI849_041_line_7.jpg_window_6.jpg,   |   5.00%\n",
      "MaI14_051_02.jpg_window_20.jpg,   |   10.71%\n",
      "MaI849_039_line_9.jpg_window_28.jpg,   |   7.14%\n",
      "MaI849_041_line_5.jpg_window_40.jpg,   |   8.33%\n",
      "maI16_01_5.jpg_window_38.jpg,   |   16.67%\n",
      "MaI849_039_line_6.jpg_window_45.jpg,   |   25.00%\n",
      "MaI14_051_06.jpg_window_38.jpg,   |   57.14%\n",
      "MaI14_007_1.jpg_window_29.jpg,   |   0.00%\n",
      "MaI12_Page100_line_4.jpg_window_40.jpg,   |   41.67%\n",
      "MaI12_Page101_line_3.jpg_window_17.jpg,   |   33.33%\n",
      "MaI849_041_line_1.jpg_window_51.jpg,   |   14.29%\n",
      "MaI12_Page102_line_1.jpg_window_24.jpg,   |   8.33%\n",
      "MaI12_Page101_line_3.jpg_window_21.jpg,   |   21.43%\n",
      "MaI849_039_line_3.jpg_window_6.jpg,   |   0.00%\n",
      "MaI849_038_line_3.jpg_window_43.jpg,   |   0.00%\n",
      "MaI14_007_5.jpg_window_19.jpg,   |   11.11%\n",
      "MaI849_039_line_8.jpg_window_41.jpg,   |   8.33%\n",
      "MaI14_051_02.jpg_window_49.jpg,   |   21.43%\n",
      "MaI849_039_line_8.jpg_window_16.jpg,   |   25.00%\n",
      "MaI12_Page100_line_1.jpg_window_23.jpg,   |   6.67%\n",
      "MaI12_Page101_line_5.jpg_window_48.jpg,   |   35.71%\n",
      "MaI12_Page100_line_2.jpg_window_39.jpg,   |   76.67%\n",
      "MaI14_007_3.jpg_window_28.jpg,   |   29.17%\n",
      "MaI12_Page101_line_5.jpg_window_16.jpg,   |   32.14%\n",
      "MaI12_Page102_line_2.jpg_window_33.jpg,   |   33.33%\n",
      "MaI849_041_line_1.jpg_window_40.jpg,   |   0.00%\n",
      "MaI849_039_line_7.jpg_window_27.jpg,   |   21.43%\n",
      "MaI849_039_line_8.jpg_window_48.jpg,   |   6.25%\n",
      "MaI849_039_line_4.jpg_window_50.jpg,   |   5.00%\n",
      "MaI14_007_4.jpg_window_0.jpg,   |   12.50%\n",
      "MaI12_Page102_line_3.jpg_window_35.jpg,   |   25.00%\n",
      "MaI849_039_line_2.jpg_window_49.jpg,   |   5.00%\n",
      "MaI12_Page101_line_1.jpg_window_14.jpg,   |   53.57%\n",
      "MaI12_Page102_line_3.jpg_window_37.jpg,   |   12.50%\n",
      "MaI14_051_01.jpg_window_5.jpg,   |   14.29%\n",
      "MaI12_Page101_line_2.jpg_window_21.jpg,   |   14.29%\n",
      "maI16_01_3.jpg_window_22.jpg,   |   10.00%\n",
      "MaI849_039_line_4.jpg_window_10.jpg,   |   7.14%\n",
      "maI16_01_9.jpg_window_39.jpg,   |   25.00%\n",
      "MaI849_039_line_2.jpg_window_31.jpg,   |   5.00%\n",
      "MaI14_051_02.jpg_window_40.jpg,   |   12.50%\n",
      "MaI14_007_5.jpg_window_11.jpg,   |   75.00%\n",
      "MaI14_007_2.jpg_window_51.jpg,   |   29.17%\n",
      "MaI849_039_line_7.jpg_window_4.jpg,   |   25.00%\n",
      "MaI849_039_line_2.jpg_window_22.jpg,   |   5.56%\n",
      "MaI12_Page100_line_3.jpg_window_48.jpg,   |   36.67%\n",
      "MaI849_039_line_1.jpg_window_21.jpg,   |   0.00%\n",
      "maI16_01_7.jpg_window_4.jpg,   |   5.00%\n",
      "MaI849_041_line_4.jpg_window_40.jpg,   |   5.00%\n",
      "MaI14_051_03.jpg_window_33.jpg,   |   0.00%\n",
      "maI16_01_6.jpg_window_24.jpg,   |   14.29%\n",
      "MaI12_Page101_line_3.jpg_window_4.jpg,   |   10.71%\n",
      "MaI849_039_line_6.jpg_window_34.jpg,   |   14.29%\n",
      "maI16_01_5.jpg_window_40.jpg,   |   5.56%\n",
      "MaI14_051_08.jpg_window_8.jpg,   |   29.17%\n",
      "maI16_01_9.jpg_window_44.jpg,   |   5.56%\n",
      "MaI849_041_line_7.jpg_window_20.jpg,   |   16.67%\n",
      "MaI14_051_03.jpg_window_14.jpg,   |   75.00%\n",
      "MaI14_007_5.jpg_window_12.jpg,   |   50.00%\n",
      "MaI12_Page101_line_2.jpg_window_2.jpg,   |   6.67%\n",
      "MaI14_007_1.jpg_window_48.jpg,   |   14.29%\n",
      "MaI12_Page100_line_5.jpg_window_6.jpg,   |   10.00%\n",
      "MaI14_051_04.jpg_window_35.jpg,   |   32.14%\n",
      "MaI849_041_line_9.jpg_window_12.jpg,   |   10.71%\n",
      "MaI14_051_08.jpg_window_9.jpg,   |   4.17%\n",
      "MaI849_039_line_3.jpg_window_39.jpg,   |   21.43%\n",
      "MaI12_Page100_line_1.jpg_window_48.jpg,   |   60.00%\n",
      "maI16_01_4.jpg_window_38.jpg,   |   14.29%\n",
      "MaI14_007_5.jpg_window_27.jpg,   |   8.33%\n",
      "MaI14_051_05.jpg_window_7.jpg,   |   29.17%\n",
      "MaI849_041_line_5.jpg_window_38.jpg,   |   100.00%\n",
      "MaI849_039_line_9.jpg_window_15.jpg,   |   16.67%\n",
      "maI16_01_8.jpg_window_24.jpg,   |   12.50%\n",
      "MaI849_039_line_5.jpg_window_2.jpg,   |   0.00%\n",
      "MaI14_007_1.jpg_window_1.jpg,   |   16.67%\n",
      "MaI14_051_03.jpg_window_12.jpg,   |   96.43%\n",
      "MaI12_Page102_line_1.jpg_window_49.jpg,   |   10.71%\n",
      "MaI12_Page102_line_5.jpg_window_7.jpg,   |   33.33%\n",
      "MaI849_039_line_3.jpg_window_44.jpg,   |   10.71%\n",
      "MaI849_041_line_4.jpg_window_2.jpg,   |   25.00%\n",
      "MaI14_051_07.jpg_window_50.jpg,   |   7.14%\n",
      "MaI12_Page101_line_2.jpg_window_36.jpg,   |   37.50%\n",
      "MaI849_041_line_4.jpg_window_34.jpg,   |   15.00%\n",
      "MaI12_Page101_line_2.jpg_window_51.jpg,   |   6.67%\n",
      "MaI849_039_line_3.jpg_window_4.jpg,   |   37.50%\n",
      "MaI14_007_5.jpg_window_14.jpg,   |   96.43%\n",
      "MaI849_038_line_2.jpg_window_16.jpg,   |   0.00%\n",
      "MaI12_Page101_line_5.jpg_window_9.jpg,   |   12.50%\n",
      "MaI12_Page101_line_4.jpg_window_7.jpg,   |   56.67%\n",
      "MaI12_Page100_line_5.jpg_window_41.jpg,   |   23.33%\n",
      "MaI849_039_line_2.jpg_window_18.jpg,   |   10.71%\n",
      "MaI849_039_line_8.jpg_window_24.jpg,   |   8.33%\n",
      "MaI12_Page100_line_3.jpg_window_49.jpg,   |   32.14%\n",
      "MaI849_038_line_5.jpg_window_1.jpg,   |   20.83%\n",
      "MaI12_Page100_line_5.jpg_window_46.jpg,   |   53.33%\n",
      "MaI14_007_8.jpg_window_21.jpg,   |   7.14%\n",
      "MaI12_Page100_line_2.jpg_window_12.jpg,   |   16.67%\n",
      "MaI12_Page102_line_2.jpg_window_22.jpg,   |   23.33%\n",
      "MaI849_041_line_7.jpg_window_12.jpg,   |   100.00%\n",
      "MaI12_Page102_line_4.jpg_window_20.jpg,   |   54.17%\n",
      "maI16_01_6.jpg_window_31.jpg,   |   5.56%\n",
      "MaI849_038_line_4.jpg_window_16.jpg,   |   4.17%\n",
      "MaI14_051_05.jpg_window_36.jpg,   |   46.43%\n",
      "MaI14_007_8.jpg_window_32.jpg,   |   0.00%\n",
      "MaI849_039_line_5.jpg_window_44.jpg,   |   56.67%\n",
      "MaI12_Page100_line_1.jpg_window_28.jpg,   |   42.86%\n",
      "MaI12_Page100_line_1.jpg_window_3.jpg,   |   20.83%\n",
      "MaI12_Page100_line_1.jpg_window_27.jpg,   |   60.00%\n",
      "MaI849_041_line_5.jpg_window_44.jpg,   |   8.33%\n",
      "MaI14_007_6.jpg_window_15.jpg,   |   85.71%\n",
      "MaI12_Page101_line_5.jpg_window_22.jpg,   |   32.14%\n",
      "MaI849_038_line_7.jpg_window_27.jpg,   |   8.33%\n",
      "maI16_01_2.jpg_window_4.jpg,   |   12.50%\n",
      "MaI849_038_line_9.jpg_window_25.jpg,   |   6.67%\n",
      "MaI14_007_3.jpg_window_13.jpg,   |   75.00%\n",
      "MaI12_Page102_line_3.jpg_window_43.jpg,   |   30.00%\n",
      "MaI849_041_line_5.jpg_window_28.jpg,   |   20.83%\n",
      "MaI849_039_line_6.jpg_window_43.jpg,   |   10.71%\n",
      "MaI14_007_3.jpg_window_44.jpg,   |   25.00%\n",
      "MaI12_Page100_line_3.jpg_window_50.jpg,   |   16.67%\n",
      "MaI849_041_line_5.jpg_window_3.jpg,   |   0.00%\n",
      "MaI14_051_05.jpg_window_4.jpg,   |   16.67%\n",
      "MaI14_051_05.jpg_window_13.jpg,   |   75.00%\n",
      "MaI12_Page101_line_2.jpg_window_47.jpg,   |   10.00%\n",
      "MaI14_051_07.jpg_window_29.jpg,   |   0.00%\n",
      "MaI12_Page101_line_4.jpg_window_1.jpg,   |   28.57%\n",
      "MaI849_038_line_1.jpg_window_29.jpg,   |   35.71%\n",
      "MaI14_007_6.jpg_window_40.jpg,   |   78.57%\n",
      "MaI849_039_line_5.jpg_window_51.jpg,   |   16.67%\n",
      "MaI849_039_line_6.jpg_window_35.jpg,   |   0.00%\n",
      "MaI849_038_line_7.jpg_window_14.jpg,   |   85.71%\n",
      "MaI12_Page100_line_3.jpg_window_46.jpg,   |   36.67%\n",
      "MaI14_007_5.jpg_window_18.jpg,   |   71.43%\n",
      "MaI849_038_line_8.jpg_window_38.jpg,   |   12.50%\n",
      "MaI12_Page102_line_3.jpg_window_20.jpg,   |   39.29%\n",
      "MaI12_Page101_line_3.jpg_window_19.jpg,   |   32.14%\n",
      "MaI12_Page100_line_4.jpg_window_23.jpg,   |   40.00%\n",
      "MaI12_Page101_line_3.jpg_window_36.jpg,   |   12.50%\n",
      "maI16_01_4.jpg_window_51.jpg,   |   14.29%\n",
      "maI16_01_6.jpg_window_42.jpg,   |   7.14%\n",
      "MaI849_038_line_1.jpg_window_25.jpg,   |   10.00%\n",
      "MaI849_041_line_2.jpg_window_13.jpg,   |   8.33%\n",
      "maI16_01_9.jpg_window_29.jpg,   |   11.11%\n",
      "MaI849_038_line_9.jpg_window_27.jpg,   |   17.86%\n",
      "MaI12_Page102_line_3.jpg_window_10.jpg,   |   20.83%\n",
      "maI16_01_4.jpg_window_49.jpg,   |   16.67%\n",
      "MaI12_Page101_line_2.jpg_window_46.jpg,   |   7.14%\n",
      "MaI849_041_line_6.jpg_window_46.jpg,   |   14.29%\n",
      "MaI14_007_4.jpg_window_15.jpg,   |   100.00%\n",
      "MaI14_007_5.jpg_window_34.jpg,   |   64.29%\n",
      "MaI12_Page100_line_3.jpg_window_3.jpg,   |   17.86%\n",
      "MaI14_007_4.jpg_window_3.jpg,   |   16.67%\n",
      "MaI849_038_line_2.jpg_window_29.jpg,   |   7.14%\n",
      "MaI14_051_08.jpg_window_36.jpg,   |   21.43%\n",
      "MaI14_007_1.jpg_window_41.jpg,   |   33.33%\n",
      "MaI12_Page101_line_4.jpg_window_43.jpg,   |   40.00%\n",
      "MaI849_041_line_7.jpg_window_13.jpg,   |   89.29%\n",
      "MaI12_Page100_line_4.jpg_window_36.jpg,   |   33.33%\n",
      "MaI849_039_line_5.jpg_window_11.jpg,   |   10.71%\n",
      "MaI849_041_line_3.jpg_window_10.jpg,   |   0.00%\n",
      "MaI14_007_9.jpg_window_1.jpg,   |   28.57%\n",
      "MaI849_039_line_3.jpg_window_42.jpg,   |   12.50%\n",
      "MaI849_041_line_5.jpg_window_17.jpg,   |   17.86%\n",
      "MaI849_039_line_3.jpg_window_33.jpg,   |   39.29%\n",
      "MaI12_Page101_line_1.jpg_window_40.jpg,   |   4.17%\n",
      "MaI14_051_08.jpg_window_3.jpg,   |   21.43%\n",
      "MaI12_Page102_line_2.jpg_window_2.jpg,   |   6.67%\n",
      "MaI12_Page100_line_3.jpg_window_23.jpg,   |   6.67%\n",
      "MaI849_041_line_9.jpg_window_11.jpg,   |   10.71%\n",
      "MaI14_007_2.jpg_window_10.jpg,   |   20.83%\n",
      "MaI14_051_08.jpg_window_41.jpg,   |   7.14%\n",
      "MaI849_039_line_9.jpg_window_45.jpg,   |   10.71%\n",
      "MaI849_041_line_1.jpg_window_32.jpg,   |   28.57%\n",
      "MaI12_Page101_line_1.jpg_window_10.jpg,   |   12.50%\n",
      "MaI14_007_9.jpg_window_37.jpg,   |   46.43%\n",
      "MaI849_039_line_9.jpg_window_14.jpg,   |   20.83%\n",
      "MaI14_051_07.jpg_window_39.jpg,   |   8.33%\n",
      "maI16_01_7.jpg_window_1.jpg,   |   5.56%\n",
      "maI16_01_9.jpg_window_46.jpg,   |   10.00%\n",
      "MaI12_Page101_line_4.jpg_window_30.jpg,   |   6.67%\n",
      "maI16_01_5.jpg_window_41.jpg,   |   16.67%\n",
      "MaI849_041_line_5.jpg_window_37.jpg,   |   96.43%\n",
      "MaI14_051_06.jpg_window_36.jpg,   |   82.14%\n",
      "MaI14_051_05.jpg_window_46.jpg,   |   10.00%\n",
      "MaI14_051_08.jpg_window_51.jpg,   |   12.50%\n",
      "MaI14_051_03.jpg_window_47.jpg,   |   8.33%\n",
      "MaI849_038_line_9.jpg_window_28.jpg,   |   8.33%\n",
      "MaI14_051_03.jpg_window_31.jpg,   |   16.67%\n",
      "MaI849_041_line_1.jpg_window_27.jpg,   |   35.71%\n",
      "MaI12_Page100_line_5.jpg_window_49.jpg,   |   80.00%\n",
      "MaI14_007_6.jpg_window_17.jpg,   |   50.00%\n",
      "MaI14_007_5.jpg_window_1.jpg,   |   0.00%\n",
      "MaI849_041_line_6.jpg_window_3.jpg,   |   12.50%\n",
      "maI16_01_7.jpg_window_13.jpg,   |   25.00%\n",
      "MaI849_038_line_9.jpg_window_34.jpg,   |   7.14%\n",
      "MaI12_Page102_line_4.jpg_window_0.jpg,   |   12.50%\n",
      "MaI849_039_line_5.jpg_window_8.jpg,   |   6.67%\n",
      "MaI849_041_line_4.jpg_window_1.jpg,   |   17.86%\n",
      "MaI12_Page100_line_3.jpg_window_45.jpg,   |   21.43%\n",
      "MaI12_Page102_line_1.jpg_window_8.jpg,   |   50.00%\n",
      "MaI849_039_line_1.jpg_window_10.jpg,   |   16.67%\n",
      "MaI12_Page101_line_1.jpg_window_31.jpg,   |   83.33%\n",
      "MaI849_038_line_5.jpg_window_13.jpg,   |   92.86%\n",
      "MaI14_007_5.jpg_window_51.jpg,   |   20.83%\n",
      "MaI14_051_02.jpg_window_22.jpg,   |   25.00%\n",
      "MaI12_Page101_line_1.jpg_window_24.jpg,   |   32.14%\n",
      "maI16_01_6.jpg_window_48.jpg,   |   0.00%\n",
      "maI16_01_7.jpg_window_22.jpg,   |   11.11%\n",
      "MaI849_039_line_7.jpg_window_21.jpg,   |   0.00%\n",
      "MaI14_007_4.jpg_window_12.jpg,   |   35.71%\n",
      "maI16_01_9.jpg_window_22.jpg,   |   7.14%\n",
      "maI16_01_4.jpg_window_48.jpg,   |   10.00%\n",
      "MaI12_Page101_line_4.jpg_window_26.jpg,   |   29.17%\n",
      "maI16_01_7.jpg_window_3.jpg,   |   25.00%\n",
      "MaI12_Page100_line_3.jpg_window_51.jpg,   |   28.57%\n",
      "MaI849_041_line_9.jpg_window_28.jpg,   |   8.33%\n",
      "MaI849_039_line_8.jpg_window_17.jpg,   |   8.33%\n",
      "MaI12_Page101_line_1.jpg_window_11.jpg,   |   46.67%\n",
      "MaI12_Page101_line_3.jpg_window_44.jpg,   |   35.71%\n",
      "MaI14_051_06.jpg_window_4.jpg,   |   17.86%\n",
      "MaI12_Page100_line_1.jpg_window_5.jpg,   |   23.33%\n",
      "MaI12_Page102_line_3.jpg_window_12.jpg,   |   13.33%\n",
      "MaI12_Page101_line_2.jpg_window_5.jpg,   |   7.14%\n",
      "maI16_01_4.jpg_window_25.jpg,   |   16.67%\n",
      "MaI14_051_06.jpg_window_15.jpg,   |   82.14%\n",
      "MaI849_038_line_9.jpg_window_16.jpg,   |   12.50%\n",
      "MaI849_038_line_4.jpg_window_42.jpg,   |   4.17%\n",
      "MaI14_051_03.jpg_window_49.jpg,   |   16.67%\n",
      "MaI849_038_line_6.jpg_window_38.jpg,   |   71.43%\n",
      "maI16_01_4.jpg_window_16.jpg,   |   25.00%\n",
      "MaI12_Page101_line_3.jpg_window_20.jpg,   |   40.00%\n",
      "MaI14_007_2.jpg_window_9.jpg,   |   16.67%\n",
      "MaI14_051_02.jpg_window_37.jpg,   |   35.71%\n",
      "MaI14_007_1.jpg_window_47.jpg,   |   7.14%\n",
      "MaI14_051_06.jpg_window_11.jpg,   |   78.57%\n",
      "MaI12_Page102_line_2.jpg_window_15.jpg,   |   30.00%\n",
      "MaI14_051_03.jpg_window_37.jpg,   |   92.86%\n",
      "MaI849_041_line_2.jpg_window_23.jpg,   |   8.33%\n",
      "MaI14_051_07.jpg_window_48.jpg,   |   16.67%\n",
      "MaI849_039_line_6.jpg_window_7.jpg,   |   7.14%\n",
      "MaI14_007_4.jpg_window_24.jpg,   |   20.83%\n",
      "maI16_01_9.jpg_window_41.jpg,   |   10.00%\n",
      "MaI849_038_line_1.jpg_window_10.jpg,   |   35.71%\n",
      "MaI14_051_05.jpg_window_16.jpg,   |   82.14%\n",
      "MaI12_Page100_line_2.jpg_window_9.jpg,   |   10.00%\n",
      "MaI14_007_1.jpg_window_31.jpg,   |   30.00%\n",
      "MaI14_051_05.jpg_window_43.jpg,   |   10.71%\n",
      "MaI849_041_line_2.jpg_window_40.jpg,   |   7.14%\n",
      "MaI12_Page100_line_5.jpg_window_20.jpg,   |   32.14%\n",
      "maI16_01_6.jpg_window_29.jpg,   |   6.25%\n",
      "MaI849_041_line_1.jpg_window_33.jpg,   |   28.57%\n",
      "MaI14_007_5.jpg_window_42.jpg,   |   5.00%\n",
      "MaI14_007_8.jpg_window_24.jpg,   |   20.83%\n",
      "MaI849_038_line_9.jpg_window_9.jpg,   |   25.00%\n",
      "MaI12_Page101_line_5.jpg_window_18.jpg,   |   12.50%\n",
      "MaI12_Page100_line_3.jpg_window_33.jpg,   |   12.50%\n",
      "MaI12_Page100_line_5.jpg_window_42.jpg,   |   23.33%\n",
      "MaI849_039_line_4.jpg_window_13.jpg,   |   35.71%\n",
      "MaI12_Page101_line_4.jpg_window_0.jpg,   |   30.00%\n",
      "MaI849_038_line_5.jpg_window_31.jpg,   |   14.29%\n",
      "MaI12_Page101_line_4.jpg_window_22.jpg,   |   10.71%\n",
      "MaI12_Page102_line_4.jpg_window_9.jpg,   |   25.00%\n",
      "MaI14_007_5.jpg_window_10.jpg,   |   89.29%\n",
      "MaI12_Page101_line_1.jpg_window_50.jpg,   |   16.67%\n",
      "MaI12_Page102_line_1.jpg_window_36.jpg,   |   36.67%\n",
      "MaI849_041_line_9.jpg_window_15.jpg,   |   16.67%\n",
      "MaI849_039_line_3.jpg_window_18.jpg,   |   0.00%\n",
      "MaI849_041_line_3.jpg_window_6.jpg,   |   53.57%\n",
      "MaI849_039_line_3.jpg_window_40.jpg,   |   0.00%\n",
      "MaI12_Page100_line_1.jpg_window_45.jpg,   |   5.00%\n",
      "MaI14_007_1.jpg_window_45.jpg,   |   25.00%\n",
      "MaI12_Page102_line_1.jpg_window_30.jpg,   |   13.33%\n",
      "MaI849_038_line_4.jpg_window_13.jpg,   |   53.57%\n",
      "maI16_01_6.jpg_window_19.jpg,   |   15.00%\n",
      "MaI12_Page101_line_1.jpg_window_19.jpg,   |   16.67%\n",
      "MaI849_041_line_6.jpg_window_32.jpg,   |   8.33%\n",
      "MaI12_Page102_line_3.jpg_window_22.jpg,   |   8.33%\n",
      "MaI14_051_03.jpg_window_11.jpg,   |   89.29%\n",
      "MaI14_051_03.jpg_window_39.jpg,   |   100.00%\n",
      "MaI12_Page100_line_2.jpg_window_25.jpg,   |   16.67%\n",
      "maI16_01_9.jpg_window_11.jpg,   |   10.00%\n",
      "MaI14_007_3.jpg_window_11.jpg,   |   57.14%\n",
      "MaI849_038_line_4.jpg_window_48.jpg,   |   10.71%\n",
      "MaI12_Page101_line_5.jpg_window_36.jpg,   |   35.71%\n",
      "MaI849_039_line_9.jpg_window_3.jpg,   |   32.14%\n",
      "MaI14_007_9.jpg_window_47.jpg,   |   25.00%\n",
      "MaI849_039_line_6.jpg_window_18.jpg,   |   53.57%\n",
      "MaI12_Page102_line_3.jpg_window_18.jpg,   |   43.33%\n",
      "maI16_01_7.jpg_window_10.jpg,   |   5.56%\n",
      "MaI849_039_line_7.jpg_window_14.jpg,   |   0.00%\n",
      "MaI849_041_line_9.jpg_window_29.jpg,   |   7.14%\n",
      "MaI849_041_line_4.jpg_window_15.jpg,   |   8.33%\n",
      "maI16_01_7.jpg_window_2.jpg,   |   11.11%\n",
      "MaI849_041_line_6.jpg_window_45.jpg,   |   26.67%\n",
      "MaI14_007_1.jpg_window_5.jpg,   |   16.67%\n",
      "MaI12_Page100_line_4.jpg_window_32.jpg,   |   10.00%\n",
      "MaI849_039_line_9.jpg_window_33.jpg,   |   21.43%\n",
      "MaI849_041_line_7.jpg_window_36.jpg,   |   85.71%\n",
      "MaI14_007_2.jpg_window_34.jpg,   |   12.50%\n",
      "maI16_01_5.jpg_window_26.jpg,   |   11.11%\n",
      "MaI849_038_line_7.jpg_window_44.jpg,   |   10.71%\n",
      "MaI14_007_4.jpg_window_44.jpg,   |   5.56%\n",
      "MaI12_Page102_line_4.jpg_window_4.jpg,   |   16.67%\n",
      "MaI12_Page100_line_3.jpg_window_24.jpg,   |   7.14%\n",
      "MaI12_Page100_line_3.jpg_window_38.jpg,   |   25.00%\n",
      "MaI849_041_line_2.jpg_window_26.jpg,   |   8.33%\n",
      "MaI12_Page102_line_5.jpg_window_4.jpg,   |   46.43%\n",
      "MaI849_039_line_4.jpg_window_4.jpg,   |   7.14%\n",
      "MaI12_Page102_line_3.jpg_window_34.jpg,   |   20.83%\n",
      "MaI14_051_02.jpg_window_39.jpg,   |   16.67%\n",
      "MaI849_039_line_3.jpg_window_21.jpg,   |   16.67%\n",
      "MaI849_038_line_1.jpg_window_6.jpg,   |   7.14%\n",
      "MaI849_039_line_5.jpg_window_38.jpg,   |   46.43%\n",
      "MaI849_041_line_8.jpg_window_2.jpg,   |   8.33%\n",
      "MaI14_007_5.jpg_window_47.jpg,   |   32.14%\n",
      "MaI849_039_line_9.jpg_window_8.jpg,   |   5.00%\n",
      "MaI14_007_2.jpg_window_21.jpg,   |   12.50%\n",
      "MaI849_039_line_6.jpg_window_40.jpg,   |   0.00%\n",
      "MaI12_Page102_line_5.jpg_window_10.jpg,   |   42.86%\n",
      "MaI849_038_line_5.jpg_window_36.jpg,   |   50.00%\n",
      "MaI12_Page101_line_2.jpg_window_24.jpg,   |   12.50%\n",
      "MaI14_051_04.jpg_window_17.jpg,   |   57.14%\n",
      "MaI849_038_line_1.jpg_window_42.jpg,   |   8.33%\n",
      "MaI849_038_line_9.jpg_window_29.jpg,   |   16.67%\n",
      "MaI849_039_line_7.jpg_window_24.jpg,   |   8.33%\n",
      "MaI849_038_line_4.jpg_window_39.jpg,   |   26.67%\n",
      "MaI14_007_5.jpg_window_48.jpg,   |   28.57%\n",
      "maI16_01_8.jpg_window_0.jpg,   |   5.56%\n",
      "MaI849_038_line_9.jpg_window_24.jpg,   |   8.33%\n",
      "MaI849_041_line_6.jpg_window_28.jpg,   |   12.50%\n",
      "MaI849_041_line_2.jpg_window_29.jpg,   |   25.00%\n",
      "MaI849_039_line_4.jpg_window_48.jpg,   |   0.00%\n",
      "maI16_01_3.jpg_window_29.jpg,   |   15.00%\n",
      "MaI849_039_line_6.jpg_window_13.jpg,   |   85.71%\n",
      "MaI12_Page102_line_5.jpg_window_34.jpg,   |   12.50%\n",
      "MaI849_038_line_1.jpg_window_43.jpg,   |   10.00%\n",
      "MaI12_Page100_line_4.jpg_window_22.jpg,   |   17.86%\n",
      "MaI14_051_08.jpg_window_18.jpg,   |   12.50%\n",
      "maI16_01_4.jpg_window_35.jpg,   |   14.29%\n",
      "MaI12_Page101_line_5.jpg_window_27.jpg,   |   7.14%\n",
      "MaI849_041_line_8.jpg_window_51.jpg,   |   29.17%\n",
      "MaI14_051_08.jpg_window_44.jpg,   |   8.33%\n",
      "MaI14_007_3.jpg_window_18.jpg,   |   46.43%\n",
      "MaI849_038_line_6.jpg_window_1.jpg,   |   10.00%\n",
      "MaI849_039_line_6.jpg_window_27.jpg,   |   5.00%\n",
      "MaI12_Page102_line_5.jpg_window_8.jpg,   |   21.43%\n",
      "MaI14_051_03.jpg_window_28.jpg,   |   20.83%\n",
      "MaI849_039_line_2.jpg_window_15.jpg,   |   17.86%\n",
      "MaI12_Page101_line_2.jpg_window_12.jpg,   |   25.00%\n",
      "MaI14_007_4.jpg_window_40.jpg,   |   10.71%\n",
      "maI16_01_7.jpg_window_21.jpg,   |   11.11%\n",
      "MaI849_038_line_6.jpg_window_13.jpg,   |   92.86%\n",
      "MaI14_007_4.jpg_window_4.jpg,   |   20.83%\n",
      "MaI14_007_2.jpg_window_24.jpg,   |   8.33%\n",
      "MaI849_038_line_9.jpg_window_40.jpg,   |   8.33%\n",
      "MaI849_041_line_5.jpg_window_9.jpg,   |   35.71%\n",
      "MaI849_039_line_8.jpg_window_4.jpg,   |   10.00%\n",
      "MaI849_039_line_5.jpg_window_34.jpg,   |   10.00%\n",
      "MaI14_051_07.jpg_window_1.jpg,   |   32.14%\n",
      "MaI14_051_07.jpg_window_17.jpg,   |   5.00%\n",
      "MaI849_038_line_1.jpg_window_24.jpg,   |   25.00%\n",
      "MaI14_051_04.jpg_window_26.jpg,   |   6.25%\n",
      "MaI14_007_8.jpg_window_29.jpg,   |   20.00%\n",
      "MaI849_041_line_1.jpg_window_19.jpg,   |   12.50%\n",
      "MaI849_039_line_3.jpg_window_34.jpg,   |   60.71%\n",
      "MaI12_Page102_line_5.jpg_window_27.jpg,   |   57.14%\n",
      "MaI849_039_line_5.jpg_window_3.jpg,   |   12.50%\n",
      "MaI12_Page100_line_4.jpg_window_51.jpg,   |   35.71%\n",
      "MaI849_041_line_3.jpg_window_41.jpg,   |   25.00%\n",
      "MaI849_041_line_8.jpg_window_24.jpg,   |   4.17%\n",
      "MaI849_041_line_5.jpg_window_0.jpg,   |   0.00%\n",
      "MaI12_Page100_line_5.jpg_window_28.jpg,   |   17.86%\n",
      "MaI12_Page100_line_1.jpg_window_36.jpg,   |   6.67%\n",
      "MaI849_039_line_3.jpg_window_8.jpg,   |   8.33%\n",
      "MaI14_007_7.jpg_window_49.jpg,   |   25.00%\n",
      "maI16_01_1.jpg_window_47.jpg,   |   5.56%\n",
      "MaI849_038_line_5.jpg_window_12.jpg,   |   82.14%\n",
      "MaI849_038_line_7.jpg_window_12.jpg,   |   53.57%\n",
      "MaI12_Page101_line_2.jpg_window_37.jpg,   |   6.67%\n",
      "MaI849_041_line_3.jpg_window_46.jpg,   |   75.00%\n",
      "MaI849_041_line_9.jpg_window_2.jpg,   |   16.67%\n",
      "MaI14_007_7.jpg_window_27.jpg,   |   5.00%\n",
      "MaI12_Page102_line_1.jpg_window_6.jpg,   |   58.33%\n",
      "MaI12_Page102_line_3.jpg_window_25.jpg,   |   10.71%\n",
      "MaI14_051_02.jpg_window_23.jpg,   |   7.14%\n",
      "MaI849_039_line_9.jpg_window_31.jpg,   |   12.50%\n",
      "MaI12_Page100_line_3.jpg_window_13.jpg,   |   10.00%\n",
      "MaI14_051_01.jpg_window_51.jpg,   |   25.00%\n",
      "MaI12_Page101_line_5.jpg_window_12.jpg,   |   35.71%\n",
      "MaI12_Page102_line_3.jpg_window_42.jpg,   |   4.17%\n",
      "MaI12_Page102_line_2.jpg_window_30.jpg,   |   33.33%\n",
      "MaI12_Page100_line_3.jpg_window_35.jpg,   |   8.33%\n",
      "MaI849_039_line_1.jpg_window_45.jpg,   |   20.83%\n",
      "MaI14_051_06.jpg_window_35.jpg,   |   78.57%\n",
      "MaI12_Page100_line_2.jpg_window_34.jpg,   |   13.33%\n",
      "MaI14_007_6.jpg_window_25.jpg,   |   15.00%\n",
      "MaI12_Page100_line_4.jpg_window_19.jpg,   |   25.00%\n",
      "MaI849_039_line_9.jpg_window_51.jpg,   |   12.50%\n",
      "MaI14_051_04.jpg_window_19.jpg,   |   13.33%\n",
      "MaI12_Page100_line_1.jpg_window_21.jpg,   |   46.43%\n",
      "MaI849_038_line_4.jpg_window_28.jpg,   |   12.50%\n",
      "MaI849_039_line_8.jpg_window_49.jpg,   |   5.56%\n",
      "MaI14_007_3.jpg_window_9.jpg,   |   8.33%\n",
      "MaI14_051_08.jpg_window_20.jpg,   |   10.71%\n",
      "MaI849_038_line_9.jpg_window_20.jpg,   |   5.00%\n",
      "MaI849_038_line_1.jpg_window_30.jpg,   |   12.50%\n",
      "MaI12_Page100_line_2.jpg_window_6.jpg,   |   8.33%\n",
      "maI16_01_3.jpg_window_30.jpg,   |   20.00%\n",
      "MaI849_038_line_4.jpg_window_38.jpg,   |   46.43%\n",
      "MaI12_Page100_line_4.jpg_window_17.jpg,   |   10.00%\n",
      "MaI14_007_2.jpg_window_8.jpg,   |   8.33%\n",
      "MaI849_038_line_2.jpg_window_26.jpg,   |   8.33%\n",
      "MaI849_041_line_6.jpg_window_4.jpg,   |   20.83%\n",
      "MaI849_038_line_1.jpg_window_39.jpg,   |   10.71%\n",
      "MaI14_051_07.jpg_window_6.jpg,   |   8.33%\n",
      "MaI849_038_line_1.jpg_window_21.jpg,   |   15.00%\n",
      "MaI14_007_7.jpg_window_45.jpg,   |   12.50%\n",
      "MaI12_Page102_line_3.jpg_window_19.jpg,   |   60.00%\n",
      "MaI849_041_line_6.jpg_window_1.jpg,   |   0.00%\n",
      "MaI849_041_line_8.jpg_window_35.jpg,   |   5.00%\n",
      "MaI14_007_9.jpg_window_14.jpg,   |   25.00%\n",
      "MaI14_007_7.jpg_window_50.jpg,   |   16.67%\n",
      "MaI849_041_line_8.jpg_window_23.jpg,   |   0.00%\n",
      "MaI849_041_line_5.jpg_window_47.jpg,   |   12.50%\n",
      "MaI14_007_5.jpg_window_46.jpg,   |   7.14%\n",
      "MaI849_038_line_4.jpg_window_33.jpg,   |   0.00%\n",
      "MaI14_007_2.jpg_window_5.jpg,   |   14.29%\n",
      "MaI849_039_line_5.jpg_window_30.jpg,   |   5.00%\n",
      "MaI12_Page100_line_1.jpg_window_18.jpg,   |   46.67%\n",
      "MaI14_051_06.jpg_window_6.jpg,   |   12.50%\n",
      "MaI849_039_line_6.jpg_window_44.jpg,   |   7.14%\n",
      "MaI14_051_06.jpg_window_32.jpg,   |   12.50%\n",
      "maI16_01_4.jpg_window_33.jpg,   |   20.00%\n",
      "maI16_01_8.jpg_window_2.jpg,   |   6.25%\n",
      "MaI12_Page102_line_1.jpg_window_39.jpg,   |   75.00%\n",
      "MaI14_007_6.jpg_window_39.jpg,   |   46.43%\n",
      "MaI14_051_05.jpg_window_15.jpg,   |   85.71%\n",
      "MaI14_051_06.jpg_window_13.jpg,   |   71.43%\n",
      "MaI14_007_9.jpg_window_46.jpg,   |   8.33%\n",
      "MaI849_041_line_6.jpg_window_40.jpg,   |   32.14%\n",
      "MaI849_041_line_7.jpg_window_22.jpg,   |   5.00%\n",
      "MaI14_051_04.jpg_window_37.jpg,   |   32.14%\n",
      "MaI849_039_line_7.jpg_window_34.jpg,   |   5.00%\n",
      "MaI14_007_3.jpg_window_10.jpg,   |   28.57%\n",
      "MaI14_051_06.jpg_window_39.jpg,   |   50.00%\n",
      "MaI14_051_08.jpg_window_17.jpg,   |   0.00%\n",
      "MaI849_041_line_2.jpg_window_24.jpg,   |   8.33%\n",
      "MaI14_051_02.jpg_window_34.jpg,   |   16.67%\n",
      "MaI14_051_07.jpg_window_45.jpg,   |   37.50%\n",
      "MaI849_038_line_5.jpg_window_44.jpg,   |   8.33%\n",
      "MaI12_Page101_line_3.jpg_window_18.jpg,   |   33.33%\n",
      "MaI12_Page101_line_1.jpg_window_30.jpg,   |   33.33%\n",
      "MaI849_038_line_6.jpg_window_29.jpg,   |   8.33%\n",
      "MaI849_041_line_8.jpg_window_20.jpg,   |   32.14%\n",
      "MaI849_039_line_4.jpg_window_38.jpg,   |   50.00%\n",
      "MaI849_038_line_5.jpg_window_37.jpg,   |   67.86%\n",
      "MaI849_041_line_2.jpg_window_25.jpg,   |   8.33%\n",
      "MaI12_Page102_line_1.jpg_window_45.jpg,   |   41.67%\n",
      "MaI12_Page101_line_4.jpg_window_6.jpg,   |   35.71%\n",
      "MaI849_038_line_6.jpg_window_47.jpg,   |   8.33%\n",
      "MaI849_038_line_2.jpg_window_44.jpg,   |   5.00%\n",
      "MaI12_Page101_line_5.jpg_window_25.jpg,   |   7.14%\n",
      "MaI12_Page101_line_3.jpg_window_31.jpg,   |   14.29%\n",
      "MaI849_039_line_3.jpg_window_7.jpg,   |   0.00%\n",
      "MaI12_Page100_line_5.jpg_window_44.jpg,   |   25.00%\n",
      "MaI14_007_4.jpg_window_39.jpg,   |   57.14%\n",
      "MaI849_041_line_5.jpg_window_30.jpg,   |   7.14%\n",
      "maI16_01_6.jpg_window_13.jpg,   |   7.14%\n",
      "MaI849_041_line_1.jpg_window_5.jpg,   |   0.00%\n",
      "MaI12_Page102_line_4.jpg_window_42.jpg,   |   0.00%\n",
      "MaI849_041_line_3.jpg_window_47.jpg,   |   32.14%\n",
      "MaI12_Page102_line_2.jpg_window_4.jpg,   |   10.71%\n",
      "MaI12_Page101_line_3.jpg_window_7.jpg,   |   0.00%\n",
      "MaI849_038_line_9.jpg_window_33.jpg,   |   20.83%\n",
      "MaI849_039_line_6.jpg_window_2.jpg,   |   16.67%\n",
      "MaI849_038_line_6.jpg_window_11.jpg,   |   60.71%\n",
      "MaI14_007_7.jpg_window_38.jpg,   |   28.57%\n",
      "MaI12_Page100_line_1.jpg_window_17.jpg,   |   8.33%\n",
      "MaI14_051_01.jpg_window_46.jpg,   |   8.33%\n",
      "MaI14_007_5.jpg_window_41.jpg,   |   16.67%\n",
      "maI16_01_3.jpg_window_12.jpg,   |   14.29%\n",
      "MaI14_007_6.jpg_window_13.jpg,   |   25.00%\n",
      "MaI849_039_line_8.jpg_window_39.jpg,   |   14.29%\n",
      "MaI849_039_line_8.jpg_window_21.jpg,   |   15.00%\n",
      "MaI849_039_line_1.jpg_window_0.jpg,   |   13.33%\n",
      "MaI849_039_line_7.jpg_window_3.jpg,   |   20.83%\n",
      "MaI12_Page100_line_5.jpg_window_45.jpg,   |   23.33%\n",
      "MaI14_051_03.jpg_window_24.jpg,   |   7.14%\n",
      "MaI849_038_line_1.jpg_window_46.jpg,   |   16.67%\n",
      "MaI12_Page102_line_2.jpg_window_35.jpg,   |   10.71%\n",
      "maI16_01_3.jpg_window_11.jpg,   |   0.00%\n",
      "MaI14_051_07.jpg_window_5.jpg,   |   16.67%\n",
      "MaI12_Page100_line_2.jpg_window_50.jpg,   |   16.67%\n",
      "MaI14_007_5.jpg_window_36.jpg,   |   35.71%\n",
      "MaI849_041_line_3.jpg_window_45.jpg,   |   16.67%\n",
      "MaI12_Page102_line_5.jpg_window_11.jpg,   |   7.14%\n",
      "MaI849_041_line_7.jpg_window_27.jpg,   |   20.83%\n",
      "MaI12_Page101_line_1.jpg_window_35.jpg,   |   16.67%\n",
      "MaI849_039_line_2.jpg_window_14.jpg,   |   8.33%\n",
      "MaI12_Page102_line_5.jpg_window_29.jpg,   |   0.00%\n",
      "MaI14_007_5.jpg_window_37.jpg,   |   57.14%\n",
      "MaI849_038_line_5.jpg_window_38.jpg,   |   89.29%\n",
      "MaI12_Page101_line_2.jpg_window_9.jpg,   |   20.83%\n",
      "MaI849_041_line_5.jpg_window_11.jpg,   |   85.71%\n",
      "MaI849_038_line_2.jpg_window_14.jpg,   |   25.00%\n",
      "MaI14_051_07.jpg_window_26.jpg,   |   10.71%\n",
      "MaI14_007_7.jpg_window_43.jpg,   |   50.00%\n",
      "MaI12_Page101_line_1.jpg_window_18.jpg,   |   45.83%\n",
      "MaI849_038_line_7.jpg_window_11.jpg,   |   53.57%\n",
      "MaI849_039_line_8.jpg_window_40.jpg,   |   8.33%\n",
      "MaI14_007_7.jpg_window_40.jpg,   |   93.33%\n",
      "MaI849_041_line_8.jpg_window_3.jpg,   |   17.86%\n",
      "MaI849_041_line_3.jpg_window_37.jpg,   |   4.17%\n",
      "MaI849_038_line_8.jpg_window_36.jpg,   |   10.71%\n",
      "MaI12_Page100_line_3.jpg_window_40.jpg,   |   39.29%\n",
      "MaI12_Page100_line_5.jpg_window_34.jpg,   |   32.14%\n",
      "MaI14_051_03.jpg_window_25.jpg,   |   6.67%\n",
      "MaI12_Page101_line_5.jpg_window_35.jpg,   |   70.00%\n",
      "MaI849_038_line_7.jpg_window_35.jpg,   |   20.00%\n",
      "MaI849_039_line_1.jpg_window_50.jpg,   |   14.29%\n",
      "MaI849_041_line_8.jpg_window_48.jpg,   |   5.00%\n",
      "MaI12_Page100_line_5.jpg_window_11.jpg,   |   21.43%\n",
      "MaI14_007_8.jpg_window_28.jpg,   |   12.50%\n",
      "MaI849_041_line_6.jpg_window_37.jpg,   |   82.14%\n",
      "MaI849_041_line_9.jpg_window_39.jpg,   |   0.00%\n",
      "MaI14_007_5.jpg_window_49.jpg,   |   12.50%\n",
      "MaI12_Page100_line_5.jpg_window_50.jpg,   |   39.29%\n",
      "maI16_01_1.jpg_window_21.jpg,   |   14.29%\n",
      "MaI849_038_line_5.jpg_window_14.jpg,   |   6.67%\n",
      "MaI849_039_line_4.jpg_window_0.jpg,   |   0.00%\n",
      "MaI849_038_line_5.jpg_window_7.jpg,   |   16.67%\n",
      "MaI14_007_8.jpg_window_3.jpg,   |   15.00%\n",
      "MaI849_041_line_8.jpg_window_29.jpg,   |   5.00%\n",
      "MaI849_039_line_2.jpg_window_19.jpg,   |   16.67%\n",
      "MaI14_007_9.jpg_window_25.jpg,   |   39.29%\n",
      "MaI14_007_1.jpg_window_11.jpg,   |   20.83%\n",
      "MaI12_Page101_line_5.jpg_window_0.jpg,   |   54.17%\n",
      "MaI14_007_3.jpg_window_43.jpg,   |   29.17%\n",
      "MaI14_007_6.jpg_window_12.jpg,   |   57.14%\n",
      "MaI14_007_5.jpg_window_35.jpg,   |   32.14%\n",
      "MaI12_Page100_line_5.jpg_window_10.jpg,   |   33.33%\n",
      "MaI14_007_9.jpg_window_17.jpg,   |   20.83%\n",
      "MaI14_007_5.jpg_window_15.jpg,   |   78.57%\n",
      "MaI849_041_line_1.jpg_window_35.jpg,   |   17.86%\n",
      "MaI12_Page101_line_1.jpg_window_13.jpg,   |   53.33%\n",
      "MaI12_Page102_line_3.jpg_window_39.jpg,   |   14.29%\n",
      "MaI14_007_6.jpg_window_50.jpg,   |   28.57%\n",
      "MaI849_041_line_8.jpg_window_19.jpg,   |   14.29%\n",
      "MaI12_Page100_line_1.jpg_window_25.jpg,   |   70.00%\n",
      "MaI14_051_07.jpg_window_44.jpg,   |   12.50%\n",
      "MaI14_007_3.jpg_window_27.jpg,   |   20.00%\n",
      "MaI14_051_02.jpg_window_43.jpg,   |   20.00%\n",
      "MaI12_Page100_line_5.jpg_window_38.jpg,   |   10.71%\n",
      "MaI849_038_line_5.jpg_window_43.jpg,   |   12.50%\n",
      "MaI849_041_line_6.jpg_window_9.jpg,   |   25.00%\n",
      "MaI12_Page101_line_4.jpg_window_44.jpg,   |   39.29%\n",
      "maI16_01_5.jpg_window_7.jpg,   |   20.00%\n",
      "MaI14_007_3.jpg_window_4.jpg,   |   11.11%\n",
      "MaI12_Page101_line_4.jpg_window_33.jpg,   |   36.67%\n",
      "MaI849_038_line_3.jpg_window_12.jpg,   |   35.71%\n",
      "MaI14_051_02.jpg_window_48.jpg,   |   64.29%\n",
      "MaI849_038_line_1.jpg_window_34.jpg,   |   39.29%\n",
      "MaI14_007_5.jpg_window_16.jpg,   |   42.86%\n",
      "MaI14_007_7.jpg_window_46.jpg,   |   25.00%\n",
      "MaI12_Page102_line_1.jpg_window_46.jpg,   |   46.67%\n",
      "MaI849_039_line_5.jpg_window_16.jpg,   |   7.14%\n",
      "MaI14_007_4.jpg_window_41.jpg,   |   23.33%\n",
      "MaI849_041_line_6.jpg_window_13.jpg,   |   67.86%\n",
      "MaI849_041_line_7.jpg_window_31.jpg,   |   8.33%\n",
      "MaI14_007_6.jpg_window_38.jpg,   |   60.71%\n",
      "MaI12_Page102_line_1.jpg_window_33.jpg,   |   25.00%\n",
      "MaI14_051_02.jpg_window_13.jpg,   |   7.14%\n",
      "MaI12_Page101_line_1.jpg_window_34.jpg,   |   32.14%\n",
      "MaI12_Page100_line_5.jpg_window_21.jpg,   |   17.86%\n",
      "MaI12_Page100_line_1.jpg_window_50.jpg,   |   8.33%\n",
      "MaI12_Page101_line_4.jpg_window_24.jpg,   |   10.71%\n",
      "MaI14_007_8.jpg_window_0.jpg,   |   8.33%\n",
      "maI16_01_8.jpg_window_29.jpg,   |   28.57%\n",
      "MaI849_038_line_6.jpg_window_30.jpg,   |   5.00%\n",
      "MaI849_039_line_4.jpg_window_12.jpg,   |   60.71%\n",
      "MaI12_Page100_line_3.jpg_window_1.jpg,   |   7.14%\n",
      "MaI12_Page100_line_4.jpg_window_47.jpg,   |   53.33%\n",
      "MaI849_041_line_2.jpg_window_31.jpg,   |   20.83%\n",
      "MaI849_039_line_4.jpg_window_40.jpg,   |   0.00%\n",
      "MaI849_041_line_1.jpg_window_6.jpg,   |   17.86%\n",
      "MaI12_Page102_line_4.jpg_window_38.jpg,   |   16.67%\n",
      "MaI14_051_06.jpg_window_16.jpg,   |   75.00%\n",
      "maI16_01_9.jpg_window_30.jpg,   |   14.29%\n",
      "MaI14_051_04.jpg_window_38.jpg,   |   64.29%\n",
      "MaI14_007_3.jpg_window_22.jpg,   |   5.00%\n",
      "MaI849_039_line_4.jpg_window_49.jpg,   |   0.00%\n",
      "MaI14_051_06.jpg_window_17.jpg,   |   85.71%\n",
      "MaI12_Page102_line_5.jpg_window_40.jpg,   |   17.86%\n",
      "MaI12_Page100_line_1.jpg_window_12.jpg,   |   13.33%\n",
      "MaI849_038_line_9.jpg_window_44.jpg,   |   12.50%\n",
      "MaI12_Page101_line_1.jpg_window_27.jpg,   |   28.57%\n",
      "MaI849_038_line_2.jpg_window_35.jpg,   |   10.71%\n",
      "MaI849_041_line_9.jpg_window_22.jpg,   |   15.00%\n",
      "MaI12_Page100_line_4.jpg_window_20.jpg,   |   29.17%\n",
      "MaI14_007_7.jpg_window_42.jpg,   |   20.83%\n",
      "MaI12_Page100_line_4.jpg_window_16.jpg,   |   14.29%\n",
      "maI16_01_5.jpg_window_24.jpg,   |   7.14%\n",
      "MaI849_039_line_5.jpg_window_7.jpg,   |   7.14%\n",
      "MaI14_051_05.jpg_window_35.jpg,   |   60.71%\n",
      "MaI12_Page102_line_4.jpg_window_34.jpg,   |   14.29%\n",
      "MaI12_Page100_line_2.jpg_window_36.jpg,   |   14.29%\n",
      "MaI12_Page101_line_3.jpg_window_43.jpg,   |   40.00%\n",
      "maI16_01_8.jpg_window_17.jpg,   |   5.56%\n",
      "MaI12_Page101_line_1.jpg_window_44.jpg,   |   73.33%\n",
      "MaI849_041_line_4.jpg_window_30.jpg,   |   12.50%\n",
      "maI16_01_6.jpg_window_28.jpg,   |   12.50%\n",
      "MaI849_041_line_1.jpg_window_49.jpg,   |   0.00%\n",
      "MaI12_Page102_line_1.jpg_window_14.jpg,   |   89.29%\n",
      "MaI14_051_04.jpg_window_21.jpg,   |   11.11%\n",
      "MaI12_Page102_line_5.jpg_window_39.jpg,   |   21.43%\n",
      "MaI14_007_8.jpg_window_13.jpg,   |   27.78%\n",
      "MaI12_Page102_line_2.jpg_window_41.jpg,   |   0.00%\n",
      "MaI12_Page101_line_3.jpg_window_11.jpg,   |   28.57%\n",
      "MaI849_041_line_9.jpg_window_13.jpg,   |   21.43%\n",
      "MaI14_051_05.jpg_window_45.jpg,   |   10.00%\n",
      "MaI849_041_line_9.jpg_window_4.jpg,   |   39.29%\n",
      "MaI849_038_line_6.jpg_window_7.jpg,   |   7.14%\n",
      "maI16_01_1.jpg_window_50.jpg,   |   5.56%\n",
      "MaI14_007_7.jpg_window_29.jpg,   |   0.00%\n",
      "MaI12_Page100_line_2.jpg_window_3.jpg,   |   7.14%\n",
      "MaI12_Page101_line_3.jpg_window_9.jpg,   |   36.67%\n",
      "MaI14_051_02.jpg_window_25.jpg,   |   12.50%\n",
      "MaI12_Page101_line_5.jpg_window_37.jpg,   |   57.14%\n",
      "MaI849_038_line_6.jpg_window_10.jpg,   |   35.71%\n",
      "MaI12_Page100_line_5.jpg_window_23.jpg,   |   56.67%\n",
      "MaI849_041_line_1.jpg_window_9.jpg,   |   16.67%\n",
      "MaI14_051_04.jpg_window_50.jpg,   |   16.67%\n",
      "MaI12_Page100_line_1.jpg_window_14.jpg,   |   17.86%\n",
      "MaI12_Page102_line_4.jpg_window_22.jpg,   |   50.00%\n",
      "MaI14_007_6.jpg_window_24.jpg,   |   16.67%\n",
      "MaI14_007_1.jpg_window_42.jpg,   |   20.83%\n",
      "MaI14_051_05.jpg_window_6.jpg,   |   45.83%\n",
      "MaI849_041_line_7.jpg_window_26.jpg,   |   20.83%\n",
      "MaI14_007_2.jpg_window_49.jpg,   |   12.50%\n",
      "maI16_01_3.jpg_window_18.jpg,   |   7.14%\n",
      "MaI849_041_line_7.jpg_window_11.jpg,   |   100.00%\n",
      "MaI14_051_07.jpg_window_25.jpg,   |   16.67%\n",
      "MaI14_007_2.jpg_window_4.jpg,   |   17.86%\n",
      "MaI849_039_line_6.jpg_window_28.jpg,   |   10.00%\n",
      "MaI849_039_line_5.jpg_window_10.jpg,   |   10.71%\n",
      "MaI849_039_line_2.jpg_window_10.jpg,   |   8.33%\n",
      "MaI14_007_2.jpg_window_20.jpg,   |   12.50%\n",
      "MaI12_Page101_line_4.jpg_window_17.jpg,   |   6.67%\n",
      "MaI12_Page102_line_4.jpg_window_17.jpg,   |   13.33%\n",
      "MaI849_039_line_3.jpg_window_5.jpg,   |   33.33%\n",
      "MaI14_051_08.jpg_window_11.jpg,   |   20.83%\n",
      "MaI14_051_07.jpg_window_8.jpg,   |   8.33%\n",
      "MaI14_007_8.jpg_window_2.jpg,   |   6.25%\n",
      "MaI12_Page101_line_5.jpg_window_4.jpg,   |   7.14%\n",
      "MaI849_041_line_6.jpg_window_43.jpg,   |   12.50%\n",
      "MaI12_Page101_line_5.jpg_window_39.jpg,   |   13.33%\n",
      "MaI14_051_06.jpg_window_22.jpg,   |   29.17%\n",
      "MaI12_Page101_line_5.jpg_window_50.jpg,   |   46.43%\n",
      "MaI849_038_line_2.jpg_window_47.jpg,   |   7.14%\n",
      "MaI12_Page102_line_5.jpg_window_12.jpg,   |   6.67%\n",
      "MaI14_007_8.jpg_window_19.jpg,   |   0.00%\n",
      "MaI14_007_2.jpg_window_2.jpg,   |   5.00%\n",
      "MaI849_038_line_6.jpg_window_3.jpg,   |   12.50%\n",
      "MaI849_038_line_8.jpg_window_26.jpg,   |   5.00%\n",
      "MaI12_Page100_line_5.jpg_window_2.jpg,   |   39.29%\n",
      "MaI12_Page102_line_4.jpg_window_18.jpg,   |   6.67%\n",
      "MaI14_007_2.jpg_window_0.jpg,   |   5.56%\n",
      "MaI849_039_line_4.jpg_window_9.jpg,   |   10.00%\n",
      "MaI14_007_4.jpg_window_17.jpg,   |   17.86%\n",
      "MaI12_Page100_line_2.jpg_window_8.jpg,   |   10.00%\n",
      "MaI849_038_line_5.jpg_window_9.jpg,   |   10.71%\n",
      "MaI14_007_6.jpg_window_49.jpg,   |   25.00%\n",
      "MaI14_007_3.jpg_window_24.jpg,   |   63.33%\n",
      "MaI849_041_line_2.jpg_window_48.jpg,   |   7.14%\n",
      "MaI12_Page100_line_5.jpg_window_39.jpg,   |   76.67%\n",
      "MaI12_Page100_line_1.jpg_window_42.jpg,   |   16.67%\n",
      "MaI849_039_line_3.jpg_window_36.jpg,   |   50.00%\n",
      "MaI12_Page102_line_5.jpg_window_3.jpg,   |   39.29%\n",
      "MaI849_038_line_7.jpg_window_15.jpg,   |   10.00%\n",
      "MaI14_051_07.jpg_window_51.jpg,   |   7.14%\n",
      "maI16_01_9.jpg_window_25.jpg,   |   6.25%\n",
      "maI16_01_5.jpg_window_50.jpg,   |   14.29%\n",
      "maI16_01_8.jpg_window_43.jpg,   |   6.25%\n",
      "maI16_01_1.jpg_window_11.jpg,   |   10.00%\n",
      "maI16_01_4.jpg_window_17.jpg,   |   22.22%\n",
      "MaI849_039_line_9.jpg_window_29.jpg,   |   8.33%\n",
      "maI16_01_5.jpg_window_36.jpg,   |   12.50%\n",
      "MaI12_Page100_line_5.jpg_window_29.jpg,   |   14.29%\n",
      "MaI14_007_1.jpg_window_28.jpg,   |   16.67%\n",
      "MaI12_Page100_line_1.jpg_window_38.jpg,   |   13.33%\n",
      "maI16_01_2.jpg_window_3.jpg,   |   18.75%\n",
      "MaI849_041_line_3.jpg_window_1.jpg,   |   8.33%\n",
      "MaI849_038_line_3.jpg_window_3.jpg,   |   5.00%\n",
      "MaI849_038_line_2.jpg_window_15.jpg,   |   0.00%\n",
      "MaI849_038_line_7.jpg_window_37.jpg,   |   35.71%\n",
      "MaI849_041_line_8.jpg_window_26.jpg,   |   5.00%\n",
      "MaI14_051_01.jpg_window_14.jpg,   |   20.83%\n",
      "MaI12_Page101_line_2.jpg_window_34.jpg,   |   35.71%\n",
      "MaI849_039_line_7.jpg_window_2.jpg,   |   32.14%\n",
      "MaI849_038_line_2.jpg_window_31.jpg,   |   8.33%\n",
      "MaI849_039_line_8.jpg_window_20.jpg,   |   38.89%\n",
      "MaI14_007_6.jpg_window_48.jpg,   |   7.14%\n",
      "maI16_01_8.jpg_window_4.jpg,   |   11.11%\n",
      "MaI14_007_7.jpg_window_0.jpg,   |   42.86%\n",
      "MaI14_051_05.jpg_window_20.jpg,   |   16.67%\n",
      "maI16_01_1.jpg_window_5.jpg,   |   10.00%\n",
      "MaI14_051_05.jpg_window_18.jpg,   |   60.71%\n",
      "MaI849_038_line_2.jpg_window_21.jpg,   |   0.00%\n",
      "MaI12_Page101_line_2.jpg_window_35.jpg,   |   45.83%\n",
      "MaI12_Page102_line_5.jpg_window_19.jpg,   |   42.86%\n",
      "MaI849_038_line_5.jpg_window_4.jpg,   |   17.86%\n",
      "MaI14_051_03.jpg_window_13.jpg,   |   96.43%\n",
      "MaI12_Page100_line_2.jpg_window_7.jpg,   |   10.71%\n",
      "MaI14_051_03.jpg_window_17.jpg,   |   53.57%\n",
      "MaI849_038_line_7.jpg_window_16.jpg,   |   16.67%\n",
      "maI16_01_4.jpg_window_31.jpg,   |   5.56%\n",
      "MaI849_039_line_9.jpg_window_9.jpg,   |   5.00%\n",
      "maI16_01_6.jpg_window_41.jpg,   |   14.29%\n",
      "MaI14_051_04.jpg_window_12.jpg,   |   96.43%\n",
      "MaI849_039_line_2.jpg_window_40.jpg,   |   0.00%\n",
      "MaI849_039_line_2.jpg_window_0.jpg,   |   28.57%\n",
      "MaI12_Page102_line_1.jpg_window_4.jpg,   |   14.29%\n",
      "MaI849_041_line_2.jpg_window_18.jpg,   |   29.17%\n",
      "MaI14_007_5.jpg_window_5.jpg,   |   12.50%\n",
      "MaI849_039_line_9.jpg_window_12.jpg,   |   4.17%\n",
      "MaI12_Page101_line_4.jpg_window_23.jpg,   |   21.43%\n",
      "MaI12_Page102_line_5.jpg_window_28.jpg,   |   0.00%\n",
      "maI16_01_7.jpg_window_29.jpg,   |   5.00%\n",
      "MaI849_038_line_2.jpg_window_24.jpg,   |   13.33%\n",
      "maI16_01_1.jpg_window_48.jpg,   |   10.00%\n",
      "MaI14_007_8.jpg_window_25.jpg,   |   8.33%\n",
      "MaI12_Page101_line_1.jpg_window_33.jpg,   |   23.33%\n",
      "MaI12_Page102_line_2.jpg_window_31.jpg,   |   29.17%\n",
      "MaI12_Page102_line_1.jpg_window_7.jpg,   |   54.17%\n",
      "maI16_01_5.jpg_window_0.jpg,   |   12.50%\n",
      "MaI12_Page100_line_5.jpg_window_24.jpg,   |   35.71%\n",
      "MaI849_038_line_2.jpg_window_10.jpg,   |   21.43%\n",
      "MaI12_Page101_line_5.jpg_window_15.jpg,   |   66.67%\n",
      "MaI849_038_line_1.jpg_window_26.jpg,   |   16.67%\n",
      "maI16_01_8.jpg_window_7.jpg,   |   0.00%\n",
      "MaI12_Page101_line_3.jpg_window_47.jpg,   |   50.00%\n",
      "MaI849_039_line_3.jpg_window_20.jpg,   |   25.00%\n",
      "MaI12_Page100_line_5.jpg_window_9.jpg,   |   23.33%\n",
      "MaI12_Page100_line_4.jpg_window_49.jpg,   |   35.71%\n",
      "MaI12_Page101_line_2.jpg_window_28.jpg,   |   7.14%\n",
      "MaI14_051_03.jpg_window_19.jpg,   |   6.67%\n",
      "MaI12_Page101_line_5.jpg_window_51.jpg,   |   6.67%\n",
      "MaI849_041_line_1.jpg_window_12.jpg,   |   0.00%\n",
      "MaI849_038_line_2.jpg_window_25.jpg,   |   8.33%\n",
      "MaI14_051_04.jpg_window_14.jpg,   |   67.86%\n",
      "MaI849_039_line_3.jpg_window_43.jpg,   |   10.71%\n",
      "MaI849_038_line_6.jpg_window_23.jpg,   |   20.83%\n",
      "MaI14_051_02.jpg_window_10.jpg,   |   21.43%\n",
      "MaI849_039_line_4.jpg_window_11.jpg,   |   50.00%\n",
      "MaI12_Page100_line_1.jpg_window_43.jpg,   |   5.00%\n",
      "MaI849_039_line_7.jpg_window_26.jpg,   |   25.00%\n",
      "MaI14_051_04.jpg_window_25.jpg,   |   20.83%\n",
      "maI16_01_6.jpg_window_32.jpg,   |   35.71%\n",
      "MaI849_041_line_2.jpg_window_30.jpg,   |   12.50%\n",
      "MaI12_Page102_line_1.jpg_window_10.jpg,   |   7.14%\n",
      "MaI849_041_line_8.jpg_window_36.jpg,   |   10.00%\n",
      "MaI14_051_05.jpg_window_38.jpg,   |   78.57%\n",
      "MaI849_038_line_2.jpg_window_20.jpg,   |   0.00%\n",
      "MaI849_038_line_7.jpg_window_22.jpg,   |   5.00%\n",
      "MaI849_038_line_7.jpg_window_28.jpg,   |   0.00%\n",
      "MaI14_007_6.jpg_window_26.jpg,   |   7.14%\n",
      "MaI849_038_line_6.jpg_window_46.jpg,   |   16.67%\n",
      "MaI14_051_05.jpg_window_21.jpg,   |   25.00%\n",
      "MaI849_041_line_9.jpg_window_37.jpg,   |   16.67%\n",
      "MaI12_Page101_line_5.jpg_window_2.jpg,   |   8.33%\n",
      "maI16_01_3.jpg_window_40.jpg,   |   5.00%\n",
      "MaI12_Page102_line_2.jpg_window_48.jpg,   |   20.00%\n",
      "MaI12_Page101_line_5.jpg_window_14.jpg,   |   25.00%\n",
      "MaI849_039_line_8.jpg_window_18.jpg,   |   20.83%\n",
      "MaI12_Page101_line_1.jpg_window_49.jpg,   |   26.67%\n",
      "MaI12_Page100_line_4.jpg_window_26.jpg,   |   53.33%\n",
      "MaI14_051_08.jpg_window_16.jpg,   |   0.00%\n",
      "MaI849_039_line_8.jpg_window_33.jpg,   |   29.17%\n",
      "MaI849_041_line_7.jpg_window_34.jpg,   |   12.50%\n",
      "maI16_01_2.jpg_window_27.jpg,   |   16.67%\n",
      "MaI14_007_4.jpg_window_34.jpg,   |   50.00%\n",
      "MaI14_051_04.jpg_window_41.jpg,   |   20.00%\n",
      "MaI12_Page102_line_4.jpg_window_43.jpg,   |   0.00%\n",
      "MaI849_041_line_6.jpg_window_44.jpg,   |   25.00%\n",
      "MaI849_039_line_6.jpg_window_47.jpg,   |   16.67%\n",
      "MaI12_Page100_line_1.jpg_window_2.jpg,   |   23.33%\n",
      "MaI12_Page100_line_5.jpg_window_32.jpg,   |   25.00%\n",
      "MaI12_Page100_line_2.jpg_window_21.jpg,   |   80.00%\n",
      "maI16_01_1.jpg_window_34.jpg,   |   14.29%\n",
      "MaI849_041_line_7.jpg_window_38.jpg,   |   67.86%\n",
      "MaI12_Page100_line_1.jpg_window_7.jpg,   |   10.71%\n",
      "MaI849_039_line_6.jpg_window_17.jpg,   |   16.67%\n",
      "MaI12_Page100_line_1.jpg_window_39.jpg,   |   25.00%\n",
      "MaI14_007_4.jpg_window_38.jpg,   |   85.71%\n",
      "MaI849_038_line_9.jpg_window_13.jpg,   |   26.67%\n",
      "MaI849_038_line_5.jpg_window_5.jpg,   |   14.29%\n",
      "MaI849_041_line_6.jpg_window_11.jpg,   |   78.57%\n",
      "MaI849_041_line_6.jpg_window_19.jpg,   |   10.00%\n",
      "MaI14_007_4.jpg_window_5.jpg,   |   16.67%\n",
      "MaI849_039_line_3.jpg_window_37.jpg,   |   42.86%\n",
      "MaI849_041_line_8.jpg_window_16.jpg,   |   14.29%\n",
      "MaI849_038_line_3.jpg_window_8.jpg,   |   28.57%\n",
      "MaI849_038_line_2.jpg_window_17.jpg,   |   12.50%\n",
      "MaI14_007_6.jpg_window_47.jpg,   |   21.43%\n",
      "maI16_01_6.jpg_window_26.jpg,   |   25.00%\n",
      "MaI12_Page100_line_4.jpg_window_33.jpg,   |   10.71%\n",
      "maI16_01_9.jpg_window_24.jpg,   |   16.67%\n",
      "MaI14_007_6.jpg_window_14.jpg,   |   46.43%\n",
      "MaI14_051_06.jpg_window_5.jpg,   |   20.83%\n",
      "maI16_01_3.jpg_window_25.jpg,   |   6.25%\n",
      "MaI849_039_line_1.jpg_window_51.jpg,   |   8.33%\n",
      "MaI849_038_line_6.jpg_window_12.jpg,   |   75.00%\n",
      "MaI12_Page102_line_4.jpg_window_39.jpg,   |   16.67%\n",
      "MaI12_Page100_line_4.jpg_window_25.jpg,   |   21.43%\n",
      "MaI849_041_line_6.jpg_window_30.jpg,   |   5.00%\n",
      "MaI14_007_7.jpg_window_2.jpg,   |   10.00%\n",
      "MaI849_041_line_1.jpg_window_30.jpg,   |   16.67%\n",
      "MaI849_038_line_1.jpg_window_15.jpg,   |   0.00%\n",
      "MaI12_Page102_line_2.jpg_window_42.jpg,   |   0.00%\n",
      "MaI12_Page102_line_3.jpg_window_47.jpg,   |   6.67%\n",
      "MaI849_039_line_8.jpg_window_38.jpg,   |   12.50%\n",
      "MaI849_039_line_1.jpg_window_46.jpg,   |   10.71%\n",
      "MaI14_051_06.jpg_window_21.jpg,   |   39.29%\n",
      "MaI14_007_6.jpg_window_9.jpg,   |   8.33%\n",
      "MaI14_007_8.jpg_window_8.jpg,   |   8.33%\n",
      "MaI12_Page100_line_3.jpg_window_7.jpg,   |   13.33%\n",
      "MaI849_039_line_2.jpg_window_37.jpg,   |   8.33%\n",
      "MaI14_051_01.jpg_window_31.jpg,   |   14.29%\n",
      "MaI849_038_line_1.jpg_window_28.jpg,   |   7.14%\n",
      "MaI14_007_2.jpg_window_15.jpg,   |   15.00%\n",
      "MaI14_007_1.jpg_window_13.jpg,   |   70.00%\n",
      "MaI849_039_line_2.jpg_window_24.jpg,   |   10.71%\n",
      "MaI849_038_line_5.jpg_window_8.jpg,   |   21.43%\n",
      "MaI849_039_line_3.jpg_window_3.jpg,   |   0.00%\n",
      "MaI14_007_3.jpg_window_2.jpg,   |   4.17%\n",
      "MaI12_Page101_line_1.jpg_window_47.jpg,   |   10.00%\n",
      "MaI849_039_line_3.jpg_window_10.jpg,   |   16.67%\n",
      "MaI849_038_line_7.jpg_window_41.jpg,   |   16.67%\n",
      "maI16_01_2.jpg_window_36.jpg,   |   20.00%\n",
      "MaI849_038_line_7.jpg_window_23.jpg,   |   11.11%\n",
      "MaI14_051_01.jpg_window_9.jpg,   |   10.00%\n",
      "MaI849_038_line_8.jpg_window_39.jpg,   |   17.86%\n",
      "MaI14_007_5.jpg_window_38.jpg,   |   35.71%\n",
      "MaI14_051_01.jpg_window_48.jpg,   |   28.57%\n",
      "MaI849_041_line_7.jpg_window_10.jpg,   |   67.86%\n",
      "MaI12_Page100_line_1.jpg_window_34.jpg,   |   10.00%\n",
      "MaI849_038_line_9.jpg_window_22.jpg,   |   16.67%\n",
      "MaI849_038_line_3.jpg_window_26.jpg,   |   14.29%\n",
      "MaI849_039_line_9.jpg_window_50.jpg,   |   11.11%\n",
      "MaI12_Page100_line_5.jpg_window_31.jpg,   |   33.33%\n",
      "MaI12_Page100_line_1.jpg_window_32.jpg,   |   45.83%\n",
      "MaI14_051_01.jpg_window_47.jpg,   |   17.86%\n",
      "maI16_01_9.jpg_window_12.jpg,   |   5.00%\n",
      "MaI12_Page101_line_2.jpg_window_3.jpg,   |   7.14%\n",
      "MaI849_039_line_1.jpg_window_18.jpg,   |   15.00%\n",
      "MaI14_007_4.jpg_window_9.jpg,   |   8.33%\n",
      "MaI14_051_03.jpg_window_6.jpg,   |   7.14%\n",
      "MaI14_007_3.jpg_window_37.jpg,   |   78.57%\n",
      "MaI849_039_line_1.jpg_window_42.jpg,   |   5.00%\n",
      "MaI849_039_line_8.jpg_window_7.jpg,   |   8.33%\n",
      "MaI12_Page100_line_5.jpg_window_26.jpg,   |   7.14%\n",
      "MaI12_Page100_line_3.jpg_window_8.jpg,   |   14.29%\n",
      "MaI14_051_03.jpg_window_15.jpg,   |   60.71%\n",
      "MaI12_Page100_line_2.jpg_window_4.jpg,   |   23.33%\n",
      "MaI12_Page102_line_2.jpg_window_23.jpg,   |   13.33%\n",
      "maI16_01_9.jpg_window_34.jpg,   |   5.00%\n",
      "MaI849_038_line_5.jpg_window_48.jpg,   |   0.00%\n",
      "MaI14_051_03.jpg_window_27.jpg,   |   12.50%\n",
      "MaI849_038_line_5.jpg_window_51.jpg,   |   0.00%\n",
      "MaI14_007_9.jpg_window_16.jpg,   |   29.17%\n",
      "MaI14_007_8.jpg_window_30.jpg,   |   15.00%\n",
      "MaI849_038_line_1.jpg_window_1.jpg,   |   5.00%\n",
      "MaI14_051_06.jpg_window_33.jpg,   |   33.33%\n",
      "MaI12_Page102_line_2.jpg_window_16.jpg,   |   26.67%\n",
      "MaI849_038_line_1.jpg_window_11.jpg,   |   21.43%\n",
      "MaI849_039_line_4.jpg_window_25.jpg,   |   11.11%\n",
      "MaI849_038_line_2.jpg_window_27.jpg,   |   8.33%\n",
      "MaI14_051_04.jpg_window_46.jpg,   |   16.67%\n",
      "MaI14_051_02.jpg_window_47.jpg,   |   35.71%\n",
      "MaI12_Page100_line_3.jpg_window_37.jpg,   |   21.43%\n",
      "MaI14_051_06.jpg_window_18.jpg,   |   96.43%\n",
      "MaI14_007_3.jpg_window_41.jpg,   |   28.57%\n",
      "MaI849_041_line_5.jpg_window_42.jpg,   |   10.71%\n",
      "MaI849_041_line_2.jpg_window_38.jpg,   |   14.29%\n",
      "MaI14_007_8.jpg_window_38.jpg,   |   0.00%\n",
      "MaI12_Page102_line_3.jpg_window_26.jpg,   |   10.71%\n",
      "maI16_01_7.jpg_window_38.jpg,   |   0.00%\n",
      "MaI12_Page100_line_5.jpg_window_0.jpg,   |   26.67%\n",
      "MaI849_041_line_6.jpg_window_10.jpg,   |   67.86%\n",
      "MaI12_Page101_line_1.jpg_window_8.jpg,   |   10.71%\n",
      "maI16_01_9.jpg_window_45.jpg,   |   10.00%\n",
      "maI16_01_6.jpg_window_16.jpg,   |   41.67%\n",
      "maI16_01_7.jpg_window_0.jpg,   |   11.11%\n",
      "MaI14_007_6.jpg_window_20.jpg,   |   7.14%\n",
      "maI16_01_3.jpg_window_38.jpg,   |   14.29%\n",
      "MaI849_041_line_8.jpg_window_50.jpg,   |   16.67%\n",
      "MaI12_Page100_line_4.jpg_window_6.jpg,   |   10.71%\n",
      "MaI12_Page100_line_3.jpg_window_39.jpg,   |   30.00%\n",
      "MaI12_Page102_line_4.jpg_window_51.jpg,   |   0.00%\n",
      "MaI12_Page101_line_1.jpg_window_7.jpg,   |   7.14%\n",
      "MaI14_007_4.jpg_window_23.jpg,   |   16.67%\n",
      "MaI12_Page102_line_5.jpg_window_49.jpg,   |   8.33%\n",
      "MaI14_007_8.jpg_window_31.jpg,   |   20.83%\n",
      "MaI849_039_line_1.jpg_window_41.jpg,   |   15.00%\n",
      "MaI849_038_line_7.jpg_window_51.jpg,   |   4.17%\n",
      "MaI12_Page100_line_3.jpg_window_25.jpg,   |   36.67%\n",
      "maI16_01_7.jpg_window_12.jpg,   |   100.00%\n",
      "MaI12_Page100_line_1.jpg_window_24.jpg,   |   50.00%\n",
      "MaI849_039_line_4.jpg_window_39.jpg,   |   25.00%\n",
      "MaI12_Page102_line_1.jpg_window_9.jpg,   |   25.00%\n",
      "MaI14_007_6.jpg_window_41.jpg,   |   6.67%\n",
      "MaI849_038_line_3.jpg_window_16.jpg,   |   5.00%\n",
      "MaI12_Page102_line_2.jpg_window_36.jpg,   |   7.14%\n",
      "MaI14_007_4.jpg_window_8.jpg,   |   8.33%\n",
      "maI16_01_4.jpg_window_19.jpg,   |   11.11%\n",
      "maI16_01_9.jpg_window_16.jpg,   |   12.50%\n",
      "MaI14_007_9.jpg_window_11.jpg,   |   93.33%\n",
      "MaI12_Page100_line_1.jpg_window_49.jpg,   |   53.57%\n",
      "MaI849_038_line_7.jpg_window_40.jpg,   |   8.33%\n",
      "maI16_01_9.jpg_window_21.jpg,   |   5.56%\n",
      "MaI12_Page100_line_1.jpg_window_31.jpg,   |   16.67%\n",
      "MaI12_Page102_line_4.jpg_window_24.jpg,   |   7.14%\n",
      "MaI12_Page102_line_1.jpg_window_29.jpg,   |   14.29%\n",
      "MaI14_007_5.jpg_window_43.jpg,   |   10.00%\n",
      "MaI849_041_line_7.jpg_window_28.jpg,   |   42.86%\n",
      "MaI849_039_line_1.jpg_window_49.jpg,   |   0.00%\n",
      "MaI12_Page101_line_2.jpg_window_32.jpg,   |   32.14%\n",
      "MaI849_041_line_4.jpg_window_50.jpg,   |   12.50%\n",
      "maI16_01_2.jpg_window_40.jpg,   |   20.00%\n",
      "MaI14_007_2.jpg_window_1.jpg,   |   5.56%\n",
      "MaI12_Page100_line_2.jpg_window_10.jpg,   |   10.71%\n",
      "MaI14_007_2.jpg_window_42.jpg,   |   20.83%\n",
      "maI16_01_3.jpg_window_37.jpg,   |   20.00%\n",
      "maI16_01_7.jpg_window_23.jpg,   |   11.11%\n",
      "MaI14_051_05.jpg_window_2.jpg,   |   12.50%\n",
      "maI16_01_2.jpg_window_33.jpg,   |   7.14%\n",
      "MaI12_Page101_line_3.jpg_window_29.jpg,   |   28.57%\n",
      "MaI849_041_line_2.jpg_window_10.jpg,   |   12.50%\n",
      "MaI849_041_line_4.jpg_window_14.jpg,   |   6.67%\n",
      "MaI849_039_line_6.jpg_window_10.jpg,   |   64.29%\n",
      "MaI849_038_line_7.jpg_window_49.jpg,   |   5.00%\n",
      "MaI12_Page102_line_3.jpg_window_51.jpg,   |   25.00%\n",
      "MaI849_041_line_7.jpg_window_24.jpg,   |   0.00%\n",
      "MaI12_Page100_line_3.jpg_window_0.jpg,   |   6.67%\n",
      "MaI849_041_line_6.jpg_window_49.jpg,   |   29.17%\n",
      "MaI12_Page102_line_3.jpg_window_44.jpg,   |   14.29%\n",
      "MaI14_007_5.jpg_window_40.jpg,   |   30.00%\n",
      "MaI12_Page101_line_2.jpg_window_38.jpg,   |   10.71%\n",
      "MaI12_Page101_line_5.jpg_window_38.jpg,   |   10.71%\n",
      "MaI849_038_line_4.jpg_window_49.jpg,   |   0.00%\n",
      "MaI849_038_line_6.jpg_window_22.jpg,   |   33.33%\n",
      "MaI14_007_1.jpg_window_44.jpg,   |   62.50%\n",
      "MaI849_039_line_6.jpg_window_24.jpg,   |   10.00%\n",
      "MaI849_039_line_6.jpg_window_20.jpg,   |   8.33%\n",
      "MaI14_007_3.jpg_window_12.jpg,   |   67.86%\n",
      "MaI12_Page101_line_5.jpg_window_21.jpg,   |   10.71%\n",
      "MaI14_051_04.jpg_window_24.jpg,   |   25.00%\n",
      "MaI12_Page101_line_1.jpg_window_38.jpg,   |   10.71%\n",
      "MaI849_038_line_3.jpg_window_39.jpg,   |   14.29%\n",
      "MaI849_039_line_6.jpg_window_1.jpg,   |   7.14%\n",
      "MaI849_039_line_5.jpg_window_12.jpg,   |   14.29%\n",
      "MaI849_041_line_4.jpg_window_29.jpg,   |   0.00%\n",
      "MaI849_038_line_2.jpg_window_41.jpg,   |   14.29%\n",
      "MaI14_051_06.jpg_window_2.jpg,   |   29.17%\n",
      "MaI12_Page102_line_1.jpg_window_19.jpg,   |   40.00%\n",
      "MaI849_041_line_7.jpg_window_49.jpg,   |   5.56%\n",
      "MaI849_041_line_1.jpg_window_42.jpg,   |   20.00%\n",
      "MaI849_039_line_1.jpg_window_11.jpg,   |   17.86%\n",
      "MaI14_051_02.jpg_window_51.jpg,   |   46.43%\n",
      "MaI849_038_line_6.jpg_window_27.jpg,   |   21.43%\n",
      "MaI849_041_line_1.jpg_window_11.jpg,   |   16.67%\n",
      "MaI12_Page102_line_3.jpg_window_0.jpg,   |   14.29%\n",
      "MaI12_Page102_line_1.jpg_window_11.jpg,   |   33.33%\n",
      "MaI14_051_07.jpg_window_38.jpg,   |   17.86%\n",
      "MaI849_041_line_3.jpg_window_30.jpg,   |   25.00%\n",
      "maI16_01_6.jpg_window_27.jpg,   |   12.50%\n",
      "MaI14_051_07.jpg_window_47.jpg,   |   8.33%\n",
      "maI16_01_5.jpg_window_23.jpg,   |   14.29%\n",
      "MaI14_051_07.jpg_window_31.jpg,   |   12.50%\n",
      "MaI14_007_7.jpg_window_21.jpg,   |   15.00%\n",
      "MaI849_038_line_6.jpg_window_20.jpg,   |   10.71%\n",
      "MaI12_Page100_line_2.jpg_window_15.jpg,   |   40.00%\n",
      "MaI14_051_03.jpg_window_40.jpg,   |   92.86%\n",
      "MaI14_007_3.jpg_window_39.jpg,   |   50.00%\n",
      "MaI849_039_line_4.jpg_window_42.jpg,   |   5.00%\n",
      "MaI849_038_line_7.jpg_window_0.jpg,   |   12.50%\n",
      "MaI849_039_line_9.jpg_window_41.jpg,   |   28.57%\n",
      "MaI12_Page101_line_3.jpg_window_27.jpg,   |   16.67%\n",
      "MaI14_007_3.jpg_window_16.jpg,   |   78.57%\n",
      "MaI849_039_line_9.jpg_window_42.jpg,   |   28.57%\n",
      "MaI12_Page101_line_3.jpg_window_37.jpg,   |   28.57%\n",
      "MaI12_Page101_line_3.jpg_window_38.jpg,   |   32.14%\n",
      "MaI849_041_line_8.jpg_window_14.jpg,   |   5.00%\n",
      "MaI14_007_6.jpg_window_8.jpg,   |   11.11%\n",
      "MaI12_Page100_line_1.jpg_window_37.jpg,   |   21.43%\n",
      "MaI14_051_04.jpg_window_51.jpg,   |   28.57%\n",
      "MaI849_039_line_9.jpg_window_11.jpg,   |   8.33%\n",
      "MaI14_051_08.jpg_window_45.jpg,   |   0.00%\n",
      "MaI14_007_6.jpg_window_45.jpg,   |   10.71%\n",
      "MaI849_041_line_7.jpg_window_44.jpg,   |   5.56%\n",
      "MaI849_039_line_4.jpg_window_20.jpg,   |   8.33%\n",
      "MaI12_Page102_line_3.jpg_window_45.jpg,   |   12.50%\n",
      "MaI12_Page100_line_1.jpg_window_20.jpg,   |   26.67%\n",
      "MaI849_041_line_9.jpg_window_41.jpg,   |   57.14%\n",
      "MaI849_038_line_4.jpg_window_10.jpg,   |   50.00%\n",
      "MaI14_007_6.jpg_window_36.jpg,   |   67.86%\n",
      "MaI849_039_line_5.jpg_window_15.jpg,   |   21.43%\n",
      "MaI849_038_line_9.jpg_window_2.jpg,   |   14.29%\n",
      "MaI14_007_4.jpg_window_14.jpg,   |   100.00%\n",
      "MaI849_039_line_9.jpg_window_4.jpg,   |   4.17%\n",
      "maI16_01_9.jpg_window_15.jpg,   |   12.50%\n",
      "MaI849_041_line_8.jpg_window_28.jpg,   |   8.33%\n",
      "MaI14_051_03.jpg_window_16.jpg,   |   57.14%\n",
      "MaI14_007_7.jpg_window_19.jpg,   |   21.43%\n",
      "MaI12_Page101_line_4.jpg_window_32.jpg,   |   30.00%\n",
      "MaI849_041_line_9.jpg_window_44.jpg,   |   8.33%\n",
      "MaI849_039_line_5.jpg_window_37.jpg,   |   64.29%\n",
      "MaI12_Page101_line_2.jpg_window_49.jpg,   |   16.67%\n",
      "MaI849_041_line_3.jpg_window_27.jpg,   |   10.71%\n",
      "MaI849_038_line_6.jpg_window_28.jpg,   |   17.86%\n",
      "MaI12_Page100_line_1.jpg_window_6.jpg,   |   10.00%\n",
      "MaI849_038_line_3.jpg_window_51.jpg,   |   12.50%\n",
      "MaI849_039_line_7.jpg_window_16.jpg,   |   0.00%\n",
      "MaI849_041_line_1.jpg_window_26.jpg,   |   35.71%\n",
      "MaI14_007_2.jpg_window_43.jpg,   |   16.67%\n",
      "MaI14_051_05.jpg_window_25.jpg,   |   15.00%\n",
      "maI16_01_8.jpg_window_12.jpg,   |   11.11%\n",
      "MaI849_041_line_7.jpg_window_47.jpg,   |   16.67%\n",
      "MaI14_051_06.jpg_window_9.jpg,   |   12.50%\n",
      "maI16_01_5.jpg_window_37.jpg,   |   16.67%\n",
      "MaI14_007_1.jpg_window_9.jpg,   |   17.86%\n",
      "MaI849_039_line_8.jpg_window_50.jpg,   |   16.67%\n",
      "MaI14_007_5.jpg_window_17.jpg,   |   53.57%\n",
      "MaI849_039_line_1.jpg_window_19.jpg,   |   25.00%\n",
      "MaI14_007_6.jpg_window_11.jpg,   |   75.00%\n",
      "MaI14_051_04.jpg_window_29.jpg,   |   20.00%\n",
      "maI16_01_5.jpg_window_12.jpg,   |   46.43%\n",
      "MaI849_038_line_3.jpg_window_34.jpg,   |   0.00%\n",
      "MaI12_Page102_line_5.jpg_window_2.jpg,   |   25.00%\n",
      "MaI849_041_line_6.jpg_window_12.jpg,   |   85.71%\n",
      "MaI849_041_line_4.jpg_window_13.jpg,   |   96.43%\n",
      "MaI849_038_line_7.jpg_window_13.jpg,   |   60.71%\n",
      "MaI849_041_line_1.jpg_window_17.jpg,   |   0.00%\n",
      "MaI849_041_line_8.jpg_window_41.jpg,   |   20.83%\n",
      "MaI14_007_7.jpg_window_36.jpg,   |   32.14%\n",
      "MaI12_Page100_line_2.jpg_window_14.jpg,   |   17.86%\n",
      "MaI849_039_line_4.jpg_window_29.jpg,   |   8.33%\n",
      "MaI14_051_04.jpg_window_44.jpg,   |   12.50%\n",
      "MaI849_041_line_6.jpg_window_41.jpg,   |   16.67%\n",
      "MaI849_038_line_9.jpg_window_14.jpg,   |   12.50%\n",
      "MaI849_039_line_5.jpg_window_45.jpg,   |   7.14%\n",
      "MaI12_Page102_line_4.jpg_window_8.jpg,   |   13.33%\n",
      "MaI849_039_line_6.jpg_window_12.jpg,   |   89.29%\n",
      "MaI14_051_03.jpg_window_36.jpg,   |   85.71%\n",
      "MaI849_039_line_6.jpg_window_29.jpg,   |   5.56%\n",
      "MaI14_051_07.jpg_window_2.jpg,   |   10.71%\n",
      "MaI12_Page100_line_3.jpg_window_2.jpg,   |   40.00%\n",
      "MaI14_051_06.jpg_window_45.jpg,   |   5.00%\n",
      "MaI14_007_9.jpg_window_10.jpg,   |   0.00%\n",
      "MaI849_039_line_3.jpg_window_0.jpg,   |   25.00%\n",
      "MaI849_039_line_1.jpg_window_25.jpg,   |   20.00%\n",
      "MaI849_041_line_9.jpg_window_1.jpg,   |   0.00%\n",
      "MaI849_041_line_6.jpg_window_48.jpg,   |   11.11%\n",
      "MaI849_041_line_5.jpg_window_1.jpg,   |   8.33%\n",
      "MaI12_Page102_line_5.jpg_window_35.jpg,   |   25.00%\n",
      "MaI849_041_line_1.jpg_window_7.jpg,   |   21.43%\n",
      "MaI849_038_line_5.jpg_window_11.jpg,   |   85.71%\n",
      "MaI849_041_line_3.jpg_window_21.jpg,   |   5.00%\n",
      "MaI12_Page100_line_2.jpg_window_1.jpg,   |   17.86%\n",
      "MaI849_038_line_9.jpg_window_12.jpg,   |   7.14%\n",
      "MaI849_039_line_3.jpg_window_35.jpg,   |   50.00%\n",
      "MaI14_007_6.jpg_window_35.jpg,   |   71.43%\n",
      "MaI849_041_line_2.jpg_window_35.jpg,   |   10.00%\n",
      "MaI14_051_05.jpg_window_14.jpg,   |   60.71%\n",
      "MaI849_041_line_1.jpg_window_41.jpg,   |   0.00%\n",
      "MaI849_041_line_7.jpg_window_37.jpg,   |   100.00%\n",
      "MaI14_007_4.jpg_window_13.jpg,   |   67.86%\n",
      "MaI12_Page100_line_5.jpg_window_18.jpg,   |   10.71%\n",
      "MaI12_Page100_line_4.jpg_window_37.jpg,   |   22.22%\n",
      "MaI12_Page100_line_4.jpg_window_46.jpg,   |   25.00%\n",
      "MaI12_Page102_line_3.jpg_window_4.jpg,   |   21.43%\n",
      "MaI12_Page102_line_1.jpg_window_5.jpg,   |   20.83%\n",
      "MaI849_041_line_9.jpg_window_30.jpg,   |   7.14%\n",
      "MaI12_Page100_line_2.jpg_window_20.jpg,   |   50.00%\n",
      "MaI12_Page100_line_2.jpg_window_37.jpg,   |   36.67%\n",
      "MaI14_007_6.jpg_window_37.jpg,   |   85.71%\n",
      "maI16_01_2.jpg_window_41.jpg,   |   16.67%\n",
      "MaI849_041_line_9.jpg_window_43.jpg,   |   12.50%\n",
      "MaI849_041_line_1.jpg_window_10.jpg,   |   39.29%\n",
      "maI16_01_6.jpg_window_14.jpg,   |   17.86%\n",
      "MaI14_007_4.jpg_window_50.jpg,   |   16.67%\n",
      "MaI849_039_line_5.jpg_window_21.jpg,   |   8.33%\n",
      "maI16_01_8.jpg_window_41.jpg,   |   7.14%\n",
      "MaI849_041_line_5.jpg_window_13.jpg,   |   82.14%\n",
      "maI16_01_2.jpg_window_12.jpg,   |   11.11%\n",
      "MaI849_038_line_1.jpg_window_51.jpg,   |   25.00%\n",
      "MaI12_Page100_line_5.jpg_window_33.jpg,   |   7.14%\n",
      "MaI14_007_4.jpg_window_27.jpg,   |   4.17%\n",
      "MaI14_007_3.jpg_window_0.jpg,   |   16.67%\n",
      "MaI14_051_04.jpg_window_18.jpg,   |   32.14%\n",
      "MaI12_Page101_line_1.jpg_window_16.jpg,   |   16.67%\n",
      "MaI14_007_7.jpg_window_3.jpg,   |   25.00%\n",
      "MaI849_041_line_7.jpg_window_35.jpg,   |   25.00%\n",
      "maI16_01_3.jpg_window_28.jpg,   |   5.56%\n",
      "MaI849_039_line_5.jpg_window_20.jpg,   |   10.71%\n",
      "MaI12_Page100_line_4.jpg_window_7.jpg,   |   21.43%\n",
      "MaI12_Page102_line_2.jpg_window_46.jpg,   |   33.33%\n",
      "MaI14_051_08.jpg_window_35.jpg,   |   16.67%\n",
      "MaI849_041_line_3.jpg_window_33.jpg,   |   7.14%\n",
      "MaI12_Page100_line_4.jpg_window_50.jpg,   |   12.50%\n",
      "maI16_01_6.jpg_window_20.jpg,   |   7.14%\n",
      "MaI14_007_4.jpg_window_45.jpg,   |   17.86%\n",
      "maI16_01_6.jpg_window_15.jpg,   |   56.67%\n",
      "MaI12_Page100_line_4.jpg_window_31.jpg,   |   14.29%\n",
      "MaI14_007_3.jpg_window_40.jpg,   |   64.29%\n",
      "MaI14_007_4.jpg_window_37.jpg,   |   82.14%\n",
      "MaI12_Page101_line_4.jpg_window_35.jpg,   |   20.83%\n",
      "MaI14_007_9.jpg_window_33.jpg,   |   20.83%\n",
      "maI16_01_1.jpg_window_0.jpg,   |   16.67%\n",
      "MaI849_041_line_2.jpg_window_17.jpg,   |   7.14%\n",
      "MaI849_038_line_3.jpg_window_35.jpg,   |   3.57%\n",
      "MaI14_051_03.jpg_window_34.jpg,   |   0.00%\n",
      "MaI14_007_8.jpg_window_17.jpg,   |   10.71%\n",
      "MaI849_038_line_2.jpg_window_49.jpg,   |   8.33%\n",
      "MaI849_041_line_2.jpg_window_19.jpg,   |   30.00%\n",
      "MaI849_039_line_9.jpg_window_49.jpg,   |   5.56%\n",
      "MaI12_Page101_line_2.jpg_window_14.jpg,   |   10.00%\n",
      "MaI12_Page100_line_5.jpg_window_51.jpg,   |   0.00%\n",
      "maI16_01_6.jpg_window_47.jpg,   |   20.83%\n",
      "maI16_01_9.jpg_window_23.jpg,   |   14.29%\n",
      "MaI849_041_line_7.jpg_window_1.jpg,   |   5.56%\n",
      "MaI14_051_03.jpg_window_50.jpg,   |   5.56%\n",
      "MaI12_Page100_line_3.jpg_window_16.jpg,   |   14.29%\n",
      "MaI12_Page101_line_1.jpg_window_20.jpg,   |   30.00%\n",
      "maI16_01_5.jpg_window_49.jpg,   |   22.22%\n",
      "MaI849_038_line_3.jpg_window_0.jpg,   |   46.67%\n",
      "MaI849_041_line_1.jpg_window_34.jpg,   |   17.86%\n",
      "MaI12_Page102_line_2.jpg_window_43.jpg,   |   25.00%\n",
      "MaI14_007_6.jpg_window_4.jpg,   |   8.33%\n",
      "MaI849_039_line_4.jpg_window_5.jpg,   |   0.00%\n",
      "MaI12_Page102_line_1.jpg_window_28.jpg,   |   50.00%\n",
      "MaI849_039_line_8.jpg_window_51.jpg,   |   10.00%\n",
      "MaI849_041_line_5.jpg_window_4.jpg,   |   0.00%\n",
      "MaI12_Page100_line_1.jpg_window_26.jpg,   |   32.14%\n",
      "MaI849_041_line_9.jpg_window_51.jpg,   |   42.86%\n",
      "MaI12_Page100_line_2.jpg_window_45.jpg,   |   26.67%\n",
      "MaI12_Page102_line_5.jpg_window_1.jpg,   |   21.43%\n",
      "MaI849_039_line_2.jpg_window_39.jpg,   |   0.00%\n",
      "MaI14_007_4.jpg_window_42.jpg,   |   16.67%\n",
      "MaI849_039_line_7.jpg_window_36.jpg,   |   7.14%\n",
      "MaI12_Page102_line_1.jpg_window_35.jpg,   |   14.29%\n",
      "MaI849_039_line_6.jpg_window_41.jpg,   |   0.00%\n",
      "MaI849_038_line_4.jpg_window_11.jpg,   |   57.14%\n",
      "MaI14_051_02.jpg_window_14.jpg,   |   29.17%\n",
      "MaI849_038_line_8.jpg_window_0.jpg,   |   13.33%\n",
      "MaI12_Page102_line_3.jpg_window_38.jpg,   |   12.50%\n",
      "MaI849_041_line_8.jpg_window_13.jpg,   |   5.00%\n",
      "MaI849_041_line_7.jpg_window_23.jpg,   |   0.00%\n",
      "MaI14_051_05.jpg_window_12.jpg,   |   96.43%\n",
      "MaI849_038_line_8.jpg_window_33.jpg,   |   7.14%\n",
      "MaI12_Page100_line_2.jpg_window_51.jpg,   |   17.86%\n",
      "maI16_01_6.jpg_window_30.jpg,   |   6.25%\n",
      "MaI849_039_line_2.jpg_window_48.jpg,   |   20.00%\n",
      "MaI14_007_7.jpg_window_8.jpg,   |   28.57%\n",
      "MaI14_007_5.jpg_window_13.jpg,   |   71.43%\n",
      "MaI849_038_line_7.jpg_window_33.jpg,   |   5.00%\n",
      "MaI12_Page102_line_4.jpg_window_29.jpg,   |   7.14%\n",
      "MaI12_Page101_line_5.jpg_window_34.jpg,   |   35.71%\n",
      "MaI12_Page101_line_1.jpg_window_17.jpg,   |   17.86%\n",
      "maI16_01_7.jpg_window_51.jpg,   |   16.67%\n",
      "MaI12_Page100_line_3.jpg_window_26.jpg,   |   33.33%\n",
      "MaI849_039_line_9.jpg_window_34.jpg,   |   17.86%\n",
      "MaI849_038_line_3.jpg_window_25.jpg,   |   21.43%\n",
      "MaI14_007_3.jpg_window_15.jpg,   |   82.14%\n",
      "maI16_01_2.jpg_window_11.jpg,   |   22.22%\n",
      "MaI849_039_line_5.jpg_window_36.jpg,   |   35.71%\n",
      "MaI849_039_line_3.jpg_window_41.jpg,   |   0.00%\n",
      "MaI849_038_line_3.jpg_window_13.jpg,   |   28.57%\n",
      "MaI12_Page101_line_5.jpg_window_47.jpg,   |   17.86%\n",
      "MaI849_038_line_7.jpg_window_45.jpg,   |   8.33%\n",
      "MaI12_Page100_line_4.jpg_window_1.jpg,   |   14.29%\n",
      "MaI849_041_line_4.jpg_window_12.jpg,   |   100.00%\n",
      "MaI14_007_7.jpg_window_26.jpg,   |   8.33%\n",
      "MaI12_Page101_line_2.jpg_window_48.jpg,   |   10.00%\n",
      "MaI849_039_line_6.jpg_window_38.jpg,   |   60.71%\n",
      "MaI12_Page100_line_1.jpg_window_47.jpg,   |   42.86%\n",
      "MaI14_007_9.jpg_window_6.jpg,   |   7.14%\n",
      "MaI12_Page101_line_5.jpg_window_46.jpg,   |   13.33%\n",
      "MaI849_041_line_7.jpg_window_32.jpg,   |   33.33%\n",
      "MaI12_Page102_line_5.jpg_window_26.jpg,   |   70.00%\n",
      "MaI849_041_line_9.jpg_window_18.jpg,   |   25.00%\n",
      "MaI849_039_line_2.jpg_window_23.jpg,   |   12.50%\n",
      "MaI849_038_line_9.jpg_window_1.jpg,   |   14.29%\n",
      "MaI14_051_07.jpg_window_11.jpg,   |   8.33%\n",
      "MaI14_051_05.jpg_window_39.jpg,   |   71.43%\n",
      "MaI14_051_03.jpg_window_32.jpg,   |   4.17%\n",
      "MaI849_039_line_7.jpg_window_18.jpg,   |   5.56%\n",
      "MaI849_039_line_6.jpg_window_23.jpg,   |   5.00%\n",
      "MaI849_041_line_2.jpg_window_39.jpg,   |   25.00%\n",
      "MaI849_039_line_5.jpg_window_28.jpg,   |   10.00%\n",
      "MaI12_Page102_line_2.jpg_window_3.jpg,   |   12.50%\n",
      "maI16_01_3.jpg_window_36.jpg,   |   15.00%\n",
      "MaI849_041_line_4.jpg_window_4.jpg,   |   0.00%\n",
      "MaI849_039_line_6.jpg_window_37.jpg,   |   75.00%\n",
      "MaI12_Page101_line_2.jpg_window_11.jpg,   |   15.00%\n",
      "MaI12_Page102_line_3.jpg_window_21.jpg,   |   16.67%\n",
      "MaI14_007_2.jpg_window_26.jpg,   |   11.11%\n",
      "MaI12_Page101_line_4.jpg_window_27.jpg,   |   35.71%\n",
      "MaI12_Page102_line_1.jpg_window_13.jpg,   |   66.67%\n",
      "maI16_01_9.jpg_window_27.jpg,   |   0.00%\n",
      "maI16_01_3.jpg_window_42.jpg,   |   6.25%\n",
      "MaI14_007_5.jpg_window_23.jpg,   |   46.43%\n",
      "MaI849_039_line_7.jpg_window_29.jpg,   |   17.86%\n",
      "MaI14_007_7.jpg_window_25.jpg,   |   25.00%\n",
      "MaI849_038_line_2.jpg_window_50.jpg,   |   20.83%\n",
      "MaI849_038_line_5.jpg_window_33.jpg,   |   0.00%\n",
      "MaI12_Page102_line_4.jpg_window_1.jpg,   |   25.00%\n",
      "MaI14_007_5.jpg_window_28.jpg,   |   8.33%\n",
      "MaI14_051_01.jpg_window_4.jpg,   |   8.33%\n",
      "MaI849_039_line_7.jpg_window_23.jpg,   |   8.33%\n",
      "MaI849_038_line_3.jpg_window_29.jpg,   |   7.14%\n",
      "MaI849_041_line_8.jpg_window_4.jpg,   |   16.67%\n",
      "MaI12_Page100_line_3.jpg_window_41.jpg,   |   30.00%\n",
      "MaI849_038_line_8.jpg_window_22.jpg,   |   12.50%\n",
      "MaI12_Page102_line_4.jpg_window_23.jpg,   |   53.57%\n",
      "MaI14_051_07.jpg_window_42.jpg,   |   5.00%\n",
      "MaI12_Page101_line_3.jpg_window_23.jpg,   |   14.29%\n",
      "MaI849_041_line_3.jpg_window_26.jpg,   |   8.33%\n",
      "maI16_01_8.jpg_window_42.jpg,   |   6.25%\n",
      "MaI849_041_line_8.jpg_window_5.jpg,   |   8.33%\n",
      "MaI14_007_1.jpg_window_4.jpg,   |   12.50%\n",
      "MaI12_Page102_line_5.jpg_window_21.jpg,   |   53.57%\n",
      "maI16_01_1.jpg_window_13.jpg,   |   7.14%\n",
      "MaI14_051_01.jpg_window_45.jpg,   |   7.14%\n",
      "MaI14_007_3.jpg_window_14.jpg,   |   92.86%\n",
      "MaI14_051_05.jpg_window_5.jpg,   |   45.83%\n",
      "MaI12_Page101_line_2.jpg_window_20.jpg,   |   10.71%\n",
      "MaI14_051_02.jpg_window_41.jpg,   |   12.50%\n",
      "MaI849_041_line_8.jpg_window_21.jpg,   |   8.33%\n",
      "MaI14_007_9.jpg_window_19.jpg,   |   8.33%\n",
      "MaI12_Page101_line_1.jpg_window_9.jpg,   |   12.50%\n",
      "MaI849_041_line_4.jpg_window_5.jpg,   |   0.00%\n",
      "MaI14_051_05.jpg_window_1.jpg,   |   8.33%\n",
      "MaI849_038_line_9.jpg_window_15.jpg,   |   12.50%\n",
      "MaI849_039_line_5.jpg_window_27.jpg,   |   12.50%\n",
      "MaI849_039_line_4.jpg_window_16.jpg,   |   25.00%\n",
      "MaI849_038_line_4.jpg_window_1.jpg,   |   12.50%\n",
      "MaI849_038_line_7.jpg_window_50.jpg,   |   4.17%\n",
      "MaI849_041_line_4.jpg_window_38.jpg,   |   96.43%\n",
      "MaI14_007_2.jpg_window_50.jpg,   |   8.33%\n",
      "MaI849_041_line_1.jpg_window_39.jpg,   |   16.67%\n",
      "maI16_01_9.jpg_window_10.jpg,   |   7.14%\n",
      "MaI12_Page101_line_2.jpg_window_50.jpg,   |   28.57%\n",
      "MaI849_041_line_4.jpg_window_43.jpg,   |   5.00%\n",
      "MaI14_051_07.jpg_window_18.jpg,   |   8.33%\n",
      "MaI14_051_08.jpg_window_29.jpg,   |   29.17%\n",
      "MaI849_038_line_5.jpg_window_34.jpg,   |   0.00%\n",
      "MaI849_038_line_5.jpg_window_46.jpg,   |   4.17%\n",
      "maI16_01_5.jpg_window_11.jpg,   |   11.11%\n",
      "MaI849_038_line_3.jpg_window_22.jpg,   |   25.00%\n",
      "MaI14_007_4.jpg_window_46.jpg,   |   7.14%\n",
      "MaI12_Page100_line_2.jpg_window_35.jpg,   |   13.33%\n",
      "MaI849_038_line_9.jpg_window_37.jpg,   |   5.00%\n",
      "MaI12_Page100_line_1.jpg_window_11.jpg,   |   16.67%\n",
      "MaI14_007_1.jpg_window_10.jpg,   |   39.29%\n",
      "MaI12_Page101_line_2.jpg_window_17.jpg,   |   16.67%\n",
      "MaI849_038_line_7.jpg_window_32.jpg,   |   0.00%\n",
      "MaI849_041_line_4.jpg_window_11.jpg,   |   71.43%\n",
      "MaI12_Page100_line_5.jpg_window_22.jpg,   |   40.00%\n",
      "MaI849_041_line_7.jpg_window_48.jpg,   |   22.22%\n",
      "maI16_01_3.jpg_window_24.jpg,   |   6.25%\n",
      "MaI14_051_06.jpg_window_14.jpg,   |   85.71%\n",
      "maI16_01_3.jpg_window_23.jpg,   |   11.11%\n",
      "MaI849_038_line_8.jpg_window_1.jpg,   |   10.71%\n",
      "MaI849_039_line_2.jpg_window_4.jpg,   |   0.00%\n",
      "MaI849_041_line_6.jpg_window_24.jpg,   |   5.56%\n",
      "MaI14_051_08.jpg_window_1.jpg,   |   10.00%\n",
      "MaI849_041_line_9.jpg_window_40.jpg,   |   33.33%\n",
      "MaI12_Page100_line_2.jpg_window_17.jpg,   |   20.00%\n",
      "MaI849_039_line_7.jpg_window_25.jpg,   |   8.33%\n",
      "MaI849_041_line_9.jpg_window_21.jpg,   |   5.56%\n",
      "MaI849_038_line_4.jpg_window_29.jpg,   |   10.71%\n",
      "maI16_01_9.jpg_window_47.jpg,   |   10.00%\n",
      "MaI12_Page100_line_5.jpg_window_35.jpg,   |   25.00%\n",
      "MaI849_039_line_4.jpg_window_21.jpg,   |   8.33%\n",
      "MaI849_039_line_7.jpg_window_8.jpg,   |   14.29%\n",
      "MaI849_038_line_6.jpg_window_2.jpg,   |   16.67%\n",
      "MaI14_051_05.jpg_window_31.jpg,   |   14.29%\n",
      "MaI12_Page102_line_1.jpg_window_32.jpg,   |   17.86%\n",
      "MaI849_038_line_3.jpg_window_1.jpg,   |   35.71%\n",
      "MaI14_051_01.jpg_window_30.jpg,   |   16.67%\n",
      "MaI849_041_line_4.jpg_window_17.jpg,   |   15.00%\n",
      "MaI12_Page100_line_1.jpg_window_46.jpg,   |   35.71%\n",
      "MaI12_Page102_line_1.jpg_window_47.jpg,   |   36.67%\n",
      "MaI14_007_3.jpg_window_42.jpg,   |   20.83%\n",
      "MaI849_039_line_8.jpg_window_46.jpg,   |   10.71%\n",
      "MaI12_Page102_line_1.jpg_window_1.jpg,   |   50.00%\n",
      "MaI849_039_line_7.jpg_window_32.jpg,   |   12.50%\n",
      "MaI849_041_line_4.jpg_window_28.jpg,   |   8.33%\n",
      "MaI14_007_7.jpg_window_44.jpg,   |   33.33%\n",
      "MaI849_038_line_7.jpg_window_29.jpg,   |   0.00%\n",
      "MaI12_Page101_line_1.jpg_window_48.jpg,   |   25.00%\n",
      "MaI14_051_01.jpg_window_50.jpg,   |   20.83%\n",
      "MaI12_Page101_line_4.jpg_window_25.jpg,   |   10.71%\n",
      "MaI14_007_1.jpg_window_12.jpg,   |   16.67%\n",
      "MaI14_007_4.jpg_window_10.jpg,   |   64.29%\n",
      "MaI849_039_line_3.jpg_window_47.jpg,   |   8.33%\n",
      "MaI849_039_line_1.jpg_window_24.jpg,   |   10.00%\n",
      "MaI12_Page101_line_1.jpg_window_1.jpg,   |   14.29%\n",
      "MaI849_038_line_2.jpg_window_37.jpg,   |   21.43%\n",
      "MaI12_Page100_line_2.jpg_window_33.jpg,   |   15.00%\n",
      "MaI849_038_line_6.jpg_window_21.jpg,   |   20.83%\n",
      "MaI14_007_8.jpg_window_39.jpg,   |   0.00%\n",
      "maI16_01_2.jpg_window_24.jpg,   |   7.14%\n",
      "MaI12_Page102_line_4.jpg_window_19.jpg,   |   35.71%\n",
      "MaI12_Page101_line_3.jpg_window_5.jpg,   |   7.14%\n",
      "MaI14_051_03.jpg_window_9.jpg,   |   8.33%\n",
      "MaI14_007_3.jpg_window_29.jpg,   |   21.43%\n",
      "MaI849_039_line_4.jpg_window_1.jpg,   |   0.00%\n",
      "MaI12_Page100_line_5.jpg_window_47.jpg,   |   46.67%\n",
      "MaI849_041_line_2.jpg_window_43.jpg,   |   5.00%\n",
      "MaI849_039_line_1.jpg_window_48.jpg,   |   4.17%\n",
      "MaI12_Page100_line_2.jpg_window_0.jpg,   |   10.00%\n",
      "MaI14_007_8.jpg_window_15.jpg,   |   21.43%\n",
      "MaI12_Page102_line_5.jpg_window_31.jpg,   |   10.71%\n",
      "MaI849_041_line_6.jpg_window_22.jpg,   |   16.67%\n",
      "MaI14_051_08.jpg_window_37.jpg,   |   14.29%\n",
      "MaI14_007_3.jpg_window_36.jpg,   |   75.00%\n",
      "MaI849_041_line_1.jpg_window_20.jpg,   |   35.71%\n",
      "MaI12_Page100_line_4.jpg_window_27.jpg,   |   36.67%\n",
      "MaI849_041_line_1.jpg_window_24.jpg,   |   8.33%\n",
      "MaI14_051_01.jpg_window_8.jpg,   |   33.33%\n",
      "MaI12_Page101_line_3.jpg_window_10.jpg,   |   35.71%\n",
      "maI16_01_7.jpg_window_19.jpg,   |   6.25%\n",
      "MaI12_Page101_line_5.jpg_window_1.jpg,   |   33.33%\n",
      "MaI12_Page100_line_3.jpg_window_12.jpg,   |   6.67%\n",
      "MaI12_Page102_line_2.jpg_window_28.jpg,   |   12.50%\n",
      "MaI12_Page100_line_5.jpg_window_48.jpg,   |   66.67%\n",
      "MaI849_038_line_4.jpg_window_25.jpg,   |   8.33%\n",
      "maI16_01_4.jpg_window_18.jpg,   |   28.57%\n",
      "MaI849_041_line_4.jpg_window_35.jpg,   |   14.29%\n",
      "MaI14_051_02.jpg_window_36.jpg,   |   20.83%\n",
      "MaI12_Page101_line_2.jpg_window_30.jpg,   |   33.33%\n",
      "MaI849_038_line_4.jpg_window_34.jpg,   |   0.00%\n",
      "MaI14_051_01.jpg_window_41.jpg,   |   20.83%\n",
      "MaI14_051_05.jpg_window_28.jpg,   |   7.14%\n",
      "MaI12_Page101_line_5.jpg_window_17.jpg,   |   21.43%\n",
      "MaI849_041_line_7.jpg_window_15.jpg,   |   4.17%\n",
      "MaI12_Page100_line_5.jpg_window_27.jpg,   |   6.67%\n",
      "MaI12_Page100_line_2.jpg_window_11.jpg,   |   20.00%\n",
      "MaI849_039_line_9.jpg_window_10.jpg,   |   6.67%\n",
      "MaI14_007_1.jpg_window_0.jpg,   |   33.33%\n",
      "MaI14_051_08.jpg_window_7.jpg,   |   20.83%\n",
      "MaI849_041_line_5.jpg_window_8.jpg,   |   17.86%\n",
      "MaI849_041_line_4.jpg_window_48.jpg,   |   5.00%\n",
      "MaI14_007_8.jpg_window_47.jpg,   |   12.50%\n",
      "MaI14_051_06.jpg_window_40.jpg,   |   92.86%\n",
      "MaI12_Page100_line_2.jpg_window_40.jpg,   |   40.00%\n",
      "MaI14_051_03.jpg_window_7.jpg,   |   16.67%\n",
      "MaI849_038_line_1.jpg_window_13.jpg,   |   21.43%\n",
      "MaI849_041_line_5.jpg_window_34.jpg,   |   0.00%\n",
      "MaI849_041_line_7.jpg_window_25.jpg,   |   14.29%\n",
      "MaI849_041_line_9.jpg_window_5.jpg,   |   7.14%\n",
      "MaI849_041_line_9.jpg_window_32.jpg,   |   20.00%\n",
      "MaI14_007_8.jpg_window_27.jpg,   |   8.33%\n",
      "maI16_01_4.jpg_window_32.jpg,   |   16.67%\n",
      "MaI849_039_line_6.jpg_window_19.jpg,   |   20.83%\n",
      "MaI14_051_02.jpg_window_35.jpg,   |   12.50%\n",
      "MaI12_Page100_line_4.jpg_window_28.jpg,   |   6.67%\n",
      "MaI12_Page101_line_2.jpg_window_31.jpg,   |   43.33%\n",
      "MaI12_Page101_line_2.jpg_window_40.jpg,   |   7.14%\n",
      "MaI849_039_line_8.jpg_window_15.jpg,   |   5.00%\n",
      "MaI14_051_01.jpg_window_13.jpg,   |   25.00%\n",
      "MaI849_039_line_4.jpg_window_35.jpg,   |   25.00%\n",
      "MaI12_Page101_line_2.jpg_window_13.jpg,   |   0.00%\n",
      "MaI14_007_8.jpg_window_1.jpg,   |   6.25%\n",
      "MaI12_Page100_line_1.jpg_window_44.jpg,   |   8.33%\n",
      "MaI12_Page101_line_3.jpg_window_8.jpg,   |   0.00%\n",
      "maI16_01_5.jpg_window_42.jpg,   |   20.00%\n",
      "MaI849_039_line_5.jpg_window_22.jpg,   |   5.00%\n",
      "MaI14_051_06.jpg_window_0.jpg,   |   14.29%\n",
      "MaI12_Page101_line_5.jpg_window_23.jpg,   |   25.00%\n",
      "MaI14_007_4.jpg_window_36.jpg,   |   92.86%\n",
      "MaI12_Page102_line_2.jpg_window_44.jpg,   |   8.33%\n",
      "MaI849_041_line_4.jpg_window_18.jpg,   |   12.50%\n",
      "MaI12_Page100_line_3.jpg_window_36.jpg,   |   35.71%\n",
      "maI16_01_4.jpg_window_0.jpg,   |   10.00%\n",
      "MaI14_007_5.jpg_window_22.jpg,   |   50.00%\n",
      "MaI849_038_line_6.jpg_window_37.jpg,   |   64.29%\n",
      "MaI849_039_line_6.jpg_window_3.jpg,   |   20.83%\n",
      "MaI14_007_6.jpg_window_46.jpg,   |   8.33%\n",
      "MaI849_039_line_7.jpg_window_46.jpg,   |   5.00%\n",
      "MaI849_039_line_2.jpg_window_46.jpg,   |   12.50%\n",
      "MaI14_007_1.jpg_window_39.jpg,   |   20.00%\n",
      "MaI12_Page100_line_1.jpg_window_0.jpg,   |   13.33%\n",
      "MaI12_Page102_line_4.jpg_window_5.jpg,   |   16.67%\n",
      "MaI849_041_line_3.jpg_window_25.jpg,   |   7.14%\n",
      "MaI849_041_line_4.jpg_window_37.jpg,   |   92.86%\n",
      "maI16_01_6.jpg_window_38.jpg,   |   15.00%\n",
      "maI16_01_9.jpg_window_26.jpg,   |   0.00%\n",
      "MaI12_Page102_line_5.jpg_window_20.jpg,   |   70.00%\n",
      "MaI849_039_line_2.jpg_window_29.jpg,   |   5.00%\n",
      "MaI849_039_line_1.jpg_window_12.jpg,   |   11.11%\n",
      "MaI12_Page101_line_2.jpg_window_26.jpg,   |   40.00%\n",
      "MaI14_007_7.jpg_window_1.jpg,   |   25.00%\n",
      "MaI14_051_06.jpg_window_1.jpg,   |   20.83%\n",
      "MaI14_051_06.jpg_window_37.jpg,   |   78.57%\n",
      "MaI849_041_line_2.jpg_window_9.jpg,   |   8.33%\n",
      "MaI12_Page100_line_2.jpg_window_26.jpg,   |   21.43%\n",
      "MaI12_Page102_line_2.jpg_window_32.jpg,   |   37.50%\n",
      "MaI14_051_08.jpg_window_6.jpg,   |   10.71%\n",
      "MaI849_038_line_4.jpg_window_47.jpg,   |   7.14%\n",
      "MaI12_Page102_line_1.jpg_window_0.jpg,   |   60.00%\n",
      "MaI849_041_line_1.jpg_window_22.jpg,   |   0.00%\n",
      "MaI12_Page100_line_3.jpg_window_17.jpg,   |   14.29%\n",
      "MaI849_038_line_1.jpg_window_33.jpg,   |   46.43%\n",
      "MaI849_041_line_2.jpg_window_49.jpg,   |   14.29%\n",
      "maI16_01_8.jpg_window_25.jpg,   |   20.00%\n",
      "MaI849_038_line_2.jpg_window_13.jpg,   |   12.50%\n",
      "MaI849_038_line_4.jpg_window_12.jpg,   |   39.29%\n",
      "MaI14_051_05.jpg_window_3.jpg,   |   10.71%\n",
      "maI16_01_1.jpg_window_41.jpg,   |   16.67%\n",
      "MaI12_Page102_line_1.jpg_window_17.jpg,   |   14.29%\n",
      "MaI12_Page100_line_5.jpg_window_8.jpg,   |   76.67%\n",
      "maI16_01_9.jpg_window_33.jpg,   |   15.00%\n",
      "MaI849_039_line_6.jpg_window_50.jpg,   |   7.14%\n",
      "maI16_01_3.jpg_window_4.jpg,   |   20.83%\n",
      "MaI14_007_2.jpg_window_31.jpg,   |   16.67%\n",
      "MaI14_007_1.jpg_window_23.jpg,   |   10.71%\n",
      "MaI12_Page102_line_1.jpg_window_18.jpg,   |   8.33%\n",
      "MaI14_007_1.jpg_window_38.jpg,   |   12.50%\n",
      "MaI849_039_line_6.jpg_window_11.jpg,   |   82.14%\n",
      "MaI12_Page101_line_1.jpg_window_21.jpg,   |   33.33%\n",
      "MaI12_Page102_line_5.jpg_window_23.jpg,   |   16.67%\n",
      "maI16_01_2.jpg_window_28.jpg,   |   12.50%\n",
      "MaI12_Page101_line_3.jpg_window_30.jpg,   |   20.00%\n",
      "MaI14_051_07.jpg_window_49.jpg,   |   25.00%\n",
      "MaI849_039_line_9.jpg_window_13.jpg,   |   10.00%\n",
      "MaI12_Page101_line_1.jpg_window_32.jpg,   |   53.57%\n",
      "MaI12_Page102_line_1.jpg_window_31.jpg,   |   32.14%\n",
      "MaI849_039_line_6.jpg_window_8.jpg,   |   25.00%\n",
      "MaI849_041_line_1.jpg_window_50.jpg,   |   12.50%\n",
      "MaI12_Page101_line_2.jpg_window_39.jpg,   |   10.00%\n",
      "MaI14_007_8.jpg_window_37.jpg,   |   0.00%\n",
      "MaI14_007_8.jpg_window_26.jpg,   |   20.83%\n",
      "MaI14_007_3.jpg_window_17.jpg,   |   67.86%\n",
      "MaI849_041_line_8.jpg_window_11.jpg,   |   20.00%\n",
      "MaI12_Page102_line_3.jpg_window_9.jpg,   |   7.14%\n",
      "MaI12_Page101_line_3.jpg_window_12.jpg,   |   60.00%\n",
      "MaI14_007_6.jpg_window_22.jpg,   |   20.83%\n",
      "maI16_01_2.jpg_window_34.jpg,   |   14.29%\n",
      "MaI12_Page101_line_1.jpg_window_22.jpg,   |   25.00%\n",
      "MaI14_051_06.jpg_window_48.jpg,   |   8.33%\n",
      "MaI14_007_9.jpg_window_2.jpg,   |   28.57%\n",
      "MaI12_Page102_line_4.jpg_window_21.jpg,   |   29.17%\n",
      "MaI12_Page101_line_3.jpg_window_49.jpg,   |   10.71%\n",
      "maI16_01_5.jpg_window_27.jpg,   |   12.50%\n",
      "MaI849_039_line_7.jpg_window_30.jpg,   |   8.33%\n",
      "MaI14_007_3.jpg_window_34.jpg,   |   64.29%\n",
      "MaI12_Page101_line_2.jpg_window_7.jpg,   |   14.29%\n",
      "MaI849_038_line_1.jpg_window_7.jpg,   |   7.14%\n",
      "MaI14_007_4.jpg_window_51.jpg,   |   17.86%\n",
      "MaI849_039_line_3.jpg_window_38.jpg,   |   35.71%\n",
      "MaI14_051_04.jpg_window_4.jpg,   |   12.50%\n",
      "MaI14_051_05.jpg_window_11.jpg,   |   100.00%\n",
      "MaI12_Page102_line_3.jpg_window_13.jpg,   |   40.00%\n",
      "MaI12_Page102_line_5.jpg_window_36.jpg,   |   46.67%\n",
      "MaI14_007_2.jpg_window_35.jpg,   |   8.33%\n",
      "MaI849_041_line_3.jpg_window_16.jpg,   |   8.33%\n",
      "MaI849_039_line_2.jpg_window_51.jpg,   |   16.67%\n",
      "MaI14_007_7.jpg_window_20.jpg,   |   20.83%\n",
      "MaI14_007_3.jpg_window_35.jpg,   |   82.14%\n",
      "MaI849_039_line_4.jpg_window_26.jpg,   |   5.00%\n",
      "MaI12_Page100_line_2.jpg_window_46.jpg,   |   17.86%\n",
      "MaI849_039_line_7.jpg_window_37.jpg,   |   46.43%\n",
      "MaI12_Page102_line_5.jpg_window_9.jpg,   |   46.43%\n",
      "MaI14_051_04.jpg_window_20.jpg,   |   12.50%\n",
      "MaI14_051_04.jpg_window_13.jpg,   |   67.86%\n",
      "MaI14_051_01.jpg_window_3.jpg,   |   5.56%\n",
      "MaI14_051_05.jpg_window_40.jpg,   |   85.71%\n",
      "MaI849_041_line_4.jpg_window_20.jpg,   |   8.33%\n",
      "MaI12_Page100_line_1.jpg_window_4.jpg,   |   28.57%\n",
      "MaI14_051_04.jpg_window_36.jpg,   |   25.00%\n",
      "MaI14_007_6.jpg_window_30.jpg,   |   10.71%\n",
      "MaI12_Page100_line_3.jpg_window_34.jpg,   |   8.33%\n",
      "MaI14_007_4.jpg_window_31.jpg,   |   20.00%\n",
      "MaI12_Page102_line_3.jpg_window_48.jpg,   |   4.17%\n",
      "maI16_01_5.jpg_window_1.jpg,   |   12.50%\n",
      "MaI14_007_4.jpg_window_11.jpg,   |   64.29%\n",
      "MaI849_041_line_6.jpg_window_18.jpg,   |   8.33%\n",
      "maI16_01_8.jpg_window_26.jpg,   |   25.00%\n",
      "MaI14_007_9.jpg_window_9.jpg,   |   0.00%\n",
      "maI16_01_7.jpg_window_11.jpg,   |   29.17%\n",
      "maI16_01_8.jpg_window_8.jpg,   |   12.50%\n",
      "MaI14_051_05.jpg_window_32.jpg,   |   7.14%\n",
      "MaI14_051_07.jpg_window_22.jpg,   |   25.00%\n",
      "MaI12_Page100_line_1.jpg_window_33.jpg,   |   17.86%\n",
      "MaI849_039_line_8.jpg_window_10.jpg,   |   14.29%\n",
      "MaI849_039_line_6.jpg_window_46.jpg,   |   33.33%\n",
      "MaI12_Page101_line_4.jpg_window_42.jpg,   |   25.00%\n",
      "maI16_01_7.jpg_window_25.jpg,   |   10.00%\n",
      "MaI14_007_7.jpg_window_5.jpg,   |   12.50%\n",
      "MaI849_039_line_2.jpg_window_20.jpg,   |   20.00%\n",
      "MaI12_Page100_line_5.jpg_window_43.jpg,   |   29.17%\n",
      "MaI849_041_line_3.jpg_window_0.jpg,   |   5.00%\n",
      "MaI14_051_07.jpg_window_41.jpg,   |   7.14%\n",
      "MaI14_051_08.jpg_window_12.jpg,   |   20.83%\n",
      "MaI14_051_05.jpg_window_37.jpg,   |   60.71%\n",
      "MaI12_Page102_line_5.jpg_window_38.jpg,   |   30.00%\n",
      "MaI849_039_line_5.jpg_window_14.jpg,   |   36.67%\n",
      "MaI14_051_03.jpg_window_38.jpg,   |   96.43%\n",
      "maI16_01_2.jpg_window_7.jpg,   |   15.00%\n",
      "MaI12_Page102_line_1.jpg_window_27.jpg,   |   16.67%\n",
      "MaI12_Page101_line_3.jpg_window_48.jpg,   |   33.33%\n",
      "maI16_01_4.jpg_window_26.jpg,   |   6.25%\n",
      "MaI12_Page101_line_1.jpg_window_0.jpg,   |   16.67%\n",
      "MaI14_007_7.jpg_window_35.jpg,   |   14.29%\n",
      "MaI849_038_line_1.jpg_window_38.jpg,   |   7.14%\n",
      "MaI14_051_03.jpg_window_18.jpg,   |   60.71%\n",
      "MaI12_Page102_line_1.jpg_window_12.jpg,   |   28.57%\n",
      "MaI14_007_9.jpg_window_36.jpg,   |   16.67%\n",
      "MaI14_007_4.jpg_window_35.jpg,   |   92.86%\n",
      "MaI14_051_02.jpg_window_44.jpg,   |   16.67%\n",
      "MaI849_041_line_9.jpg_window_3.jpg,   |   67.86%\n",
      "MaI14_007_1.jpg_window_2.jpg,   |   7.14%\n",
      "MaI14_007_2.jpg_window_19.jpg,   |   20.83%\n",
      "MaI849_039_line_4.jpg_window_18.jpg,   |   12.50%\n",
      "MaI14_007_6.jpg_window_18.jpg,   |   28.57%\n",
      "MaI12_Page100_line_4.jpg_window_39.jpg,   |   22.22%\n",
      "MaI849_039_line_6.jpg_window_16.jpg,   |   25.00%\n",
      "MaI12_Page102_line_3.jpg_window_41.jpg,   |   3.57%\n",
      "maI16_01_6.jpg_window_46.jpg,   |   5.56%\n",
      "MaI849_039_line_4.jpg_window_19.jpg,   |   12.50%\n",
      "MaI849_039_line_8.jpg_window_11.jpg,   |   14.29%\n",
      "MaI12_Page100_line_4.jpg_window_5.jpg,   |   40.00%\n",
      "Average Accuracy: 23.20%\n",
      "Results saved to //home//jaykishor_c//ml//Output2//BLEU_Scores_Accuracy_actual_and_predicated_char.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    " \n",
    "# Function to calculate BLEU score\n",
    "def calculate_bleu_score(actual_sequence, predicted_sequence):\n",
    "    reference = [list(actual_sequence)]  # Wrap in another list for multiple references\n",
    "    hypothesis = list(predicted_sequence)\n",
    "    bleu_score = sentence_bleu(reference, hypothesis)\n",
    "    return bleu_score\n",
    " \n",
    "# Function to calculate accuracy\n",
    "def calculate_accuracy(actual_sequence, predicted_sequence):\n",
    "    # Ensure the sequences are the same length for comparison\n",
    "    min_length = min(len(actual_sequence), len(predicted_sequence))\n",
    "    if min_length == 0:\n",
    "        return 0  # Return 0 if either sequence is empty to avoid division by zero\n",
    "    correct_predictions = sum(1 for i in range(min_length) if actual_sequence[i] == predicted_sequence[i])\n",
    "    accuracy = (correct_predictions / min_length) * 100  # Calculate accuracy as a percentage\n",
    "    return accuracy\n",
    "\n",
    " \n",
    "# Folder paths and files\n",
    "image_folder = r\"//home//jaykishor_c//ml//color_window_double1//color_window_double1\"\n",
    "label_file = r\"//home//jaykishor_c//ml//gt_WIndow .xlsx\"\n",
    "output_file = r\"//home//jaykishor_c//ml//Output2//BLEU_Scores_Accuracy_actual_and_predicated_char.xlsx\"\n",
    " \n",
    "# Load the labels DataFrame\n",
    "label_df = pd.read_excel(label_file)\n",
    " \n",
    "# List all image files in the folder\n",
    "image_files = [f for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png'))]\n",
    " \n",
    "# Initialize a results list and variable to track total accuracy\n",
    "results = []\n",
    "total_accuracy = 0\n",
    "num_images = 0\n",
    " \n",
    "# Process each image\n",
    "for image_name in image_files:\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_name}\")\n",
    "        continue\n",
    " \n",
    "    # Extract the actual sequence from the DataFrame\n",
    "    actual_sequence = get_actual_sequence_from_df(image_name, image, label_df)\n",
    "    if actual_sequence is None:\n",
    "        print(f\"No label found for image: {image_name}\")\n",
    "        continue\n",
    " \n",
    "    # Predict the sequence using the HMM models\n",
    "    predicted_sequence = predict_line_sequence(image)\n",
    "    # Calculate BLEU score\n",
    "    # bleu_score = calculate_bleu_score(actual_sequence, predicted_sequence)\n",
    "    # Calculate accuracy\n",
    "    accuracy = calculate_accuracy(actual_sequence, predicted_sequence)\n",
    "    print(f'{image_name},   |   {accuracy:.2f}%')\n",
    "    # Add the accuracy to the total\n",
    "    total_accuracy += accuracy\n",
    "    num_images += 1\n",
    "    # Append results\n",
    "    results.append({\n",
    "        \"Image Name\": image_name,\n",
    "        \"Actual Sequence\": ''.join(actual_sequence),\n",
    "        \"Predicted Sequence\": predicted_sequence,\n",
    "        # \"BLEU Score\": bleu_score,\n",
    "        \"Accuracy\": accuracy\n",
    "    })\n",
    " \n",
    "# Calculate the average accuracy\n",
    "average_accuracy = total_accuracy / num_images if num_images > 0 else 0\n",
    " \n",
    "# Save the results to an Excel sheet\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel(output_file, index=False)\n",
    " \n",
    "# Print average accuracy\n",
    "print(f\"Average Accuracy: {average_accuracy:.2f}%\")\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLUE score for each character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for character 'െ': 2.8389115490445386e-232\n",
      "BLEU Score for character 'ത': 3.395489862661054e-232\n",
      "BLEU Score for character 'അ': 3.905171559289336e-232\n",
      "BLEU Score for character '്': 3.102670747246022e-232\n",
      "BLEU Score for character 'ാ': 2.8074745719404793e-232\n",
      "BLEU Score for character 'ി': 3.1704930077296505e-232\n",
      "BLEU Score for character 'പ': 3.717992382547305e-232\n",
      "BLEU Score for character 'റ': 3.450944764551663e-232\n",
      "BLEU Score for character 'ര': 3.1541659018010075e-232\n",
      "BLEU Score for character 'ള': 5.0812780049985006e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score for character 'ക': 3.1750531739989355e-232\n",
      "BLEU Score for character 'ഷ': 5.2822531843433194e-232\n",
      "BLEU Score for character 'മ': 3.637495942076716e-232\n",
      "BLEU Score for character 'ആ': 5.4761369592005975e-232\n",
      "BLEU Score for character 'ഠ': 5.132511014697576e-232\n",
      "BLEU Score for character 'ൽ': 5.6383456886193345e-232\n",
      "BLEU Score for character 'ർ': 5.6064713439997805e-232\n",
      "BLEU Score for character 'ഇ': 5.882492291217442e-232\n",
      "BLEU Score for character 'ങ': 6.573479617511883e-232\n",
      "BLEU Score for character 'ന': 3.215678839099107e-232\n",
      "BLEU Score for character 'ജ': 4.479906922372853e-232\n",
      "BLEU Score for character 'ട': 3.5871414554869394e-232\n",
      "BLEU Score for character 'വ': 3.768861368173813e-232\n",
      "BLEU Score for character 'ഹ': 5.377379257150705e-232\n",
      "BLEU Score for character 'ം': 4.25444340014233e-232\n",
      "BLEU Score for character 'യ': 3.668116985093867e-232\n",
      "BLEU Score for character '\"': 2.7919579467428226e-232\n",
      "BLEU Score for character 'ധ': 5.132511014697576e-232\n",
      "BLEU Score for character 'ച': 3.933859688850494e-232\n",
      "BLEU Score for character 'എ': 4.846541452815868e-232\n",
      "BLEU Score for character 'ല': 3.86093635691412e-232\n",
      "BLEU Score for character 'ഴ': 5.065387892369619e-232\n",
      "BLEU Score for character 'ദ': 4.4253060780047346e-232\n",
      "BLEU Score for character 'ഗ': 5.201447251047216e-232\n",
      "BLEU Score for character 'ഉ': 6.3211493403261365e-232\n",
      "BLEU Score for character 'ൂ': 5.042935485021652e-232\n",
      "BLEU Score for character 'സ': 4.387300924558648e-232\n",
      "BLEU Score for character 'ീ': 5.1928426769222885e-232\n",
      "BLEU Score for character 'ഭ': 5.432324344202769e-232\n",
      "BLEU Score for character 'ഖ': 7.259419553339045e-232\n",
      "BLEU Score for character 'ശ': 5.1365603362015104e-232\n",
      "BLEU Score for character 'ൈ': 5.194987150918798e-232\n",
      "BLEU Score for character 'ൾ': 6.499038101352642e-232\n",
      "BLEU Score for character 'ഘ': 8.34186146802972e-232\n",
      "BLEU Score for character 'ൊ': 5.965248090744155e-232\n",
      "BLEU Score for character 'ഞ': 7.817228731469945e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "characters_to_remove = ['ണ',' ൾ','ു','ഥ','ൃ','ബ','ൂഃ','ഃ','ൻ']\n",
    " \n",
    "# Calculate BLEU score for predictions\n",
    "for char, model in character_hmms.items():\n",
    "    try:\n",
    "        sequences = combined_features_glcm_and_dct[char]\n",
    "        # Remove empty sequences\n",
    "        sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "        # Check if we have any sequences left\n",
    "        if len(sequences) >= 15:\n",
    "            X = np.vstack(sequences)\n",
    "            lengths = [len(seq) for seq in sequences]\n",
    "            # Check for valid transition matrix\n",
    "            row_sums = model.transmat_.sum(axis=1)\n",
    "            if not np.allclose(row_sums, 1):\n",
    "                print(f\"Problem with transition matrix for character '{char}': row sums = {row_sums}\")\n",
    "                characters_to_remove.append(char)\n",
    "                continue  # Skip this model and move to the next one\n",
    "            # Get predicted states\n",
    "            predicted_states = model.predict(X)\n",
    "            mapped_predictions = [state_to_char[state] for state in predicted_states]\n",
    "            # Calculate BLEU score\n",
    "            bleu_score = sentence_bleu([ground_truth], mapped_predictions)\n",
    "            print(f\"BLEU Score for character '{char}': {bleu_score}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Error with character '{char}': {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove characters if they exist in the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ണ\n",
      "Character ണ not found in character_hmms.\n",
      " ൾ\n",
      "Character  ൾ not found in character_hmms.\n",
      "ു\n",
      "Character ു not found in character_hmms.\n",
      "ഥ\n",
      "Character ഥ not found in character_hmms.\n",
      "ൃ\n",
      "Character ൃ not found in character_hmms.\n",
      "ബ\n",
      "Character ബ not found in character_hmms.\n",
      "ൂഃ\n",
      "Character ൂഃ not found in character_hmms.\n",
      "ഃ\n",
      "Character ഃ not found in character_hmms.\n",
      "ൻ\n",
      "Character ൻ not found in character_hmms.\n"
     ]
    }
   ],
   "source": [
    "for char in characters_to_remove:\n",
    "    print (char)\n",
    "    if char in character_hmms:\n",
    "        del character_hmms[char]\n",
    "        print(f\"Deleted HMM model for character: {char}\")\n",
    "    else:\n",
    "        print(f\"Character {char} not found in character_hmms.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate BLEU score for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 7.817228731469945e-232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "# Calculate BLEU score for predictions (this is more useful for sequence generation tasks)\n",
    "for char, model in character_hmms.items():\n",
    "    sequences = combined_features_glcm_and_dct[char]\n",
    "    \n",
    "    # Remove empty sequences\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "    \n",
    "    # Check if we have any sequences left\n",
    "    if len(sequences) >=15:\n",
    "       \n",
    "        X = np.vstack(sequences)\n",
    "    \n",
    "    lengths = [len(seq) for seq in sequences]\n",
    "    \n",
    "    # Get predicted states\n",
    "    predicted_states = model.predict(X)\n",
    "    mapped_predictions = [state_to_char[state] for state in predicted_states]\n",
    "\n",
    "# Calculate BLEU score\n",
    "bleu_score = sentence_bleu([ground_truth], mapped_predictions)\n",
    "print(f\"BLEU Score: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the BLUR score to an Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to //home//jaykishor_c//ml//Output2//mapped_predictions_bleu_scores.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/jaykishor_c/ml/JaykishorEnv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "\n",
    "# List to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each character and its model\n",
    "for char, model in character_hmms.items():\n",
    "    sequences = combined_features_glcm_and_dct[char]\n",
    "    \n",
    "    # Remove empty sequences\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "    \n",
    "    # Check if we have enough sequences to proceed\n",
    "    if len(sequences) >= 15:\n",
    "        X = np.vstack(sequences)\n",
    "\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        \n",
    "        # Get predicted states and map to characters\n",
    "        predicted_states = model.predict(X)\n",
    "        mapped_predictions = [state_to_char[state] for state in predicted_states]\n",
    "        \n",
    "        # Calculate BLEU score\n",
    "        bleu_score = sentence_bleu([ground_truth], mapped_predictions)\n",
    "        \n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'Character': char,\n",
    "            'Mapped Predictions': ''.join(mapped_predictions),\n",
    "            'BLEU Score': bleu_score\n",
    "        })\n",
    "\n",
    "# Create a DataFrame to store results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Save the results to an Excel file\n",
    "output_path = r'//home//jaykishor_c//ml//Output2//mapped_predictions_bleu_scores.xlsx'\n",
    "results_df.to_excel(output_path, index=False)\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Mapped Predictions</th>\n",
       "      <th>BLEU Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>െ</td>\n",
       "      <td>അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ\"അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ...</td>\n",
       "      <td>2.838912e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ത</td>\n",
       "      <td>\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...</td>\n",
       "      <td>3.395490e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>അ</td>\n",
       "      <td>\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഅഅഅഅഅഅഅ\"\"\"\"...</td>\n",
       "      <td>3.905172e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>്</td>\n",
       "      <td>ഃഃഃഃഃഃഃഃഃഃ\"\"\"\"ഃഃഃഃഃഃ\"\"\"\"\"\"\"\"ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ...</td>\n",
       "      <td>3.102671e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ാ</td>\n",
       "      <td>ംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...</td>\n",
       "      <td>2.807475e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ി</td>\n",
       "      <td>ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ\"\"\"\"ഃഃഃഃഃഃഃഃഃ...</td>\n",
       "      <td>3.170493e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>പ</td>\n",
       "      <td>അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅംം...</td>\n",
       "      <td>3.717992e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>റ</td>\n",
       "      <td>ംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...</td>\n",
       "      <td>3.450945e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ര</td>\n",
       "      <td>ംംംഃഃഃഃഃഃഃഃഃംംംംംംംംംംംംംംംംഃഃഃഃഃഃംംംംംംംംംംംം...</td>\n",
       "      <td>3.154166e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ള</td>\n",
       "      <td>ംംംംംംംംംംംംംംംംംംംംംംഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ...</td>\n",
       "      <td>5.081278e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ക</td>\n",
       "      <td>ംംംംംംംംംംംംംംംംംംംംം\"\"\"\"\"ംംംംംംംംംംംം\"\"\"\"\"\"ംം...</td>\n",
       "      <td>3.175053e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ഷ</td>\n",
       "      <td>ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ\"\"\"\"\"\"\"\"\"\"\"\"ഃഃ\"അംംംംംംംംംംംംംംം...</td>\n",
       "      <td>5.282253e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>മ</td>\n",
       "      <td>ംംംംംംംംംംംംംംംംംംംംംംംം\"\"\"ംംംംംംംംംംംംംംംംംംം...</td>\n",
       "      <td>3.637496e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ആ</td>\n",
       "      <td>അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅംംംംംംംംംംംംംംഅഅ...</td>\n",
       "      <td>5.476137e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ഠ</td>\n",
       "      <td>അഅഅഅഅഅഅഅ\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഅഅഅഅഅഅഅ\"\"\"\"\"\"\"\"\"അഅഅഅഅ...</td>\n",
       "      <td>5.132511e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ൽ</td>\n",
       "      <td>\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"ംം...</td>\n",
       "      <td>5.638346e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ർ</td>\n",
       "      <td>ംംംംംംംം\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഃഃഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഃഃഅഅഅ...</td>\n",
       "      <td>5.606471e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ഇ</td>\n",
       "      <td>ംംംഅഅഅഅഅഅഅഅഅഅഅംംംംംംംഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ...</td>\n",
       "      <td>5.882492e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ങ</td>\n",
       "      <td>ംംംംംംംംംംംംംംംം\"\"\"\"\"\"\"\"\"\"\"\"അഅഅഅഅ\"\"\"\"\"അഅഅഅ\"\"അഅ...</td>\n",
       "      <td>6.573480e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ന</td>\n",
       "      <td>അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ...</td>\n",
       "      <td>3.215679e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ജ</td>\n",
       "      <td>അഅഅഅഅഅഅഃഃഃഃഃഃഃഅഅഅഃഃഃഃഃഃഃഃഃഃഃഃഃഃഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ...</td>\n",
       "      <td>4.479907e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ട</td>\n",
       "      <td>\"\"അഅഅ\"\"\"\"\"\"\"\"\"\"\"അഅ\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഅ\"\"\"\"\"\"അഅഅ\"\"\"...</td>\n",
       "      <td>3.587141e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>വ</td>\n",
       "      <td>\"\"\"ഃഃഃഃഃഃഃഃഃഃഃംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...</td>\n",
       "      <td>3.768861e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ഹ</td>\n",
       "      <td>ഃഃഃഃഃഃഃ\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഅ...</td>\n",
       "      <td>5.377379e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ം</td>\n",
       "      <td>ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഅഅഅഅഃഃഃഃഃഃഃഃ...</td>\n",
       "      <td>4.254443e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>യ</td>\n",
       "      <td>അഅഃഃഃഃഃഃഃഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ...</td>\n",
       "      <td>3.668117e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>\"</td>\n",
       "      <td>അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഃഃഃഃഃഃഃഃഃഃഅഅഅഃഃഃഃഃഃഃഃഃഅഅഅഅഅഅഅഅഅ...</td>\n",
       "      <td>2.791958e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ധ</td>\n",
       "      <td>ഃഃഃ\"ംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...</td>\n",
       "      <td>5.132511e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ച</td>\n",
       "      <td>\"\"\"\"\"\"\"\"ംം\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...</td>\n",
       "      <td>3.933860e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>എ</td>\n",
       "      <td>ംംംംഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅംംംംംംംഅഅഅഅഅഅഅഅഅഅംംംംംം...</td>\n",
       "      <td>4.846541e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ല</td>\n",
       "      <td>അഅ\"\"\"\"\"\"അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ\"\"\"\"\"\"\"അഅഅഅഅ\"\"\"അഅഅഅഅഅ...</td>\n",
       "      <td>3.860936e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ഴ</td>\n",
       "      <td>ംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...</td>\n",
       "      <td>5.065388e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ദ</td>\n",
       "      <td>\"\"\"\"\"\"\"\"\"\"\"\"\"\"ംംംംംംംംംംംംഃഃഃഃഃഃഃഃഃഃഃഃംഃഃഃഃഃഃഃ...</td>\n",
       "      <td>4.425306e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ഗ</td>\n",
       "      <td>അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ\"ംംംംംംംംംം...</td>\n",
       "      <td>5.201447e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ഉ</td>\n",
       "      <td>\"\"\"\"\"\"ഃഃഃഃഃഃഃഃംംംഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ\"അഅഅഅഅഅഅഅഅഅ...</td>\n",
       "      <td>6.321149e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ൂ</td>\n",
       "      <td>ഃഃഃഃംംംംംംംംംംഃ\"\"\"\"\"ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ\"\"\"\"...</td>\n",
       "      <td>5.042935e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>സ</td>\n",
       "      <td>അഅഅഅഅഅഅഅഅഅ\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...</td>\n",
       "      <td>4.387301e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ീ</td>\n",
       "      <td>അഅഅഅഅഅഅഅഅഅഅഅഅഅഅംംംംംംംംംഃഃഃഃഃംംംംഃഃഃംംംംംംംംംം...</td>\n",
       "      <td>5.192843e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ഭ</td>\n",
       "      <td>അഅഅഅഅഅഅഅഅഅഅഅഅ\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...</td>\n",
       "      <td>5.432324e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ഖ</td>\n",
       "      <td>ംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...</td>\n",
       "      <td>7.259420e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ശ</td>\n",
       "      <td>\"\"\"\"\"\"\"\"\"\"\"ംംംംംംംഅഅഅഅഅഅംംംംംംംംംംംംംംംംഅഅഅഅഅഅ...</td>\n",
       "      <td>5.136560e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ൈ</td>\n",
       "      <td>\"ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ\"\"\"\"\"ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ...</td>\n",
       "      <td>5.194987e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ൾ</td>\n",
       "      <td>\"\"\"\"ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃംംംംംംംംംംംംംംംംംംംംംം...</td>\n",
       "      <td>6.499038e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ഘ</td>\n",
       "      <td>ഃഃഃഃഃഃഃഃഃഃഃഃഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഃഃഃംംംംംംഃഃഃഃഃഃഃം...</td>\n",
       "      <td>8.341861e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ൊ</td>\n",
       "      <td>\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഃഅഃഅഃഅഃഃഅഃഅഃഅ\"\"\"\"...</td>\n",
       "      <td>5.965248e-232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ഞ</td>\n",
       "      <td>അഅഅഅഅഅഅഅഅഅഅഅഅഅ\"\"\"\"ംംംംംംംംംംംം\"\"\"\"\"\"\"\"\"\"\"\"\"\"ഃഃ...</td>\n",
       "      <td>7.817229e-232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Character                                 Mapped Predictions     BLEU Score\n",
       "0          െ  അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ\"അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ...  2.838912e-232\n",
       "1          ത  \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...  3.395490e-232\n",
       "2          അ  \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഅഅഅഅഅഅഅ\"\"\"\"...  3.905172e-232\n",
       "3          ്  ഃഃഃഃഃഃഃഃഃഃ\"\"\"\"ഃഃഃഃഃഃ\"\"\"\"\"\"\"\"ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ...  3.102671e-232\n",
       "4          ാ  ംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...  2.807475e-232\n",
       "5          ി  ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ\"\"\"\"ഃഃഃഃഃഃഃഃഃ...  3.170493e-232\n",
       "6          പ  അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅംം...  3.717992e-232\n",
       "7          റ  ംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...  3.450945e-232\n",
       "8          ര  ംംംഃഃഃഃഃഃഃഃഃംംംംംംംംംംംംംംംംഃഃഃഃഃഃംംംംംംംംംംംം...  3.154166e-232\n",
       "9          ള  ംംംംംംംംംംംംംംംംംംംംംംഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ...  5.081278e-232\n",
       "10         ക  ംംംംംംംംംംംംംംംംംംംംം\"\"\"\"\"ംംംംംംംംംംംം\"\"\"\"\"\"ംം...  3.175053e-232\n",
       "11         ഷ  ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ\"\"\"\"\"\"\"\"\"\"\"\"ഃഃ\"അംംംംംംംംംംംംംംം...  5.282253e-232\n",
       "12         മ  ംംംംംംംംംംംംംംംംംംംംംംംം\"\"\"ംംംംംംംംംംംംംംംംംംം...  3.637496e-232\n",
       "13         ആ  അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅംംംംംംംംംംംംംംഅഅ...  5.476137e-232\n",
       "14         ഠ  അഅഅഅഅഅഅഅ\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഅഅഅഅഅഅഅ\"\"\"\"\"\"\"\"\"അഅഅഅഅ...  5.132511e-232\n",
       "15         ൽ  \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"ംം...  5.638346e-232\n",
       "16         ർ  ംംംംംംംം\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഃഃഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഃഃഅഅഅ...  5.606471e-232\n",
       "17         ഇ  ംംംഅഅഅഅഅഅഅഅഅഅഅംംംംംംംഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ...  5.882492e-232\n",
       "18         ങ  ംംംംംംംംംംംംംംംം\"\"\"\"\"\"\"\"\"\"\"\"അഅഅഅഅ\"\"\"\"\"അഅഅഅ\"\"അഅ...  6.573480e-232\n",
       "19         ന  അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ...  3.215679e-232\n",
       "20         ജ  അഅഅഅഅഅഅഃഃഃഃഃഃഃഅഅഅഃഃഃഃഃഃഃഃഃഃഃഃഃഃഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ...  4.479907e-232\n",
       "21         ട  \"\"അഅഅ\"\"\"\"\"\"\"\"\"\"\"അഅ\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഅ\"\"\"\"\"\"അഅഅ\"\"\"...  3.587141e-232\n",
       "22         വ  \"\"\"ഃഃഃഃഃഃഃഃഃഃഃംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...  3.768861e-232\n",
       "23         ഹ  ഃഃഃഃഃഃഃ\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഅ...  5.377379e-232\n",
       "24         ം  ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഅഅഅഅഃഃഃഃഃഃഃഃ...  4.254443e-232\n",
       "25         യ  അഅഃഃഃഃഃഃഃഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ...  3.668117e-232\n",
       "26         \"  അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഃഃഃഃഃഃഃഃഃഃഅഅഅഃഃഃഃഃഃഃഃഃഅഅഅഅഅഅഅഅഅ...  2.791958e-232\n",
       "27         ധ  ഃഃഃ\"ംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...  5.132511e-232\n",
       "28         ച  \"\"\"\"\"\"\"\"ംം\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...  3.933860e-232\n",
       "29         എ  ംംംംഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅംംംംംംംഅഅഅഅഅഅഅഅഅഅംംംംംം...  4.846541e-232\n",
       "30         ല  അഅ\"\"\"\"\"\"അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ\"\"\"\"\"\"\"അഅഅഅഅ\"\"\"അഅഅഅഅഅ...  3.860936e-232\n",
       "31         ഴ  ംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...  5.065388e-232\n",
       "32         ദ  \"\"\"\"\"\"\"\"\"\"\"\"\"\"ംംംംംംംംംംംംഃഃഃഃഃഃഃഃഃഃഃഃംഃഃഃഃഃഃഃ...  4.425306e-232\n",
       "33         ഗ  അഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅ\"ംംംംംംംംംം...  5.201447e-232\n",
       "34         ഉ  \"\"\"\"\"\"ഃഃഃഃഃഃഃഃംംംഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ\"അഅഅഅഅഅഅഅഅഅ...  6.321149e-232\n",
       "35         ൂ  ഃഃഃഃംംംംംംംംംംഃ\"\"\"\"\"ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ\"\"\"\"...  5.042935e-232\n",
       "36         സ  അഅഅഅഅഅഅഅഅഅ\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...  4.387301e-232\n",
       "37         ീ  അഅഅഅഅഅഅഅഅഅഅഅഅഅഅംംംംംംംംംഃഃഃഃഃംംംംഃഃഃംംംംംംംംംം...  5.192843e-232\n",
       "38         ഭ  അഅഅഅഅഅഅഅഅഅഅഅഅ\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...  5.432324e-232\n",
       "39         ഖ  ംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംംം...  7.259420e-232\n",
       "40         ശ  \"\"\"\"\"\"\"\"\"\"\"ംംംംംംംഅഅഅഅഅഅംംംംംംംംംംംംംംംംഅഅഅഅഅഅ...  5.136560e-232\n",
       "41         ൈ  \"ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ\"\"\"\"\"ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃ...  5.194987e-232\n",
       "42         ൾ  \"\"\"\"ഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃഃംംംംംംംംംംംംംംംംംംംംംം...  6.499038e-232\n",
       "43         ഘ  ഃഃഃഃഃഃഃഃഃഃഃഃഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഅഃഃഃംംംംംംഃഃഃഃഃഃഃം...  8.341861e-232\n",
       "44         ൊ  \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"അഃഅഃഅഃഅഃഃഅഃഅഃഅ\"\"\"\"...  5.965248e-232\n",
       "45         ഞ  അഅഅഅഅഅഅഅഅഅഅഅഅഅ\"\"\"\"ംംംംംംംംംംംം\"\"\"\"\"\"\"\"\"\"\"\"\"\"ഃഃ...  7.817229e-232"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Log Probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for char, model in character_hmms.items():\\n    sequences = combined_features_glcm_and_dct[char]\\n    sequences = [seq for seq in sequences if len(seq) > 0]\\n\\n    if len(sequences) >= 15:\\n        X = np.vstack(sequences)\\n        lengths = [len(seq) for seq in sequences]\\n        log_probability = model.score(X, lengths)\\n        print(f\"Log Probability for character \\'{char}\\': {log_probability}\")\\n'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for char, model in character_hmms.items():\n",
    "    sequences = combined_features_glcm_and_dct[char]\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "\n",
    "    if len(sequences) >= 15:\n",
    "        X = np.vstack(sequences)\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        log_probability = model.score(X, lengths)\n",
    "        print(f\"Log Probability for character '{char}': {log_probability}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Model Probability**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for char, model in character_hmms.items():\\n    sequences = combined_features_glcm_and_dct[char]\\n    sequences = [seq for seq in sequences if len(seq) > 0]\\n\\n    if len(sequences) >= 15:\\n        X = np.vstack(sequences)\\n        lengths = [len(seq) for seq in sequences]\\n        log_probability = model.score(X, lengths)\\n        model_probability = np.exp(log_probability)  # Convert to regular probability\\n        print(f\"Model Probability for character \\'{char}\\': {model_probability}\")\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for char, model in character_hmms.items():\n",
    "    sequences = combined_features_glcm_and_dct[char]\n",
    "    sequences = [seq for seq in sequences if len(seq) > 0]\n",
    "\n",
    "    if len(sequences) >= 15:\n",
    "        X = np.vstack(sequences)\n",
    "        lengths = [len(seq) for seq in sequences]\n",
    "        log_probability = model.score(X, lengths)\n",
    "        model_probability = np.exp(log_probability)  # Convert to regular probability\n",
    "        print(f\"Model Probability for character '{char}': {model_probability}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Transition Matrix Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for char, model in character_hmms.items():\\n    row_sums = model.transmat_.sum(axis=1)\\n    if not np.allclose(row_sums, 1):\\n        print(f\"Transition matrix issue for \\'{char}\\': {row_sums}\")\\n    else:\\n        print(f\"Transition matrix for \\'{char}\\' is valid.\")\\n'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for char, model in character_hmms.items():\n",
    "    row_sums = model.transmat_.sum(axis=1)\n",
    "    if not np.allclose(row_sums, 1):\n",
    "        print(f\"Transition matrix issue for '{char}': {row_sums}\")\n",
    "    else:\n",
    "        print(f\"Transition matrix for '{char}' is valid.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual and Prediction of character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to /home/jaykishor_c/ml/Output2//actual_vs_predicted.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store actual vs predicted characters\n",
    "results = {'Actual': [], 'Predicted': []}\n",
    " \n",
    "# Process each test character and its sequences\n",
    "for actual_char, test_sequences in combined_features_glcm_and_dct.items():\n",
    "    for test_sequence in test_sequences:\n",
    "        test_sequence = np.array(test_sequence)\n",
    "        # Dictionary to store scores for each character model\n",
    "        scores = {}\n",
    "        # Score the test sequence against each character's HMM model\n",
    "        for char, model in character_hmms.items():\n",
    "            try:\n",
    "                scores[char] = model.score(test_sequence)\n",
    "            except:\n",
    "                scores[char] = -np.inf  # If model can't score, assign a low score\n",
    "        # Predict the character with the highest score\n",
    "        predicted_char = max(scores, key=scores.get)\n",
    "        # Store the result\n",
    "        results['Actual'].append(actual_char)\n",
    "        results['Predicted'].append(predicted_char)\n",
    " \n",
    "# Save the results to an Excel file\n",
    "output_path = r'/home/jaykishor_c/ml/Output2//actual_vs_predicted.xlsx'\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_excel(output_path, index=False)\n",
    "\n",
    "\n",
    "print(f\"Results saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JaykishorEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
